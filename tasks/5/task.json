{
  "id": 5,
  "status": "-",
  "title": "Local app",
  "description": "Create a local Electron+React app to handle project management, see tasks and feature status, update task fields/notes, see all the documents in a nice Markdown display, be able to launch/manage agents running locally and overview status in git (i.e. being able to see if an agent is working on something or not), getting notifications when work is done etc., see all child projects and manage them in the future. Ideally this app is the go-to place for anyone to use THIS project (the factory) and wouldn't have to run any scripts or code manually. A big feature of this should also be access to some sort of chat interface so that it should be possible to talk with a chosen LLM about the whole project. It should be possible to give the LLM chat access to the same tools that the agents use but in a restricted manner, so only the ones that are read-only. It should also be possible to configure further ways of connecting to LLMS for chat and for agents other than the currently chosen litellm. For instance, there's an app LM Studio that allows connecting to a locally running LLM via API calls. The project for the local app exists detailing the steps involved in creating a local app for project management. This will be the first project to stem from this one. It should follow the same exact principles as this project, but it will live in its own separate repository. This project is just meant to kickstart the whole scaffolding and specification. If any extra functionality comes into this project, it should be easy to adapt this Local app project to use the exact same ideas. Notes: Currently I'm using VSCode to view the project, run everything, see tasks etc. It would be ideal to have a dedicated app for managing the project, viewing tasks, seeing progress etc. For being able to see how the agents fares etc. Cline the plugin for VSCode does something like this and maybe it makes sense to even built upon a fork on this. One thing to keep in mind is that we want to be really third-party independent. If we can create something ourselves we should. The only question is how it integrates with the project. If maintaining such a service/dependency is too heavy, then using a third party solution makes sense. Each third party solution should be its own tasks, with documented features and explanations as to why it was chosen etc.",
  "features": [
    {
      "id": "5.1",
      "status": "-",
      "title": "Bootstrap Local App repository and add as submodule",
      "description": "Create a new repository (e.g., factory-local-app) initialized with standard files (README with scope/goals, LICENSE, .gitignore, .editorconfig, .nvmrc, package.json), docs/ folder with placeholders (ARCHITECTURE.md, DEVELOPMENT.md), and minimal Node project setup. Add it to this factory repo as a Git submodule under projects/local-app. Acceptance: submodule exists under projects/local-app; repo contains the specified files; README explains project purpose and alignment to the factory; dev install command and dev script stub documented.",
      "plan": "Implementation plan for 5.1: Bootstrap Local App repository and add as submodule\n\n1) Create the remote repository\n- Name: factory-local-app (or similar)\n- Description: \"Local Electron+React app scaffold for project/agent management aligned with the Factory.\"\n- Visibility: per project policy (public/private)\n- Default branch: main\n- License: MIT (add license file in repo)\n\n2) Initialize the repository locally\n- Prepare a working directory and initialize git:\n  - git clone <new_repo_url> factory-local-app\n  - cd factory-local-app\n- Initialize Node version via .nvmrc (use current LTS used by the factory; example below)\n\n3) Create initial file/folder structure\n- Root files:\n  - README.md\n  - LICENSE\n  - .gitignore\n  - .editorconfig\n  - .nvmrc\n  - package.json\n- Folders:\n  - docs/\n    - ARCHITECTURE.md\n    - DEVELOPMENT.md\n  - src/\n    - index.js\n\n4) Populate files with minimal, acceptance-compliant content\n- README.md (must explain project purpose, alignment with the factory, and have install/dev script docs)\n  Suggested content:\n  Title: Factory Local App\n  Purpose: A local Electron+React app to manage Factory projects, tasks, agent status, documents (Markdown), notifications, and chat with LLMs via read-only tools. This repo is the standalone implementation aligned with the Factory principles.\n  Alignment: Shares architecture and conventions with the Factory; intended to integrate seamlessly and evolve independently while remaining compatible with Factory workflows and tooling.\n  Status: Bootstrap scaffold only; Electron/React wiring to follow in subsequent features.\n  Requirements: Node (see .nvmrc), npm.\n  Install: npm install\n  Develop: npm run dev (currently a stub that logs a message; see docs/DEVELOPMENT.md)\n  Next steps: Electron-React scaffolding, agent read-only tool adapters, LLM provider adapters (LiteLLM, LM Studio, etc.).\n\n- LICENSE: Standard MIT text with your name/year.\n\n- .gitignore (Node + OS/editor basics):\n  node_modules/\n  dist/\n  .DS_Store\n  .env\n  .env.*\n  npm-debug.log*\n  yarn-debug.log*\n  yarn-error.log*\n  .vscode/\n\n- .editorconfig (common defaults):\n  root = true\n\n  [*]\n  charset = utf-8\n  end_of_line = lf\n  insert_final_newline = true\n  indent_style = space\n  indent_size = 2\n  trim_trailing_whitespace = true\n\n- .nvmrc: set Node LTS (example):\n  20.17.0\n\n- package.json (minimal Node project setup with a dev script stub):\n  {\n    \"name\": \"@factory/local-app\",\n    \"version\": \"0.1.0\",\n    \"private\": true,\n    \"description\": \"Local Electron+React app scaffold for Factory project management.\",\n    \"license\": \"MIT\",\n    \"type\": \"module\",\n    \"engines\": { \"node\": \">=20.17.0\" },\n    \"scripts\": {\n      \"dev\": \"node src/index.js\",\n      \"validate\": \"node -e \\\"console.log('TODO: add validation/linting')\\\"\"\n    }\n  }\n\n- docs/ARCHITECTURE.md (placeholder):\n  Overview: High-level goals (project/task/agent management UI, docs viewer, notifications, LLM chat with read-only tool access).\n  Principles: Local-first, third-party independent when practical; modular adapters for LLM providers; alignment with Factory repo conventions.\n  Modules (planned): UI (Electron+React), Data layer (reads project files/git), Agent status integration, LLM provider adapters.\n  Security/Privacy: Local data, restricted read-only tool invocation for chat.\n\n- docs/DEVELOPMENT.md (placeholder):\n  Prerequisites: Node per .nvmrc, npm, git.\n  Setup: nvm use; npm install.\n  Commands: npm run dev (currently prints a stub message); npm run validate.\n  Conventions: Editorconfig, future lint/formatting planned.\n  Next: Add Electron+React scaffolding and dev runner; document environment variables when introduced.\n\n- src/index.js (stub dev entry):\n  console.log(\"Factory Local App: dev environment not yet implemented. See docs/DEVELOPMENT.md.\");\n  process.exit(0);\n\n5) Commit and push the bootstrap\n- git add .\n- git commit -m \"chore: bootstrap factory-local-app scaffold (docs, config, dev stub)\"\n- git push origin main\n\n6) Add as a submodule in the Factory repo\n- From the root of the Factory repo:\n  - git submodule add -b main <new_repo_url> projects/local-app\n  - git commit -m \"chore(projects): add local app as git submodule\"\n- If submodules are already initialized, ensure they are updated:\n  - git submodule update --init --recursive\n\n7) Verify acceptance criteria\n- Submodule exists under projects/local-app pointing to the new repo.\n- The submodule's repo contains: README.md, LICENSE, .gitignore, .editorconfig, .nvmrc, package.json, docs/ARCHITECTURE.md, docs/DEVELOPMENT.md, src/index.js.\n- README explains project purpose and alignment to Factory and documents install and dev script stub (npm install; npm run dev).\n\n8) Notes and considerations\n- Keep this repo independent; future work will add Electron+React and adapter architecture.\n- Third-party integrations (LiteLLM, LM Studio, etc.) will be evaluated and documented as separate tasks with rationale.\n- Ensure Node version stays in sync with the Factory by updating .nvmrc as needed.\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.2",
      "status": "-",
      "title": "Electron + React + TypeScript scaffold",
      "description": "Initialize the app using a modern toolchain (electron-vite with React + TypeScript). Include scripts: dev, build, lint, format. Ensure secure defaults: contextIsolation=true, sandbox where applicable, separate main, preload, and renderer packages. Acceptance: `pnpm/npm run dev` runs the app with React UI placeholder; `... build` yields a runnable app in dist; TypeScript config present; eslint/prettier configured.",
      "plan": "Implementation Plan: Electron + React + TypeScript Scaffold using electron-vite\n\n1) Prerequisites and Repo Setup\n   1. Ensure Node.js >= 18 and pnpm or npm installed.\n   2. Create a new, separate repository for the Local App (e.g., repo name: factory-local-app). Initialize git.\n   3. Add a .gitignore (Node + macOS/Windows defaults). Optionally add .nvmrc/.node-version.\n\n2) Scaffold with electron-vite (React + TypeScript)\n   1. Run the official scaffolder:\n      - Using npm: npm create electron-vite@latest\n      - Using pnpm: pnpm dlx create-electron-vite\n   2. When prompted:\n      - Project name: factory-local-app\n      - Framework: React\n      - Variant: TypeScript\n   3. cd factory-local-app and install deps:\n      - pnpm install (or npm install)\n\n3) Verify Project Structure (separate main/preload/renderer)\n   1. Ensure folders exist (names may vary by template):\n      - electron/main (or src/main): Electron main process\n      - electron/preload (or src/preload): Preload scripts\n      - src/renderer (or src/renderer): React renderer\n   2. Confirm tsconfig(s) exist in root and for sub-packages (if template provides separate ones).\n\n4) Secure BrowserWindow Defaults\n   1. Open main process entry (e.g., electron/main/index.ts or src/main/index.ts):\n      - In new BrowserWindow({ webPreferences: {...} }) set:\n        - preload: path to preload script (resolved with fileURLToPath or join)...\n        - sandbox: true\n        - contextIsolation: true\n        - nodeIntegration: false\n        - webSecurity: true\n        - devTools: process.env.NODE_ENV !== 'production'\n        - disableBlinkFeatures: 'Auxclick' (optional)\n      - Remove/disable any use of the remote module.\n   2. Handle a simple IPC for testing:\n      - ipcMain.handle('ping', () => 'pong')\n\n5) Preload: Minimal, Read-Only, Context Bridge\n   1. In preload (e.g., electron/preload/index.ts):\n      - import { contextBridge, ipcRenderer } from 'electron'\n      - Expose a safe API:\n        contextBridge.exposeInMainWorld('api', {\n          ping: () => ipcRenderer.invoke('ping'),\n          versions: { electron: process.versions.electron, chrome: process.versions.chrome, node: process.versions.node }\n        })\n      - Avoid Node built-ins when sandbox: true (do not import fs/path).\n\n6) Renderer: React Placeholder UI\n   1. In src/renderer (React app entry), add a minimal page:\n      - Show a title like \"Factory Local App\"\n      - Buttons/labels to call window.api.ping() and display \"pong\" result.\n      - Display versions from window.api.versions.\n   2. Ensure TypeScript ambient types for window.api (create src/renderer/env.d.ts):\n      - declare interface Window { api: { ping(): Promise<string>; versions: { electron: string; chrome: string; node: string } } }\n\n7) TypeScript Configuration\n   1. Root tsconfig.json:\n      - \"compilerOptions\": { \"target\": \"ES2020\", \"module\": \"ESNext\", \"strict\": true, \"moduleResolution\": \"Bundler\", \"jsx\": \"react-jsx\", \"types\": [\"node\"] }\n      - Include/Exclude appropriate src paths.\n   2. If template splits tsconfig per package (main/preload/renderer), ensure each has strict: true and appropriate lib/module settings.\n\n8) ESLint + Prettier Setup\n   1. Install dev dependencies:\n      - pnpm add -D eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin eslint-plugin-react eslint-plugin-react-hooks eslint-config-prettier prettier\n   2. Create .eslintrc.cjs:\n      module.exports = {\n        root: true,\n        env: { browser: true, node: true, es2021: true },\n        parser: '@typescript-eslint/parser',\n        parserOptions: { ecmaVersion: 'latest', sourceType: 'module', ecmaFeatures: { jsx: true } },\n        plugins: ['@typescript-eslint', 'react', 'react-hooks'],\n        extends: [\n          'eslint:recommended',\n          'plugin:@typescript-eslint/recommended',\n          'plugin:react/recommended',\n          'plugin:react-hooks/recommended',\n          'prettier'\n        ],\n        settings: { react: { version: 'detect' } },\n        rules: { 'react/react-in-jsx-scope': 'off' }\n      }\n   3. Create .prettierrc.json:\n      { \"semi\": true, \"singleQuote\": true, \"printWidth\": 100, \"trailingComma\": \"es5\" }\n   4. Add .prettierignore and .eslintignore (e.g., dist, out, build, node_modules).\n\n9) Package Scripts (dev, build, lint, format)\n   1. In package.json, ensure the following scripts exist/are adjusted:\n      - \"dev\": \"electron-vite dev\"\n      - \"build\": \"electron-vite build && electron-builder\"\n      - \"lint\": \"eslint . --ext .ts,.tsx,.cjs,.mjs\"\n      - \"format\": \"prettier --write .\"\n   2. Keep \"type\": \"module\" if template uses ESM.\n\n10) Electron Builder Configuration\n   1. Add a minimal build config in package.json or electron-builder.yml:\n      - appId: com.yourorg.factory-local-app\n      - productName: Factory Local App\n      - files: [\"dist/**\", \"dist-electron/**\", \"package.json\"] (paths may differ depending on template output)\n      - directories: { output: \"release\" }\n      - mac/win/linux targets: use defaults (e.g., dmg, nsis, AppImage) or minimal cross-platform.\n   2. Ensure electron-builder is a devDependency (template usually includes it).\n\n11) Content Security Policy (CSP)\n   1. In renderer index.html, add a conservative CSP meta for production:\n      - <meta http-equiv=\"Content-Security-Policy\" content=\"default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; connect-src 'self'; object-src 'none'; base-uri 'self'; form-action 'self'\">\n   2. For development, allow Vite's websocket: include ws://localhost:* in connect-src when NODE_ENV=development.\n\n12) Test Dev Workflow\n   1. Run: pnpm dev (or npm run dev)\n   2. Verify the Electron window loads the React app, shows versions, and the ping button returns \"pong\".\n   3. Confirm DevTools are available in dev and disabled in production builds.\n\n13) Test Production Build\n   1. Run: pnpm build (or npm run build)\n   2. Verify artifacts are generated in release/ (or dist/ depending on template).\n   3. Launch the packaged app to confirm it runs and shows the placeholder UI.\n\n14) Documentation\n   1. Create/Update README.md with:\n      - Prerequisites\n      - Install steps\n      - Scripts (dev, build, lint, format)\n      - Security defaults explanation (contextIsolation, sandbox, nodeIntegration=false, CSP)\n      - Known paths for main/preload/renderer code\n   2. Note how to switch between npm and pnpm.\n\nAcceptance Checklist Mapping\n- Run pnpm/npm run dev: opens Electron with React UI placeholder and working preload IPC (ping).\n- Run pnpm/npm run build: produces a runnable packaged app.\n- TypeScript config present (root and/or per package) with strict.\n- ESLint + Prettier configured with scripts lint and format.\n- Secure defaults in BrowserWindow: contextIsolation=true, sandbox=true, nodeIntegration=false; preload used; renderer sandboxed.\n- Separate code packages for main, preload, renderer via electron-vite template.",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.3",
      "status": "-",
      "title": "Typed IPC contract and preload API surface",
      "description": "Define a minimal IPC contract with typed channels for: settings:get/set, project:select/validate, tasks:list, task:get, task:update, docs:list, docs:read, git:status, agents:list/start/stop/logs, llm:chat. Implement a preload script exposing a narrow, typed API to the renderer. Document IPC schemas in docs/ARCHITECTURE.md. Acceptance: TypeScript types for request/response payloads; runtime validation; renderer can call stubs for each channel; security validated (no Node APIs exposed directly).",
      "plan": "Typed IPC contract and preload API surface \u2013 Implementation Plan\n\nGoal\nProvide a minimal, secure IPC contract with typed channels and runtime validation. Expose a narrow, typed preload API to the renderer. Include documentation and basic tests. Ensure no Node APIs are exposed.\n\nTech choices\n- Language: TypeScript\n- Validation: zod\n- Electron APIs: ipcMain.handle / ipcRenderer.invoke, contextBridge.exposeInMainWorld\n- Testing: vitest (or jest) for unit tests\n\n1) Repository structure and dependencies\n1.1. Create/confirm project structure:\n- /electron/main/ (main process TS)\n- /electron/preload/ (preload TS)\n- /shared/ipc/ (shared channel names, schemas, types)\n- /renderer/ (React code)\n- /docs/ARCHITECTURE.md (IPC contract docs)\n- /tests/ (unit tests for schemas and preload surface)\n1.2. Add dependencies:\n- dependencies: zod\n- devDependencies: @types/electron, vitest (or jest), ts-node/tsup/esbuild as needed for build, typescript\n1.3. Ensure tsconfig is split or configured for main/preload/renderer with isolatedModules.\n\n2) Define channel names and IPC versioning\n2.1. Create shared/ipc/channels.ts:\n- export const IPC_VERSION = 'v1' as const\n- export const Channels = {\n  settings: { get: 'settings:get', set: 'settings:set' },\n  project: { select: 'project:select', validate: 'project:validate' },\n  tasks: { list: 'tasks:list', get: 'task:get', update: 'task:update' },\n  docs: { list: 'docs:list', read: 'docs:read' },\n  git: { status: 'git:status' },\n  agents: { list: 'agents:list', start: 'agents:start', stop: 'agents:stop', logs: 'agents:logs' },\n  llm: { chat: 'llm:chat' },\n  meta: { version: 'ipc:version' }\n} as const\n- export type ChannelName = typeof Channels[keyof typeof Channels][keyof typeof Channels[keyof typeof Channels]]; (or flatten into a union)\n\n3) Define runtime schemas and types\n3.1. Create shared/ipc/schemas.ts using zod. For each channel define request/response schemas:\n- settings:get\n  Req: z.object({ keys: z.array(z.string()).optional() })\n  Res: z.object({ values: z.record(z.unknown()) })\n- settings:set\n  Req: z.object({ values: z.record(z.unknown()) })\n  Res: z.object({ success: z.boolean() })\n- project:select\n  Req: z.object({ path: z.string() })\n  Res: z.object({ path: z.string(), name: z.string().optional(), valid: z.boolean() })\n- project:validate\n  Req: z.object({ path: z.string() })\n  Res: z.object({ valid: z.boolean(), reasons: z.array(z.string()).optional() })\n- tasks:list\n  Req: z.object({ status: z.array(z.string()).optional(), search: z.string().optional(), limit: z.number().int().min(1).max(500).optional() })\n  Res: z.object({ tasks: z.array(z.object({ id: z.string(), title: z.string(), status: z.string(), assignee: z.string().nullable().optional(), updatedAt: z.string() })) })\n- task:get\n  Req: z.object({ id: z.string() })\n  Res: z.object({ id: z.string(), title: z.string(), description: z.string().optional(), status: z.string(), notes: z.string().optional(), metadata: z.record(z.unknown()).optional(), updatedAt: z.string() })\n- task:update\n  Req: z.object({ id: z.string(), patch: z.object({ title: z.string().optional(), description: z.string().optional(), status: z.string().optional(), notes: z.string().optional(), metadata: z.record(z.unknown()).optional() }).refine((p)=>Object.keys(p).length>0, 'patch must have at least 1 key') })\n  Res: z.object({ success: z.boolean(), task: z.any().optional() })\n- docs:list\n  Req: z.object({ basePath: z.string().optional() })\n  Res: z.object({ docs: z.array(z.object({ path: z.string(), title: z.string().optional() })) })\n- docs:read\n  Req: z.object({ path: z.string() })\n  Res: z.object({ path: z.string(), content: z.string(), frontmatter: z.record(z.unknown()).optional() })\n- git:status\n  Req: z.object({ cwd: z.string().optional() })\n  Res: z.object({ branch: z.string().optional(), dirty: z.boolean(), ahead: z.number().int().optional(), behind: z.number().int().optional(), files: z.array(z.object({ path: z.string(), status: z.string() })) })\n- agents:list\n  Req: z.object({})\n  Res: z.object({ agents: z.array(z.object({ id: z.string(), name: z.string(), status: z.enum(['idle','running','stopped','error']), pid: z.number().optional(), taskId: z.string().optional() })) })\n- agents:start\n  Req: z.object({ id: z.string().optional(), name: z.string().optional(), args: z.record(z.unknown()).optional() }).refine((v)=>!!v.id||!!v.name, { message: 'id or name required' })\n  Res: z.object({ success: z.boolean(), instanceId: z.string().optional() })\n- agents:stop\n  Req: z.object({ id: z.string() })\n  Res: z.object({ success: z.boolean() })\n- agents:logs\n  Req: z.object({ id: z.string(), since: z.number().int().optional(), limit: z.number().int().optional() })\n  Res: z.object({ logs: z.array(z.object({ ts: z.number(), level: z.enum(['debug','info','warn','error']), message: z.string() })) })\n- llm:chat\n  Req: z.object({ model: z.string().optional(), messages: z.array(z.object({ role: z.enum(['system','user','assistant','tool']), content: z.string(), name: z.string().optional(), tool_call_id: z.string().optional() })), temperature: z.number().min(0).max(2).optional() })\n  Res: z.object({ message: z.object({ role: z.literal('assistant'), content: z.string() }), usage: z.object({ promptTokens: z.number().optional(), completionTokens: z.number().optional() }).optional() })\n- meta: version\n  Req: z.object({}) ; Res: z.object({ version: z.string() })\n3.2. Create shared/ipc/types.ts exporting TypeScript types via zod.infer for all request/response payloads (e.g., SettingsGetReq = z.infer<typeof Schemas.Settings.Get.Req>) and grouped namespaces.\n\n4) Main-process: typed handler registration with runtime validation\n4.1. Create electron/main/ipc/handle.ts with helper:\n- function registerHandler<TReq, TRes>(channel: string, reqSchema: ZodSchema<TReq>, resSchema: ZodSchema<TRes>, handler: (event, req: TReq) => Promise<TRes> | TRes)\n  - ipcMain.handle(channel, async (event, raw) => { const req = reqSchema.parse(raw); const res = await handler(event, req); return resSchema.parse(res); })\n4.2. Create electron/main/ipc/register.ts to register all channels with stub handlers:\n- settings:get -> in-memory store (Map) returning requested keys or all\n- settings:set -> merge into Map, return { success: true }\n- project:select -> return { path, name: basename(path), valid: true }\n- project:validate -> return { valid: true, reasons: [] }\n- tasks:list -> return { tasks: [] } (stub)\n- task:get -> return a fabricated task for given id\n- task:update -> noop update against fabricated task; return { success: true, task: { ... } }\n- docs:list -> return { docs: [{ path: 'README.md', title: 'README' }] }\n- docs:read -> return content stub like '# Placeholder'\n- git:status -> return { dirty: false, files: [], branch: 'main', ahead: 0, behind: 0 }\n- agents:list -> return an empty list\n- agents:start -> return { success: true, instanceId: 'stub-1' }\n- agents:stop -> return { success: true }\n- agents:logs -> return { logs: [] }\n- llm:chat -> return { message: { role: 'assistant', content: 'Stub response' } }\n- ipc:version -> return { version: IPC_VERSION }\n4.3. Wire registration in electron/main/index.ts after app.whenReady():\n- import registerIPCHandlers() and call it before creating BrowserWindow\n\n5) Preload: secure, narrow, typed API surface\n5.1. Create electron/preload/safeInvoke.ts\n- function safeInvoke<TReq, TRes>(channel, reqSchema, resSchema, payload):\n  - validate payload with reqSchema.parse\n  - const res = await ipcRenderer.invoke(channel, payload)\n  - return resSchema.parse(res)\n5.2. Create electron/preload/index.ts\n- Use contextBridge.exposeInMainWorld('api', {\n  meta: { version: () => safeInvoke(Channels.meta.version, Schemas.Meta.Version.Req, Schemas.Meta.Version.Res, {}) },\n  settings: { get: (keys?) => safeInvoke(...), set: (values) => safeInvoke(...) },\n  project: { select: (path) => safeInvoke(...), validate: (path) => safeInvoke(...) },\n  tasks: { list: (opts?) => safeInvoke(...), get: (id) => safeInvoke(...), update: (id, patch) => safeInvoke(...) },\n  docs: { list: (basePath?) => safeInvoke(...), read: (path) => safeInvoke(...) },\n  git: { status: (cwd?) => safeInvoke(...) },\n  agents: { list: () => safeInvoke(...), start: (args) => safeInvoke(...), stop: (id) => safeInvoke(...), logs: (id, opts?) => safeInvoke(...) },\n  llm: { chat: (input) => safeInvoke(...) }\n})\n5.3. Add electron/preload/global.d.ts to augment Window:\n- declare global { interface Window { api: { ...full typed surface... } } }\n5.4. Ensure no Node APIs are exposed; do not export ipcRenderer or fs. Only functions above.\n\n6) BrowserWindow security hardening\n6.1. In electron/main/createWindow.ts (or index.ts) when creating BrowserWindow:\n- webPreferences: {\n  contextIsolation: true,\n  nodeIntegration: false,\n  enableRemoteModule: false,\n  sandbox: true,\n  preload: path.join(__dirname, 'preload.js'),\n}\n- Set a Content Security Policy for the renderer (meta tag or headers if using custom protocol). Disallow eval.\n- Validate allowed origins if loading external content (prefer file:// or custom app:// protocol only).\n\n7) Renderer stubs/smoke wiring\n7.1. In renderer, create a simple hook or effect that calls window.api.meta.version() and window.api.tasks.list() and logs results to ensure stubs function.\n7.2. Add minimal UI trigger (button) to call, but feature acceptance only requires renderer can call stubs; the hook suffices.\n\n8) Tests\n8.1. Schema tests (tests/ipc.schemas.test.ts):\n- For each Req/Res schema, test valid payload passes and representative invalid payload fails.\n8.2. Preload API surface tests (tests/preload.api.test.ts):\n- Mock ipcRenderer.invoke and assert safeInvoke parses/throws correctly.\n- Assert window.api exposes only expected top-level keys (Object.keys(window.api)).\n8.3. Handler tests (tests/main.handlers.test.ts):\n- Unit test registerHandler rejects invalid requests and validates responses.\n\n9) Documentation\n9.1. Create/extend docs/ARCHITECTURE.md with:\n- IPC overview: goals, security model, versioning (IPC_VERSION = v1), channel naming conventions, request/response flow.\n- Channel catalog: list each channel with request/response shape (brief tables or bullet lists), example payloads, error semantics (Zod errors mapped to { code: 'BAD_REQUEST', message }).\n- Preload API surface: document window.api structure and usage examples.\n- Security posture: contextIsolation, nodeIntegration=false, no Node exposure, runtime validation, CSP.\n- Extensibility: how to add a new channel (add schemas, types, handler, preload function, docs), versioning strategy (introduce v2 channels or feature-detect via ipc:version).\n\n10) DX and linting safeguards\n10.1. Add ESLint/TS rules to prevent importing 'electron' or Node built-ins in /renderer.\n10.2. Add tsconfig path aliases: '@shared/*' -> './shared/*' to share types.\n10.3. Add a precommit hook to run type check and tests for IPC layers.\n\n11) Acceptance validation checklist\n- TypeScript types exported for all request/response payloads under shared/ipc/types.ts\n- All ipcMain handlers and preload wrappers validate with zod at runtime\n- Renderer can call stubs for each channel: add a simple smoke call on app start\n- Security validated: BrowserWindow uses contextIsolation, nodeIntegration=false, sandbox=true; preload exposes only window.api; no direct Node APIs accessible in renderer\n\n12) Future work hooks (non-blocking)\n- Swap stub handlers with real integrations (git CLI, agents orchestrator, docs FS)\n- Introduce structured error type and map zod errors to renderer-friendly error codes\n- Add streaming support for llm:chat (via ipc event or MessagePort)\n- Add permissions model to restrict llm:chat to read-only tools\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.4",
      "status": "-",
      "title": "Local settings storage and project root selector",
      "description": "Implement a JSON-backed settings store in Electron userData path. Create UI to set and persist the path to the factory project root. Implement project validation against docs/FILE_ORGANISATION.md (check tasks/, docs/, scripts/, etc.). Acceptance: User can pick a folder; app validates and persists; invalid structure yields clear error; settings survive restarts; tested on macOS/Windows/Linux paths.",
      "plan": "Title: Local settings storage and project root selector (Electron + React)\n\nGoal\n- Persist user settings (JSON) in Electron app.getPath('userData')\n- Provide UI to pick and persist the factory project root directory\n- Validate the selected project directory against required structure (including docs/FILE_ORGANISATION.md and key folders like tasks/, docs/, scripts/)\n- Show clear errors for invalid selections\n- Ensure settings survive restarts\n- Work on macOS, Windows, Linux\n\nHigh-level Architecture\n- Main process: SettingsStore (JSON on disk), ProjectValidator (filesystem checks), IPC handlers for settings and validation\n- Preload: Expose a minimal, typed API via contextBridge\n- Renderer: Settings UI (React) to view/change project root, invoke validation, and show status\n- Shared types: TS interfaces for Settings and ValidationResult used across boundaries\n\nStep-by-step Plan\n1) Define shared types\n   - Create src/shared/types.ts:\n     - export interface AppSettings { version: number; projectRootPath?: string; lastValidatedAt?: string; }\n     - export interface ValidationIssue { code: string; message: string; path?: string; }\n     - export interface ValidationResult { ok: boolean; issues: ValidationIssue[]; }\n\n2) Implement SettingsStore in main\n   - File: src/main/settings/SettingsStore.ts\n   - Responsibilities:\n     - Use app.getPath('userData') to determine settings path (e.g., settings.json)\n     - Load on construction; if file missing, start with defaults { version: 1 }\n     - Provide async get(): Promise<AppSettings>\n     - Provide async set(patch: Partial<AppSettings>): Promise<AppSettings>\n     - Atomic write approach: write to temp file then rename, or writeFile with fs.promises; include try/catch and fallback\n     - Validate JSON on read; if corrupted, back up to settings.bak-<timestamp>.json and reset to defaults\n     - Normalize stored paths (use path.resolve and path.normalize), preserve original case on Windows but normalize separators in logic\n     - Export a singleton instance\n\n3) Implement ProjectValidator in main\n   - File: src/main/validation/ProjectValidator.ts\n   - validate(path: string): Promise<ValidationResult>\n     - Steps:\n       a) Resolve and realpath the provided path; ensure it exists and is a directory -> else issues.push({ code: 'NOT_A_DIRECTORY', ... })\n       b) Check required items:\n          - docs/FILE_ORGANISATION.md exists\n          - tasks/ directory exists\n          - docs/ directory exists\n          - scripts/ directory exists\n       c) Optional checks (non-blocking warnings): .git exists; README.md exists\n       d) If docs/FILE_ORGANISATION.md exists, optionally parse for additional expected paths:\n          - Simple heuristic: scan for backticked paths or lines starting with - or * that contain folder names; for each \"path/\" token, check existence; add issues with code 'MISSING_FROM_DOCS_SPEC' if missing (as warning)\n       e) Accumulate issues; ok = issues with blocking codes length === 0\n       f) Return { ok, issues }\n     - Cross-platform notes: use path.join; avoid hard-coded separators; handle permissions by catching EACCES and reporting code 'PERMISSION_DENIED'\n\n4) IPC contract and handlers (main)\n   - File: src/main/ipc/settingsIpc.ts\n   - Register in app ready phase\n   - ipcMain.handle('settings:get', async () => SettingsStore.get())\n   - ipcMain.handle('settings:setProjectRoot', async (event, folderPath: string) => {\n       const result = await ProjectValidator.validate(folderPath)\n       if (!result.ok) return { ok: false, result }\n       const settings = await SettingsStore.set({ projectRootPath: path.resolve(folderPath), lastValidatedAt: new Date().toISOString() })\n       return { ok: true, settings, result }\n     })\n   - ipcMain.handle('settings:validateProjectRoot', async (event, folderPath: string) => {\n       return await ProjectValidator.validate(folderPath)\n     })\n\n5) Preload bridge\n   - File: src/preload/index.ts\n   - contextIsolation: true, nodeIntegration: false\n   - Expose api.settings with types:\n     - get(): Promise<AppSettings>\n     - setProjectRoot(path: string): Promise<{ ok: boolean; settings?: AppSettings; result: ValidationResult }>\n     - validateProjectRoot(path: string): Promise<ValidationResult>\n   - Use ipcRenderer.invoke for the above channels\n\n6) Renderer: Settings UI\n   - Files:\n     - src/renderer/pages/Settings.tsx\n     - src/renderer/components/FolderPicker.tsx\n   - Settings.tsx features:\n     - Load current settings on mount (api.settings.get)\n     - Show current projectRootPath (read-only field or text)\n     - Input + \"Browse\" button to open folder dialog (via a small main-side helper or use ipcRenderer.invoke('dialog:openDirectory'))\n       - Add a minimal dialog handler in main: ipcMain.handle('dialog:openDirectory', async () => dialog.showOpenDialog({ properties: ['openDirectory'] }))\n     - Validate button: calls api.settings.validateProjectRoot(path)\n     - Save button: calls api.settings.setProjectRoot(path)\n     - Status area:\n       - If validation ok: green success message\n       - If invalid: list issues with clear messages and codes; group blocking vs warnings\n     - Clear/Reset button: let user clear projectRootPath (api.settings.setProjectRoot('')) or add 'settings:clear' handler to remove the key\n   - FolderPicker.tsx: simple component with input and Browse button\n\n7) App startup behavior\n   - In main app ready:\n     - Load settings; if no projectRootPath or validation fails (validate on startup), consider presenting a modal or route to Settings page in renderer\n   - In renderer root, if settings.projectRootPath missing or invalid, redirect to Settings route\n\n8) Error handling and messaging\n   - Translate ValidationIssue codes to user-friendly text in UI:\n     - NOT_A_DIRECTORY: \"Selected path is not a directory or does not exist\"\n     - MISSING_FILE_ORGANISATION: \"Missing docs/FILE_ORGANISATION.md\"\n     - MISSING_TASKS_DIR: \"Missing tasks/ folder\"\n     - MISSING_DOCS_DIR: \"Missing docs/ folder\"\n     - MISSING_SCRIPTS_DIR: \"Missing scripts/ folder\"\n     - PERMISSION_DENIED: \"Insufficient permissions to read this path\"\n     - MISSING_FROM_DOCS_SPEC: \"Path referenced in FILE_ORGANISATION.md not found\"\n   - The API returns structured issues; the UI shows them clearly\n\n9) Cross-platform considerations\n   - Use path.join and fs.promises\n   - Avoid shell expansions; always resolve absolute paths\n   - Windows: handle drive letters; do not alter case; store as returned by dialog\n   - Linux/macOS: follow symlinks via fs.realpath; but store the user-chosen path and keep resolved path only for internal checks\n   - Dialog filters: none (directory only)\n\n10) Persistence verification\n   - Ensure settings.json written to app.getPath('userData')\n   - On restart, SettingsStore loads existing file and hydrates state\n   - Add logging in dev for load/save paths\n\n11) Testing\n   - Unit tests (Node/Vitest or Jest) for ProjectValidator:\n     - Valid structure returns ok=true\n     - Missing tasks/ -> blocking issue\n     - Missing docs/FILE_ORGANISATION.md -> blocking issue\n     - Permission denied (simulate by pointing to a restricted dir) -> PERMISSION_DENIED\n     - Cross-platform path normalization tests (use path.normalize) and mock fs where needed\n   - Manual E2E checks on macOS/Windows/Linux:\n     - Pick valid project root -> success and persisted across app restart\n     - Pick invalid folder -> clear errors shown, not persisted\n     - After save, restart app -> settings loaded, UI shows selected path\n\n12) Implementation details and scaffolding\n   - Add new scripts/entries:\n     - Ensure preload is configured in BrowserWindow({ webPreferences: { preload, contextIsolation: true, nodeIntegration: false } })\n   - Update TypeScript config to include src/shared in both main and renderer tsconfig references\n   - Add minimal logging facility for main (console in dev)\n\n13) Documentation\n   - Add docs/settings.md explaining persistence location per OS, what is validated, and troubleshooting common errors\n   - Update README to describe how to configure project root in the app\n\n14) Acceptance criteria mapping\n   - User can pick a folder: Settings UI with folder dialog\n   - App validates and persists: 'Validate' and 'Save' flows wire to ProjectValidator and SettingsStore\n   - Invalid structure yields clear error: ValidationIssue codes/messages shown in UI\n   - Settings survive restarts: stored in userData/settings.json and loaded on launch\n   - Tested on macOS/Windows/Linux: unit tests + manual steps documented\n\n15) Nice-to-haves (deferred if time-limited)\n   - Live watcher: revalidate when project structure changes\n   - Auto-detect probable project root by scanning parent folders for matching structure\n   - Migration system for settings.version\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.5",
      "status": "-",
      "title": "Task schema definition and validator",
      "description": "Create a JSON Schema that mirrors the canonical task format described in docs/tasks/task_format.py and task_example.json. Generate TypeScript interfaces from the schema. Implement a validator used before reading/writing task.json. Acceptance: Validator catches malformed examples; TS types aligned with schema; unit tests cover valid/invalid cases using sample task.json files.",
      "plan": "Implementation plan for Feature 5.5: Task schema definition and validator\n\n1) Gather canonical sources\n- Open and study docs/tasks/task_format.py and docs/tasks/task_example.json to enumerate all fields, types, required/optional properties, allowed enums, nested objects/arrays, defaults, and any constraints (e.g., regex patterns, value ranges, cross-field rules).\n- Document the final field list and constraints in a short design notes file at docs/tasks/schema_notes.md for future maintainability.\n\n2) Create JSON Schema\n- File: schema/task.schema.json\n- Version: Draft 2020-12 (or 2019-09) to support modern features. Include $schema and $id.\n- Define the root object type with strict: \"additionalProperties\": false\n- Encode all required fields from Python canonical format.\n- Capture enums, min/max constraints, formats (date-time, uri), and patterns as present in the canonical spec.\n- Use definitions/$defs for reusable sub-objects (e.g., Task, Subtask, Assignee, StatusHistory, Link, etc.) if applicable.\n- Provide description fields for clarity and align property naming exactly with canonical names.\n- If Python spec defines defaults, include them using default where helpful (note defaults are for tooling, not enforcement).\n- Add examples array containing the known-good task_example.json.\n\n3) Validation library setup (Node/TS)\n- Dependency: ajv@^8 and ajv-formats for formats support.\n- Create a validation module in shared code:\n  - File: src/shared/validation/taskValidator.ts\n  - Export: validateTask(data: unknown): { valid: true; data: Task } | { valid: false; errors: Ajv.ErrorObject[] }\n  - Load and compile the schema once (singleton), configure Ajv with:\n    - allErrors: true\n    - strict: true\n    - removeAdditional: false\n    - allowUnionTypes: true (if needed)\n    - formats from ajv-formats\n  - Add helper function assertValidTask(data) that throws a descriptive Error when invalid, with a compacted error message builder for UI logging.\n\n4) Type generation from schema\n- Dependency: json-schema-to-typescript (jstt).\n- Script: npm run generate:task-types -> generates src/shared/types/task.ts from schema/task.schema.json\n- Configure jstt options:\n  - bannerComment warning that the file is auto-generated, do not edit.\n  - style: prefer interfaces\n  - declareExternallyReferenced: true\n- Ensure the generated root type is exported as Task to be consumed across the app.\n- Add a type-test compile step (tsc --noEmit) in CI that imports Task from generated types and uses it in at least one file to ensure alignment.\n\n5) Integrate validator in read/write flows\n- Identify modules that read and write task.json (e.g., src/main/fs/taskStore.ts or equivalent). If they don\u2019t exist yet, create a dedicated task store module.\n- On read:\n  - Read JSON -> parse -> validate via validateTask\n  - If invalid: throw a descriptive error including path(s) and message(s) for UI display.\n  - If valid: return typed Task\n- On write:\n  - Validate the Task object before serialization. If invalid, fail-fast with error to avoid persisting malformed data.\n- Optional: provide a CLI/Dev script npm run validate:task path/to/task.json to quickly validate files during development.\n\n6) Testing\n- Test framework: Vitest (or Jest if the project standard already exists). Assume Vitest here.\n- Add fixtures:\n  - tests/fixtures/task/valid/task_valid.json \u2014 copy of docs/tasks/task_example.json\n  - tests/fixtures/task/invalid/*.json \u2014 multiple malformed cases, such as:\n    - missing required field(s)\n    - wrong type (string vs number)\n    - disallowed additional properties\n    - invalid enum values\n    - invalid nested object shape\n    - bad format (e.g., invalid date-time)\n- Unit tests:\n  - tests/taskValidator.valid.spec.ts \u2014 ensure valid example passes and types narrow to Task\n  - tests/taskValidator.invalid.spec.ts \u2014 iterate over invalid fixtures, assert validateTask returns {valid:false} and errors describe the failing paths\n  - tests/generation.types.spec.ts \u2014 import generated Task type and ensure a sample object typed as Task compiles; ensure a known-invalid object fails type-check via // @ts-expect-error tests\n- Ensure CI runs: type generation (or validate generated file is up-to-date), tsc --noEmit, and vitest\n\n7) Developer tooling and scripts\n- package.json scripts:\n  - generate:task-types: json2ts schema/task.schema.json -o src/shared/types/task.ts\n  - validate:task: ts-node scripts/validateTaskFile.ts <path> (or node + tsx if repo uses it)\n  - test: vitest run\n  - typecheck: tsc --noEmit\n- Add a prebuild or postinstall step to generate types or document that contributors must run generate:task-types after schema changes.\n\n8) Documentation\n- docs/tasks/schema_notes.md \u2014 mapping table: Python canonical fields -> JSON Schema properties; any assumptions; examples of valid/invalid fragments.\n- CONTRIBUTING.md \u2014 add a short section explaining how to modify task.schema.json, regenerate types, run validator, and add tests.\n\n9) Quality gates\n- Add a CI job that fails if:\n  - Generated types are outdated (diff check after running generate:task-types)\n  - tsc typecheck fails\n  - vitest fails\n- Add a pre-commit hook (optional) using simple-git-hooks or husky to run quick validate:task on changed task.json files.\n\n10) Future-proofing\n- If the Python canonical spec evolves, keep a bi-directional mapping note in schema_notes.md and bump schema $id version (e.g., v1 -> v1.1). Communicate breaking vs non-breaking changes and update tests accordingly.\n\nDeliverables checklist\n- schema/task.schema.json aligned with docs/tasks/task_format.py and task_example.json\n- src/shared/types/task.ts generated by json-schema-to-typescript\n- src/shared/validation/taskValidator.ts with Ajv-based validateTask/assertValidTask\n- Read/write integration with validation hooks\n- Tests and fixtures for valid/invalid cases\n- Scripts in package.json and CI updates\n- Documentation updates",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.6",
      "status": "-",
      "title": "Tasks indexer and file watcher",
      "description": "Scan tasks/{id}/ directories under the selected project root to build an in-memory index of tasks and features. Implement a file watcher to refresh the index on changes (create/modify/delete). Cache results for quick UI rendering. Acceptance: Indexing handles 100+ tasks; watcher reliably updates on file changes; performance measured and documented; exposed via IPC: tasks:list and task:get.",
      "plan": "Title: Tasks indexer and file watcher\n\nGoal\n- Scan tasks/{id}/ under the selected project root to build an in-memory index of tasks and their features.\n- Implement a file watcher to refresh the index on filesystem changes (create/modify/delete).\n- Cache results for fast UI rendering.\n- Expose IPC endpoints: tasks:list and task:get.\n- Handle 100+ tasks reliably; measure and document performance.\n\nHigh-level Design\n- Run the indexer in Electron main process.\n- Use chokidar to watch the tasks directory.\n- In-memory cache for fast list rendering; optionally persist to disk to prewarm on app start.\n- Minimal summaries for list; full details on demand for get.\n- Parser abstraction to support JSON/YAML task metadata (task.json/task.yaml). Extract features if present.\n- IPC handlers return typed DTOs to the renderer.\n\nDirectory and Files\n- tasks/{id}/ is a task directory. We detect the task ID from the directory name.\n- Preferred task metadata files within each task dir (first match wins):\n  1) task.json\n  2) task.yaml or task.yml\n  3) README.md (fallback for title/description only)\n- Optional files: features.json or features.yaml; otherwise features can live inline in task metadata under \"features\" key. If none found, features = []\n\nTech Stack\n- Node/Electron main process (TypeScript)\n- chokidar for watching\n- fast-glob for initial discovery (or fs.readdir recursive if preferred)\n- yaml for YAML parsing\n- fs-extra for FS convenience\n- zod for schema validation (optional but recommended)\n- lodash.debounce (or simple custom debounce)\n- perf_hooks for measurements\n- Jest or Vitest for tests\n\nType Definitions (shared/types/tasks.ts)\n- TaskId = string\n- TaskSummary {\n  id: string\n  path: string\n  title: string\n  status?: string\n  featureCount: number\n  updatedAt: number // ms epoch from latest relevant file mtime\n}\n- TaskFeature {\n  id: string\n  title?: string\n  status?: string\n}\n- TaskDetail extends TaskSummary {\n  description?: string\n  assignee?: string\n  tags?: string[]\n  features: TaskFeature[]\n  raw?: { source: 'json'|'yaml'|'md'|null, data?: any }\n}\n- TaskIndexStats {\n  projectRoot: string\n  taskCount: number\n  lastFullScanMs: number\n  lastScanAt: number\n  averageScanMs?: number\n}\n\nFilesystem Parsing Rules\n- For each tasks/<id>/:\n  - Read task.json or task.yaml/yml. Validate with zod schema (soft validation: log and continue if invalid).\n  - Extract fields: title, status, description, assignee, tags, features.\n  - If features missing, try features.json or features.yaml.\n  - If no structured metadata found, try README.md: use first heading as title and first paragraph as description; features = [].\n  - Determine updatedAt as max mtime of the selected primary metadata file and features file (if any).\n- Feature entries should at least have id; if no id provided, derive from directory/file name or hash of title.\n\nCaching Strategy\n- Maintain an in-memory Map<string, TaskDetail> index (key = taskId).\n- Maintain a separate array of TaskSummary built from details to respond quickly.\n- Persist a snapshot of summaries + a minimal detail cache to disk in app.getPath('userData')/cache/tasks/<hash(projectRoot)>.json to prewarm on app launch.\n- On startup for a given project root: try load disk cache first, serve immediately; then trigger background fresh full scan to validate/refresh.\n- Throttle disk cache writes (e.g., once every 2 seconds, trailing) to avoid excessive FS writes during rapid changes.\n\nWatcher Strategy (chokidar)\n- Watch: <projectRoot>/tasks/** with ignored patterns: ['**/node_modules/**', '**/.git/**', '**/.DS_Store'].\n- Events handled: add, addDir, change, unlink, unlinkDir.\n- Debounce re-scan operations per task directory (e.g., 150ms) to coalesce multiple rapid edits.\n- Incremental updates: on event within tasks/<id>/..., only re-parse that specific task; on directory removal, delete entry; on new dir, parse it.\n- Provide a full re-scan method as fallback and for initial indexing.\n\nPerformance\n- Use perf_hooks.performance.now() around scan operations; record lastFullScanMs and average over recent N scans.\n- Target: 100+ tasks initial scan in under ~500ms for simple metadata on a typical dev machine (document test conditions).\n- Ensure watchers do not trigger full re-scan unless necessary; prefer per-task incremental updates.\n\nIPC Endpoints (main/ipc/tasks.ts)\n- tasks:list -> returns { tasks: TaskSummary[], stats: TaskIndexStats }\n- task:get { id: string } -> returns TaskDetail | null\n- Optionally (dev-only): tasks:stats -> TaskIndexStats (or included in tasks:list)\n\nAPI Contracts (renderer expectation)\n- tasks:list should resolve quickly using in-memory summaries, even if a background refresh is ongoing.\n- task:get should return from cache if available; otherwise parse on-demand for that task directory and update cache.\n\nEdge Cases & Error Handling\n- Missing or malformed metadata: log warning; fall back to minimal info from directory name; do not crash.\n- Duplicate task IDs (duplicate directory names): last write wins; log error.\n- Non-UTF8 files: ignore with warning.\n- Root change: gracefully dispose current watcher and caches; initialize new indexer.\n\nImplementation Steps\n1) Scaffolding\n   - Create files:\n     - main/services/tasks/TaskIndexer.ts\n     - main/services/tasks/parsers/jsonParser.ts\n     - main/services/tasks/parsers/yamlParser.ts\n     - main/services/tasks/parsers/mdParser.ts\n     - main/ipc/tasks.ts\n     - shared/types/tasks.ts\n     - docs/performance/tasks_indexer.md\n     - tests/tasks/indexer.spec.ts\n\n2) Types and Schemas\n   - Define TaskSummary, TaskDetail, TaskFeature, TaskIndexStats in shared/types/tasks.ts.\n   - Define zod schemas in parsers for validation (optional but helpful).\n\n3) Parsers\n   - jsonParser: read task.json/features.json; parse, validate, normalize fields.\n   - yamlParser: read task.yaml|yml/features.yaml|yml; parse with yaml.\n   - mdParser: read README.md; extract first H1 (title) and first paragraph (description).\n   - Export a function parseTaskDir(taskDir: string): Promise<TaskDetail | null> that tries parsers in order and returns normalized TaskDetail.\n   - Ensure updatedAt is computed via fs.stat for the chosen files.\n\n4) TaskIndexer Class (main/services/tasks/TaskIndexer.ts)\n   - constructor(projectRoot: string)\n   - public async init(): initializes cache (load from disk), sets up chokidar watcher, triggers initial full scan in background.\n   - private async fullScan():\n     - Enumerate subdirectories under <root>/tasks using fs or fast-glob.\n     - In parallel (bounded concurrency, e.g., 10), parse each task dir.\n     - Build memory maps for details and summaries; compute stats; swap atomically.\n     - Persist summaries to disk cache (throttled).\n   - private async parseAndUpdateTask(taskDir: string): parse single task and update/remove in cache.\n   - private onFsEvent(event, path): debounced per task directory -> calls parseAndUpdateTask or remove.\n   - getSummaries(): TaskSummary[] (return shallow clone to avoid mutation)\n   - getTask(id: string): TaskDetail | null (if missing, try parse on-demand)\n   - getStats(): TaskIndexStats\n   - dispose(): close watcher, flush cache, cleanup timers.\n   - Use EventEmitter to emit 'index:updated' and 'task:updated' for future live UI updates (optional in this feature).\n\n5) Disk Cache\n   - Path: path.join(app.getPath('userData'), 'cache', 'tasks', hash(projectRoot) + '.json').\n   - Shape: { version: 1, projectRoot, summaries: TaskSummary[], timestamp }.\n   - Load on init if exists; populate in-memory summaries; mark as warm.\n   - Save after full scans and after bursts of incremental updates (throttled).\n\n6) Watcher Setup\n   - chokidar.watch(path.join(projectRoot, 'tasks'), { ignoreInitial: false, depth: 3, ignored: ['**/node_modules/**', '**/.git/**', '**/.DS_Store'] })\n   - Handle addDir/removeDir for tasks/<id> creation/deletion; add/change/unlink for metadata files inside.\n   - Debounce per-task using a Map<taskId, timeout> with 150ms delay.\n\n7) IPC Wiring (main/ipc/tasks.ts)\n   - Register handlers in app ready:\n     - ipcMain.handle('tasks:list', async () => ({ tasks: indexer.getSummaries(), stats: indexer.getStats() }))\n     - ipcMain.handle('task:get', async (_evt, id: string) => indexer.getTask(id))\n   - Export a function registerTasksIpc(indexer: TaskIndexer) to be called from main bootstrap.\n\n8) Bootstrap Integration\n   - In main process startup, when project root is selected/changed, instantiate TaskIndexer(root); call init(); registerTasksIpc(indexer).\n   - On root change, dispose previous indexer and create a new one.\n\n9) Performance Measurement & Documentation\n   - Record lastFullScanMs and taskCount on each scan; maintain an average over the last N scans.\n   - Add logs (debug) with counts and timings.\n   - Write docs/performance/tasks_indexer.md:\n     - How to run performance test\n     - Hardware/software environment\n     - Results for 100+ tasks (initial scan time, memory footprint estimate)\n\n10) Testing (Jest/Vitest)\n   - Create temp directory fixture with >120 tasks; generate task.json files with minimal fields.\n   - Test full scan finds all tasks and builds accurate summaries (featureCount, titles).\n   - Test watcher: create a new task dir -> expect new task in index after debounce; modify task.json title -> expect updated summary; delete task dir -> expect removal.\n   - Test performance: measure scan duration and assert within a reasonable bound (use generous threshold to avoid flakiness, but record measured value).\n   - Test malformed files: invalid JSON/YAML -> no crash, logs warning, task omitted or minimal fallback from README.md.\n   - Test disk cache: prewrite a cache file, init indexer, verify summaries served quickly prior to full scan.\n\n11) Observability & Logging\n   - Centralize logs in TaskIndexer with levels (info/debug/warn) using existing logging utility if present.\n   - Include counts and timings in info logs after scans.\n\n12) Configuration\n   - Expose optional configuration:\n     - TASKS_INDEXER_MAX_CONCURRENCY (default 10)\n     - TASKS_WATCH_DEBOUNCE_MS (default 150)\n     - TASKS_CACHE_WRITE_MS (default 2000)\n     - TASKS_DISABLE_DISK_CACHE (default false)\n   - Read from env or app config service.\n\n13) Security & Safety\n   - Sanitize and normalize projectRoot; ensure all watched paths are within projectRoot/tasks.\n   - Escape/sanitize IDs derived from directory names (use directory basename as ID, no path traversal).\n\n14) Acceptance Mapping\n- Indexing handles 100+ tasks: Verified by tests with 120+ generated tasks and documented timings.\n- Watcher reliably updates on file changes: Unit/integration tests simulate add/modify/delete and validate index updates.\n- Performance measured and documented: perf_hooks instrumentation and docs/performance report.\n- Exposed via IPC: tasks:list and task:get implemented and wired in main process.\n\n15) Future Enhancements (not required now)\n- Live push updates to renderer via IPC events on index changes.\n- Schema evolution handling with versioning.\n- Additional parsers (e.g., TOML) and richer feature directory structures.\n- Indexed search across task titles/descriptions via minisearch or lunr.\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.7",
      "status": "-",
      "title": "Tasks list UI with filtering and search",
      "description": "Build a React view listing tasks with id, title, status, and counts of features (done/total). Provide text search and filters (e.g., status). Clicking a row opens details. Acceptance: Renders list from IPC data; filtering/search applied client-side; empty states handled; accessibility basics (labels, keyboard nav) covered.",
      "plan": "Implementation Plan: Tasks list UI with filtering and search (Feature 5.7)\n\nAssumptions\n- Project uses Electron (main + preload) and React + TypeScript in renderer.\n- There is/will be an IPC surface to fetch tasks from the main process. If not present, we will add it here.\n- React Router is used (or can be added) for navigation to a Task Details view.\n\n1) Define shared types\n- Create shared/types/tasks.ts with the minimal shape required by this feature:\n  export type TaskStatus = 'todo' | 'in_progress' | 'blocked' | 'done'\n  export interface TaskSummary {\n    id: string\n    title: string\n    status: TaskStatus\n    features: { done: number; total: number }\n  }\n- If a shared folder is not available, duplicate the type in both main and renderer temporarily with TODO to consolidate.\n\n2) IPC: main process handlers\n- In main/src/ipc/tasks.ts (or similar):\n  - Register ipcMain.handle('tasks:get', async () => Promise<TaskSummary[]>)\n  - Implementation can read from the existing task source. If not available yet, stub with an in-memory mock returning an array of TaskSummary.\n- Export a small tasksService.listSummaries() to keep main code clean; later it can be wired to real data (git/agents).\n\n3) Preload bridge\n- In preload/index.ts, expose tasks API via contextBridge:\n  type TasksAPI = { getTasks: () => Promise<TaskSummary[]> }\n  contextBridge.exposeInMainWorld('tasksAPI', {\n    getTasks: () => ipcRenderer.invoke('tasks:get')\n  })\n- Add global typing for window.tasksAPI in renderer/src/types/global.d.ts to ensure TS safety.\n\n4) Renderer: API wrapper\n- Create renderer/src/api/tasks.ts:\n  export async function getTasks(): Promise<TaskSummary[]> { return window.tasksAPI.getTasks() }\n\n5) Routing: ensure details route exists\n- Add a route /tasks and /tasks/:id in the router if not already present.\n- Create a placeholder TaskDetailsPage that reads :id and displays basic info (can be expanded by another feature).\n\n6) UI structure and components\n- Create renderer/src/pages/TasksPage/ with components:\n  - TasksPage.tsx: page container and state management\n  - TaskFilters.tsx: search input + status checkboxes\n  - TaskList.tsx: renders list + empty/loading/error states\n  - TaskRow.tsx: individual row\n- Style with existing styling system (CSS Modules/Tailwind) or minimal CSS module for layout and badges.\n\n7) State and data flow in TasksPage\n- Local state: tasks (TaskSummary[]), loading, error, searchQuery (string), selectedStatuses (Set<TaskStatus>)\n- useEffect(() => { loadTasks() }, []) where loadTasks calls getTasks(), sets loading/error accordingly.\n- Derived filteredTasks computed via useMemo from tasks, searchQuery, selectedStatuses.\n  - Search: case-insensitive substring match on id and title.\n  - Filters: include task if selectedStatuses is empty OR selectedStatuses has task.status.\n\n8) Filters UI (TaskFilters)\n- Accessible search input:\n  - <label htmlFor=\"task-search\">Search tasks</label>\n  - <input id=\"task-search\" type=\"search\" value={searchQuery} onChange=... placeholder=\"Search by id or title\" />\n  - Clear button (type=button) that resets searchQuery when visible.\n- Status filter group:\n  - Wrap in <fieldset><legend>Status filters</legend> ...</fieldset>\n  - Checkboxes for each status: Todo, In progress, Blocked, Done\n  - Maintain selectedStatuses via onChange toggling.\n\n9) List and Empty/Loading/Error states (TaskList)\n- Loading: show skeleton rows (e.g., 5 gray bars with aria-hidden) and aria-live polite message \"Loading tasks\u2026\".\n- Error: show message \"Could not load tasks\" and a Retry button that calls loadTasks.\n- Empty states:\n  - If tasks length === 0 after load: \"No tasks available yet.\"\n  - If filteredTasks length === 0 but tasks > 0: \"No tasks match your search/filters\" with a Clear filters button to reset search and filters.\n- Render count summary with aria-live: \"Showing X of Y tasks\".\n\n10) TaskRow content and semantics\n- Each row rendered as a button-like element for keyboard activation while preserving list semantics:\n  - <li><button className=\"row\" onClick={openDetails} onKeyDown={handleKeyDown} aria-label={`Open task ${id}: ${title}`}> ... </button></li>\n- Display:\n  - Left: monospaced id\n  - Middle: title (truncate with ellipsis)\n  - Right: status badge with color + Features: done/total\n- Provide title attribute with full title for hover.\n\n11) Navigation behavior\n- openDetails navigates to /tasks/{id} using useNavigate from React Router.\n- handleKeyDown supports Enter/Space to open; Up/Down arrow optional (see step 12).\n\n12) Keyboard navigation\n- Default Tab navigation is sufficient; enhance with optional roving tabindex for arrow up/down among rows:\n  - Maintain focusedRowIndex state; on ArrowUp/ArrowDown, move focus to previous/next row button.\n  - Ensure no keyboard trap; Esc does nothing.\n\n13) Accessibility\n- Ensure labels for search and filters; fieldset/legend for checkbox group.\n- Buttons have accessible names; list has role=list and each row role=listitem (implicit via li).\n- Use aria-live=\"polite\" for result count updates.\n- Status badges must pass color contrast (use text + background choices accordingly).\n- Focus outline visible for interactive elements.\n\n14) Performance considerations\n- For now, simple list rendering; add react-window virtualization only if list size > ~500 in future tasks.\n- useMemo for filteredTasks to avoid unnecessary re-computation when typing.\n\n15) Testing\n- Unit tests (renderer) for filter function with cases: search only, status only, combined, empty, case-insensitive.\n- Component tests with React Testing Library:\n  - Renders from mocked API data and shows correct counts and rows.\n  - Search narrows results; clearing restores.\n  - Status filters work (single and multiple selections).\n  - Empty states render appropriately.\n  - Keyboard: Enter/Space triggers navigation; Tab focus order correct.\n  - Basic a11y using jest-axe (no violations for the page core flow).\n\n16) Type safety and linting\n- Strongly type IPC payloads and window.tasksAPI. Ensure no any leaks.\n- Add eslint rules for accessibility (jsx-a11y) if not already present.\n\n17) Visual polish\n- Status badge styles: todo (gray), in_progress (blue), blocked (red), done (green).\n- Monospace for IDs, truncate long titles, consistent spacing.\n\n18) Documentation\n- docs/ui/tasks-list.md: overview, data shape, IPC contract, component responsibilities, a11y notes, and testing strategy.\n\n19) Integration checklist (acceptance criteria mapping)\n- Renders list from IPC data: Verify getTasks IPC wired and list displays items.\n- Filtering/search applied client-side: Verify search and status filters adjust the derived list without re-fetch.\n- Empty states handled: No data, no matches, error, and loading states exist and are readable.\n- Accessibility basics covered: Labels, fieldset/legend, focus, keyboard activation, aria-live counts, contrast for badges.\n\n20) Optional: live updates hook (future)\n- Outline but do not implement now: an IPC event 'tasks:updated' + preload onUpdated(callback) to refresh list when tasks change.\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.8",
      "status": "-",
      "title": "Task details view with feature list and editing notes/fields",
      "description": "Create a detail page showing the task metadata and its features with statuses. Implement controlled editing for permitted fields (e.g., description, notes, status) with schema validation and disk write-back via task:update IPC. Provide change preview and basic error handling. Acceptance: Edits persist to task.json on disk, schema-valid; changes reflected in UI and index; guard rails prevent schema-breaking updates; unit/e2e tests simulate common edits.",
      "plan": "Implementation Plan: Task details view with feature list and editing notes/fields\n\n1) Data model and validation\n1.1 Define a canonical task schema in a shared module\n    - Create src/shared/schemas/task.ts using Zod (or Ajv if preferred) to describe the full task JSON shape.\n      Example (adjust to existing project fields if present):\n        const TaskStatus = z.enum([\"todo\",\"in-progress\",\"blocked\",\"done\"]);\n        const Feature = z.object({ id: z.string(), title: z.string(), status: TaskStatus, description: z.string().optional(), acceptance: z.string().optional() });\n        export const TaskSchema = z.object({\n          id: z.string(),\n          title: z.string(),\n          status: TaskStatus,\n          description: z.string().default(\"\"),\n          notes: z.string().default(\"\"),\n          priority: z.string().optional(),\n          features: z.array(Feature).default([]),\n          // ...add other known metadata with safe defaults\n        });\n        export type Task = z.infer<typeof TaskSchema>;\n    - Define AllowedEditableFields = [\"description\", \"notes\", \"status\"].\n    - Export a helper validateTask(data): { ok: boolean; value?: Task; error?: string }.\n\n1.2 Stable JSON formatting utility\n    - Add src/shared/json.ts with export function stableStringify(obj) using JSON.stringify(obj, null, 2) for consistent diffs.\n\n2) Main process: tasks service and IPC\n2.1 Tasks service for read/write\n    - Create src/main/services/tasks.ts with functions:\n      - getTaskPath(id: string): string \u2013 resolve to tasks/<id>/task.json (or pull from config).\n      - readTask(id: string): Promise<{ task: Task; version: { mtimeMs: number; hash: string } }>\n        \u2022 Read JSON, parse, validate with TaskSchema.\n        \u2022 Compute version: mtimeMs from fs.stat and hash via sha256(stringified file).\n      - updateTask(id: string, changes: Partial<Pick<Task, typeof AllowedEditableFields[number]>>, baseVersion: { mtimeMs: number; hash: string }): Promise<{ task: Task }>\n        \u2022 Read current file and version.\n        \u2022 Concurrency guard: if current.hash !== baseVersion.hash or mtime differs beyond tolerance, throw { code: 'VERSION_CONFLICT' }.\n        \u2022 Whitelist: Filter changes to AllowedEditableFields only; type-check each value.\n        \u2022 Merge: const next = { ...current, ...filteredChanges }.\n        \u2022 Validate next with TaskSchema; if invalid, throw { code: 'VALIDATION_ERROR', details }.\n        \u2022 Atomic write: write to tmp file (path + \".tmp\") with stableStringify, fs.rename to target; optionally create a .bak first if desired.\n        \u2022 Return updated task.\n\n2.2 IPC channels\n    - In src/main/ipc/tasks.ts register handlers in app ready:\n      - ipcMain.handle('task:get', async (_, { id }) => readTask(id))\n      - ipcMain.handle('task:update', async (_, { id, changes, baseVersion }) => {\n          try { const { task } = await updateTask(id, changes, baseVersion); \n                win.webContents.send('tasks:updated', { id, task });\n                return { ok: true, task }; \n          } catch (e) { return { ok: false, error: serializeIpcError(e) }; }\n        })\n    - Implement serializeIpcError to map codes: VERSION_CONFLICT, VALIDATION_ERROR, FS_ERROR.\n\n3) Renderer: routing and data access\n3.1 Route\n    - Add route /tasks/:id to the React Router. Create pages/TaskDetailsPage.tsx.\n\n3.2 IPC client helpers\n    - Add src/renderer/ipc/tasks.ts:\n      - getTask(id): invoke('task:get', { id }).\n      - updateTask(id, changes, baseVersion): invoke('task:update', { id, changes, baseVersion }).\n      - subscribeUpdated(cb): ipcRenderer.on('tasks:updated', cb) (cleanup on unmount).\n\n4) UI: Task details page\n4.1 Layout\n    - Header: task title, ID, and editable Status select (restricted to enum values).\n    - Metadata section: show non-editable fields (priority, etc.).\n    - Description: Markdown editor textarea with live preview toggle; sanitize with DOMPurify on preview.\n    - Notes: Simple textarea (or Markdown too if desired) with preview toggle.\n    - Features list: read-only table/list of features with their statuses; show badge colors by status.\n    - Actions: Save, Cancel, and a \"Preview changes\" button to open a modal showing diffs.\n\n4.2 State management\n    - Fetch on mount: const { task, version } = await getTask(id); keep originalTaskRef and baseVersionRef.\n    - Local form state: use React state or react-hook-form; initialize with task fields.\n    - Dirty tracking: compute isDirty by shallow comparing editable fields to original. Prompt on route change/close if dirty (beforeunload and router blocker).\n\n4.3 Change preview modal\n    - Build a list of field diffs only for AllowedEditableFields that changed.\n    - For text fields (description, notes): show side-by-side or inline unified diff (use diff-match-patch or fast-diff) plus a Markdown-rendered preview of new content.\n    - For status: show from -> to.\n\n4.4 Save flow\n    - Build changes object with only fields that differ and pass baseVersion from initial load.\n    - Call updateTask via IPC; on success:\n      \u2022 Update originalTaskRef and baseVersionRef using result of a fresh getTask(id) (or use returned task and recompute version with a subsequent get if needed).\n      \u2022 Update local state to match saved task.\n      \u2022 Emit toast \"Task saved\" and close preview modal if open.\n      \u2022 Let tasks list or other views update via 'tasks:updated' event in their stores.\n    - On error:\n      \u2022 VERSION_CONFLICT: show modal explaining file changed externally; options: Reload (discard edits), Overwrite anyway (disable for this feature, or allow via forcing update by skipping version check \u2014 keep it out-of-scope to stay safe), Copy my edits to clipboard.\n      \u2022 VALIDATION_ERROR: highlight offending fields and show message.\n      \u2022 FS_ERROR: show retry/cancel.\n\n4.5 Guard rails in UI\n    - Only render controls for AllowedEditableFields.\n    - Enforce enum for status.\n    - Limit description/notes length with soft max (e.g., 100k chars) to avoid huge writes.\n    - Sanitize markdown preview.\n\n5) Index/list synchronization\n    - Wherever the task index is shown, subscribe to 'tasks:updated' and update the in-memory store for that id.\n    - Verify that after saving, the index reflects new status/description snippet.\n\n6) Testing\n6.1 Unit tests (Jest)\n    - task schema: accepts valid tasks; rejects invalid statuses; defaults missing description/notes/features.\n    - tasks service updateTask:\n      \u2022 Applies only whitelisted fields; rejects extra keys.\n      \u2022 Fails on version conflict; succeeds after reread.\n      \u2022 Validates and writes atomically (use memfs or tmp dirs; verify final file contents).\n    - IPC handlers: return shapes { ok: true/false } and map errors correctly.\n\n6.2 Component tests (React Testing Library)\n    - TaskDetailsPage renders metadata, features list, and editable fields.\n    - Editing description toggles dirty state and enables Save.\n    - Preview modal shows correct diffs for text and status.\n    - On save success, dirty state clears and toast appears.\n    - Validation error displays correctly (mock IPC).\n\n6.3 E2E tests (Playwright or Spectron)\n    - Launch app with a fixture project containing a sample task.json.\n    - Navigate to Task details; modify description and status; open preview; save; verify disk file content changed and index view shows updated status.\n    - Simulate external change (modify file between load and save) and verify conflict handling dialog.\n\n7) Implementation details and utilities\n7.1 Hashing and versioning\n    - Use node:crypto createHash('sha256').update(fileContents).digest('hex').\n    - Store and pass both mtimeMs and hash, but rely on hash for conflict decision.\n\n7.2 Atomic write helper\n    - writeAtomic(path, contents): write to path + '.tmp', fs.fsync, rename to path. Optionally keep a .bak on first write in dev.\n\n7.3 Markdown rendering\n    - Use markdown-it or marked in renderer; sanitize with DOMPurify; allow code highlighting if available.\n\n7.4 Error mapping\n    - Standardize IPC error payload: { code, message, details? } and avoid exposing stack traces in renderer.\n\n8) Documentation\n    - Add docs/dev/task-details.md covering:\n      \u2022 Task schema and editable fields\n      \u2022 IPC contract for task:get and task:update\n      \u2022 Concurrency behavior\n      \u2022 How to add a new editable field safely\n      \u2022 Testing instructions\n\n9) Acceptance checklist mapping\n    - Edits persist to task.json on disk: Verified via unit (memfs) and e2e (real file) tests.\n    - Schema-valid: Main process validates with TaskSchema; tests cover invalid updates.\n    - Changes reflected in UI and index: 'tasks:updated' event updates stores; e2e asserts list shows new status.\n    - Guard rails prevent schema-breaking updates: Whitelist in main, enum constraints in UI and validator; unit tests cover.\n    - Unit/e2e tests simulate common edits: Description/notes/status success; invalid status fail; version conflict path.",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.9",
      "status": "-",
      "title": "Markdown documentation explorer and renderer",
      "description": "Implement a docs browser that lists Markdown files under docs/ (including docs/tasks/*). Render Markdown with basic extensions (tables, code highlighting), safe HTML sanitization, and internal link navigation. Acceptance: Sidebar shows directory tree; renderer supports anchors and code blocks; clicking internal links navigates within the app; large files render efficiently; tested with provided docs/*.md.",
      "plan": "Title: Markdown documentation explorer and renderer (Feature 5.9)\n\nGoal\nImplement a docs browser that lists Markdown files under docs/ (including docs/tasks/*), renders them safely and efficiently with anchors and code highlighting, and supports internal link navigation within the app.\n\nHigh-Level Architecture\n- Main process: Filesystem service (list/read/watch docs), exposes IPC channels.\n- Preload script: Safe API surface via contextBridge for renderer to list/read docs, subscribe to changes, and open external links.\n- Renderer (React):\n  - DocsPage: Layout with Sidebar (directory tree) + Content (Markdown renderer).\n  - DocsTree: Renders file/directory tree; selects files.\n  - MarkdownRenderer: Renders content using react-markdown + remark/rehype plugins, sanitization, and code highlighting; handles internal link navigation and anchors.\n- Performance: Markdown parsing in a Web Worker with LRU cache keyed by file path + mtime; lazy code highlighting; avoid re-parsing unchanged files.\n\nDetailed Steps\n1) Setup file system service in the main process\n   1.1 Create src/main/services/docsService.ts:\n       - Config: const DOCS_ROOT = path.join(appConfig.projectRoot, \"docs\"). Ensure it includes docs/ and docs/tasks/ by default.\n       - listDocsTree(root: string): Recursively read files and directories under DOCS_ROOT, filter for .md and directories, return a normalized tree structure: { type: 'dir'|'file', name, relPath, children? } using posix-style relPath.\n       - readDocFile(relPath: string): Validate that the resolved path is within DOCS_ROOT. Return { content, mtimeMs }.\n       - watchDocs(cb): Use chokidar to watch DOCS_ROOT for add/change/unlink events on .md files and directory add/remove. Debounce and emit a summary event { type, relPath }.\n   1.2 Add IPC channels in src/main/ipc/docsIpc.ts:\n       - 'docs:listTree' -> returns listDocsTree(DOCS_ROOT)\n       - 'docs:read' (relPath) -> returns readDocFile(relPath)\n       - 'docs:watch' -> uses event.sender to send push events 'docs:changed' with changed relPath and type.\n       - Ensure robust error handling and path traversal protection.\n\n2) Expose safe APIs via preload script\n   2.1 In src/preload/index.ts add:\n       - contextBridge.exposeInMainWorld('docs', {\n           listTree: () => ipcRenderer.invoke('docs:listTree'),\n           read: (relPath: string) => ipcRenderer.invoke('docs:read', relPath),\n           onChanged: (handler: (evt) => void) => ipcRenderer.on('docs:changed', (_, payload) => handler(payload))\n         })\n       - contextBridge.exposeInMainWorld('shell', {\n           openExternal: (url: string) => ipcRenderer.invoke('shell:openExternal', url)\n         })\n   2.2 In main process, handle 'shell:openExternal' via shell.openExternal and validate allowed protocols (http/https/mailto).\n   2.3 Ensure Electron security: contextIsolation: true, nodeIntegration: false, enableRemoteModule: false.\n\n3) Data models and utilities in the renderer\n   3.1 Define types in src/renderer/types/docs.ts:\n       - DocNode = { type: 'dir'|'file', name: string, relPath: string, children?: DocNode[] }\n   3.2 Path utilities src/renderer/utils/docsPath.ts:\n       - resolveLink(currentRelPath: string, href: string): returns { targetRelPath?: string, hash?: string, externalUrl?: string }\n         \u2022 If href starts with http(s):// -> externalUrl\n         \u2022 If href starts with # -> stay on currentRelPath + hash\n         \u2022 Else resolve posix path relative to dirname(currentRelPath). Remove leading './'. Normalize .. segments. Handle links with or without .md extension by accepting both forms; if target points to a directory read default index.md if present.\n       - isInsideDocs(relPath)\n   3.3 Tree helpers src/renderer/utils/tree.ts:\n       - buildIndex(tree): Map relPath -> node\n       - findDefaultDoc(tree): First occurrence priority: docs/README.md, docs/index.md, else lexicographically first .md file.\n\n4) UI: DocsPage and routing\n   4.1 Add React Router route /docs/*.\n   4.2 Represent current selection in the URL as /docs/<encodedRelPath>[#hash]. Use encodeURIComponent on each path segment to avoid issues. Example: /docs/AGENT_PLANNER.md#workflow\n   4.3 DocsPage layout in src/renderer/pages/DocsPage.tsx:\n       - Left: Sidebar with resizable SplitPane (optional). Renders DocsTree.\n       - Right: MarkdownRenderer with loading and error states.\n       - On mount: fetch listTree via window.docs.listTree(). Build index and choose default document if URL has none.\n       - Subscribe to window.docs.onChanged to refresh tree and reload currently open file if it changed.\n       - When the route changes (file or hash), reload content if file changed and scroll to anchor if hash present.\n\n5) Sidebar: DocsTree component\n   5.1 Component src/renderer/components/docs/DocsTree.tsx:\n       - Props: tree, selectedRelPath, onSelect(relPath)\n       - Render collapsible tree with directories and files; highlight selected file; keyboard navigation (optional but simple arrow/enter handling if time allows).\n       - Sorting: directories first then files, each alphabetical case-insensitive.\n       - For large trees (>500 nodes), consider react-window for virtualization; otherwise lazily expand directories to limit render cost.\n   5.2 Search filter (optional for now). Keep out of scope unless trivial.\n\n6) MarkdownRenderer component with plugins, sanitization, and internal navigation\n   6.1 Component src/renderer/components/docs/MarkdownRenderer.tsx:\n       - Props: relPath, content, onNavigate(relPath, hash), onExternal(url)\n       - Use react-markdown with:\n         \u2022 remark-gfm for tables, strikethrough, task lists.\n         \u2022 rehype-slug to add id attributes to headings for anchors.\n         \u2022 rehype-autolink-headings with behavior 'append' and a small anchor link icon. Use tabindex and aria-label for a11y.\n         \u2022 rehype-sanitize with a custom schema allowing safe tags/attrs for headings, code, pre, table, thead, tbody, tr, th, td, a[href|title|target|rel], img[src|alt|title] but disallow inline event handlers, scripts, iframes. Restrict target/rel to safe values rel=\"noopener noreferrer\".\n         \u2022 Code highlighting: use refractor + rehype-prism-plus OR rehype-highlight. Prefer refractor + rehype-prism-plus for broad language support. Dynamically import languages on demand to keep bundle size small.\n       - Link handling:\n         \u2022 Provide a custom <a> renderer or use rehype options to intercept link nodes. For click events, call resolveLink(currentRelPath, href). If external -> onExternal(url). If internal .md or hash -> preventDefault and call onNavigate(newRelPath, hash).\n         \u2022 Ensure middle-click and modifier-click open external links in system browser; for internal links, support ctrl/cmd-click to open in a new in-app tab is out-of-scope; for now treat as normal navigation.\n       - Image handling:\n         \u2022 Resolve relative image paths relative to the current file directory. Provide a custom transform to create file:// paths via a secure IPC that reads files as data URLs if necessary; alternatively allow images to be loaded via a sanitized file protocol handler restricted to DOCS_ROOT.\n         \u2022 For this iteration, if images are not required by acceptance, keep images support minimal but safe (sanitized src limited to relative within docs/; deny http(s) to avoid mixed content).\n       - Anchors scrolling:\n         \u2022 useEffect to detect hash; after render, find element by id and call element.scrollIntoView({ block: 'start' }). Debounce to allow render to complete.\n       - Copy link to heading: Add a small anchor icon appended by rehype-autolink-headings; clicking copies current route with #id to clipboard (nice-to-have; optional).\n\n7) Data loading and caching\n   7.1 Create DocsStore (React context or simple hooks) src/renderer/stores/docsStore.ts:\n       - State: tree, index, selectedRelPath, selectedContent, selectedMtimeMs.\n       - Methods: loadTree(), loadFile(relPath), select(relPath, hash)\n       - Default selection: findDefaultDoc(tree)\n   7.2 LRU cache for parsed Markdown AST (or compiled React nodes) keyed by relPath + mtimeMs in src/renderer/utils/markdownCache.ts. Cache size 10-20 entries.\n   7.3 Web Worker for parsing markdown:\n       - Create src/renderer/workers/markdownWorker.ts with a bundler-friendly worker setup (Vite or Webpack worker-loader equivalent). Worker receives { content, options } and returns serialized Hast or HTML string plus metadata (headings, anchors). Use unified with remark/rehype plugins that can run in a worker (omit DOM-specific code). In main thread, use react-markdown for rendering or accept preprocessed syntax tree. If worker + react-markdown AST interop is complex, offload only expensive operations: slugification and tokenization for code; otherwise, defer worker until needed.\n       - For first implementation, implement main-thread parsing with memoization. Add worker as an enhancement if performance issues are observed with large files (>1 MB). Document upgrade path.\n\n8) Navigation integration with router\n   8.1 In DocsPage, on tree selection or internal link navigation, update URL via navigate(`/docs/${encodeRelPath(relPath)}${hash ? '#' + hash : ''}`).\n   8.2 Listen to location changes; when relPath changes, call loadFile and pass content to MarkdownRenderer. When hash changes, trigger scroll.\n   8.3 Maintain history so back/forward works natively.\n\n9) Performance considerations for large files\n   9.1 Avoid re-parsing unchanged content using mtime-based cache.\n   9.2 Defer code highlighting for large files: For files > 1 MB or with > 300 code fences, render without highlighting first, then progressively enhance code blocks using requestIdleCallback.\n   9.3 Ensure tree virtualization or lazy expansion prevents rendering thousands of nodes at once.\n   9.4 Debounce chokidar events to avoid thrashing.\n\n10) Security and sanitization\n   10.1 rehype-sanitize schema: Start from defaultSchema, extend to allow table elements and code/pre, allow className for Prism highlighting classes, restrict a[href] to http(s), mailto, and relative. Block javascript: URLs.\n   10.2 Electron: never enable nodeIntegration in renderer; all FS access via IPC; validate paths.\n   10.3 External links open via shell.openExternal with URL validation; add rel=\"noopener noreferrer\".\n\n11) Testing\n   11.1 Unit tests (Jest + Testing Library):\n       - resolveLink(): handles #hash, ../relative.md#h, links without .md, directory links -> index.md, external URLs detection.\n       - Sanitization: scripts stripped, on* attributes removed, only allowed tags/attrs preserved.\n       - Heading slug generation yields stable ids; anchors scroll function targets correct elements.\n   11.2 Integration tests (Playwright or Spectron/Playwright for Electron):\n       - Load DocsPage with docs/AGENT_PLANNER.md; verify sidebar tree shows docs and docs/tasks if present.\n       - Click sidebar item: content renders tables, code blocks with highlighting class present.\n       - Click internal link to a section (#): URL updates with hash and page scrolls to the heading.\n       - Click link to another .md file: renderer navigates, sidebar selection updates.\n       - External link opens in system browser (mock shell.openExternal call).\n       - Modify a file under docs/; watch triggers tree refresh and hot reload of the open doc.\n   11.3 Performance test: load a synthetically large .md (e.g., 2\u20135 MB) and assert render completes under a target time budget (e.g., < 1.5s on dev machine) with lazy highlighting toggle.\n\n12) UX polish\n   12.1 Loading states: skeleton or spinner in content area while loading.\n   12.2 Error states: file not found -> show friendly message and link back to default doc.\n   12.3 Remember last opened doc in localStorage and restore on app reopen.\n   12.4 Keyboard shortcuts: up/down to move in tree, enter to open (optional).\n\n13) Documentation\n   13.1 Add docs/local-app/docs-browser.md explaining usage, security model, and how to add docs.\n   13.2 Developer README section: API contracts for docs IPC, how to extend sanitization, how to add languages for code highlighting.\n\n14) Acceptance criteria mapping\n   - Sidebar shows directory tree: Implemented via DocsTree fed by listDocsTree including docs/tasks/*.\n   - Renderer supports anchors and code blocks: rehype-slug + rehype-autolink-headings + code highlighting with prism/refractor.\n   - Clicking internal links navigates within the app: resolveLink + router navigation + anchor scroll.\n   - Large files render efficiently: caching + deferred highlighting + optional worker; tested with synthetic large file.\n   - Tested with provided docs/*.md: Add tests specifically with docs/AGENT_PLANNER.md and any other provided docs.\n\n15) Tasks and file checklist\n   - src/main/services/docsService.ts\n   - src/main/ipc/docsIpc.ts\n   - src/preload/index.ts (expose docs API and shell)\n   - src/renderer/pages/DocsPage.tsx\n   - src/renderer/components/docs/DocsTree.tsx\n   - src/renderer/components/docs/MarkdownRenderer.tsx\n   - src/renderer/utils/docsPath.ts, tree.ts, markdownCache.ts\n   - src/renderer/stores/docsStore.ts\n   - src/renderer/workers/markdownWorker.ts (optional phase 2)\n   - tests/unit/docsPath.test.ts, sanitize.test.ts\n   - tests/integration/docsNavigation.spec.ts\n\n16) Dependencies\n   - react-markdown, remark-gfm, rehype-slug, rehype-autolink-headings, rehype-sanitize\n   - refractor, rehype-prism-plus (or rehype-highlight)\n   - chokidar (main process)\n   - react-router-dom\n   - react-window (optional) or simple lazy expansion\n   - testing-library/react, jest, Playwright\n\n17) Rollout plan\n   - Phase 1: Basic tree + rendering with sanitization, anchors, code highlighting, internal link navigation.\n   - Phase 2: Performance enhancements (cache, deferred highlight, optional worker), file watching, polish.\n   - Phase 3: Integration tests and docs.\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.10",
      "status": "-",
      "title": "Read-only Git status panel",
      "description": "Expose project Git status via IPC by invoking the git CLI or a lightweight library. Show current branch, ahead/behind, changed files, and submodule summary. No write operations from this panel. Acceptance: Works across platforms; handles repositories with submodules; performance acceptable; unit tests stub git outputs; UI displays clear status indicators.",
      "plan": "Read-only Git Status Panel (Feature 5.10) \u2013 Implementation Plan\n\nGoal: Expose project Git status via IPC using the git CLI (no write operations). Display current branch, ahead/behind, changed files, and submodule summary. Must be cross-platform, handle submodules, perform acceptably, include unit tests with stubbed git outputs, and provide a clear UI.\n\n1) Scope and approach\n   - Use git CLI via child_process.execFile for portability and no extra deps. Avoid shell execution; use execFile to prevent injection and ensure cross-platform behavior.\n   - Use porcelain v2 status and submodule status for robust, parsable output.\n   - Read-only only: do not call any git write operations; restrict to read-only commands.\n\n2) Data model (TypeScript types)\n   - types/git.ts:\n     - GitStatus {\n         repoRoot: string,\n         isRepo: boolean,\n         branch?: string,\n         upstream?: string,\n         ahead: number,\n         behind: number,\n         detached: boolean,\n         changes: GitChange[],\n         counts: { staged: number, unstaged: number, untracked: number, conflicted: number },\n         submodules: SubmoduleStatus[],\n         lastUpdated: number,\n         errors?: string[]\n       }\n     - GitChange { path: string, origPath?: string, indexStatus: string, worktreeStatus: string, renameScore?: number }\n       - indexStatus and worktreeStatus use git's two-letter XY codes (M,A,D,R,C,U,?,!)\n     - SubmoduleStatus { path: string, commit: string, status: 'clean'|'modified'|'uninitialized'|'conflicted', headInfo?: string }\n\n3) Git command helpers (main process)\n   - src/main/git/cli.ts:\n     - resolveRepoRoot(cwd): runs `git rev-parse --show-toplevel` to confirm repo and root. If not a repo, return { isRepo: false }.\n     - getPorcelainStatus(repoRoot): `git -C <repoRoot> status --porcelain=v2 -b -z` (null-separated for robust parsing). Parse:\n       - Branch lines beginning with `# `: extract branch name, upstream, and ahead/behind from `# branch.ab +X -Y` if present.\n       - Entry lines:\n         - `1 <XY> ...\\t<path>` for regular entries.\n         - `2 <XY> ...\\t<path>\\t<origPath>` for renames/copies.\n         - `? <path>` for untracked.\n         - `u <...>` for unresolved conflicts.\n       - Produce GitChange[] and counts.\n     - getSubmoduleStatus(repoRoot):\n       - If no .gitmodules, return empty list.\n       - Run `git -C <repoRoot> submodule status --recursive`.\n       - Parse prefix char: ' ' (clean/at expected), '-' (uninitialized), '+' (modified/detached), 'U' (conflicted). Extract commit sha, path, and trailing parenthetical info as headInfo.\n     - combineStatus(repoRoot): run porcelain status and submodule status in parallel, merge into GitStatus, set lastUpdated=Date.now().\n     - git availability check: on first call, try `git --version`. If missing, set error in result.\n     - Options for execFile: { cwd: repoRoot, windowsHide: true, maxBuffer: 10*1024*1024, env: { ...process.env, LC_ALL: 'C' } }. Use execFile('git', ['-C', repoRoot, ...]) to avoid path issues.\n\n4) Performance and update strategy (main process)\n   - src/main/git/statusService.ts:\n     - getStatus(repoPath): resolves repoRoot then calls combineStatus(repoRoot).\n     - watchStatus(repoPath, onUpdate):\n       - Use chokidar to watch `${repoRoot}/.git/**/*` and `.gitmodules` if present.\n       - Debounce updates (e.g., 500\u20131000ms) to avoid thrashing.\n       - Also poll every 5s as a fallback (configurable), and trigger on app focus.\n       - Throttle concurrent runs; if an update is in flight, coalesce.\n     - Ensure submodule watch trigger: also watch .gitmodules and submodule directories under repoRoot if feasible; otherwise rely on periodic poll for submodule changes.\n\n5) IPC wiring\n   - src/main/ipc/gitIpc.ts:\n     - Channels:\n       - 'git:getStatus' (request): args { repoPath: string }. Returns Promise<GitStatus>.\n       - 'git:subscribeStatus' (request): args { repoPath: string }. Registers watcher and starts emitting 'git:status' events per window with payload GitStatus.\n       - 'git:unsubscribeStatus' (request): stops watcher for that window/repo.\n   - src/preload/index.ts:\n     - Expose via contextBridge: window.api.git = {\n         getStatus(repoPath: string): Promise<GitStatus>,\n         subscribeStatus(repoPath: string, cb: (s: GitStatus) => void): () => void\n       }\n     - Ensure only these functions are exposed, no write capabilities.\n\n6) React UI (renderer)\n   - Components under src/renderer/git/:\n     - GitStatusPanel.tsx: Fetches initial status with getStatus, subscribes for updates; shows loading, error, empty states.\n     - SummaryHeader.tsx: Displays branch name (or Detached HEAD), upstream, ahead/behind with up/down arrows, counts (staged/unstaged/untracked/conflicted). Last updated timestamp. Manual Refresh button.\n     - ChangesList.tsx: Read-only list of files with badges (Staged/Unstaged/Untracked/Conflicted), status letters, and rename info.\n     - SubmodulesList.tsx: Collapsible section for submodules with status chip: Clean/Modified/Uninitialized/Conflicted and commit short sha and headInfo.\n   - UX:\n     - Clear indicators, tooltips explaining status symbols.\n     - No click actions (read-only). Disabled cursor for items.\n     - If not a git repo or git not installed, show friendly message with guidance.\n\n7) Cross-platform considerations\n   - Use execFile with '-C' option to avoid shell and path quoting issues.\n   - Ensure code handles Windows paths via Node path utilities; do not parse paths by splitting on '/'. Use the null-terminated output to safely separate file paths.\n   - Allow user-configurable git binary path in app settings if PATH lookup fails (future work; for now detect and show error with instruction).\n\n8) Error handling\n   - Gracefully handle:\n     - Not a git repo (rev-parse fails): isRepo=false; UI shows message.\n     - No upstream configured: display branch, ahead/behind=0, omit upstream label.\n     - Detached HEAD: display 'DETACHED' badge.\n     - Git not found: show error banner with install instructions.\n   - Collect non-fatal parse issues into errors[] for debugging.\n\n9) Unit tests (stubbed git outputs)\n   - Test framework: Vitest or Jest for main process modules; React Testing Library for renderer.\n   - Fixtures in tests/fixtures/git/: sample outputs for:\n     - Porcelain v2 with upstream and ahead/behind.\n     - No upstream.\n     - Detached HEAD.\n     - Mixed changes: staged, unstaged, untracked, rename (2-lines), conflicts.\n     - Submodule status: clean, modified (+), uninitialized (-), conflicted (U), recursive multiple entries.\n   - Mock child_process.execFile to return fixture outputs and verify parsers create correct GitStatus.\n   - Test debounce logic with fake timers to ensure at-most-one update per window when multiple FS events occur.\n   - Renderer: snapshot/basic render tests for GitStatusPanel given mocked IPC responses, verify badges and counts render.\n\n10) Performance validation\n   - One porcelain status call and one submodule status call per refresh.\n   - Debounce FS-triggered refreshes and limit periodic polling (default 5s), ensure UI remains responsive.\n   - Set maxBuffer high enough for large repos; verify no blocking of main thread (use async IPC execution).\n\n11) Security\n   - No write operations; whitelist commands used: `git --version`, `git rev-parse --show-toplevel`, `git status --porcelain=v2 -b -z`, `git submodule status --recursive`.\n   - Use execFile with explicit args; never interpolate user-provided strings into shell commands.\n   - IPC channels are namespaced under 'git:' and only expose read-only methods in preload.\n\n12) Developer docs\n   - README section: Git Status Panel\n     - Architecture overview (main service, IPC, renderer panel).\n     - Commands used and rationale.\n     - How to run tests and add new fixture cases.\n     - Known limitations and configuration for custom git binary path (if applicable).\n\n13) Implementation order\n   - Define types.\n   - Implement cli.ts parsers with unit tests using fixtures.\n   - Implement statusService.ts (getStatus/watch) and tests for debounce using mocks.\n   - Wire IPC and preload bridge.\n   - Build React UI components; hook into IPC; add basic renderer tests.\n   - Manual QA on macOS/Windows/Linux repos with and without submodules; measure responsiveness.\n   - Polish UI (tooltips, error messages), finalize docs.\n\n14) Acceptance checklist\n   - Cross-platform verified; status displays branch, ahead/behind, changed files breakdown.\n   - Submodule summary correctly shows status across recursive modules.\n   - No write operations performed.\n   - Performance acceptable: debounced updates, minimal CLI calls.\n   - Unit tests pass; parsers validated with stubbed outputs.\n   - UI shows clear, read-only status indicators and handles errors gracefully.",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.11",
      "status": "-",
      "title": "Agent process manager (start/stop/list, logs)",
      "description": "Implement process orchestration to run local agents via scripts/run_local_agent.py (or equivalent). Configurable Python interpreter path. Provide UI to start/stop agents, view running processes, and stream stdout/stderr logs with persistence. Acceptance: Start/stop works with sample agent; logs stream and are saved to file; broken interpreter path yields clear error; protected from multiple accidental starts; IPC: agents:list/start/stop/logs implemented.",
      "plan": "Agent Process Manager (start/stop/list, logs) - Implementation Plan\n\n1) Define agent model and discovery\n- Create config/agents.json describing available local agents (id, name, scriptPath, defaultArgs). Example:\n  [\n    { \"id\": \"sample\", \"name\": \"Sample Agent\", \"scriptPath\": \"scripts/run_local_agent.py\", \"defaultArgs\": [] }\n  ]\n- Future: add discovery by scanning a directory, but start with static file for deterministic behavior.\n\n2) Add dependencies and project structure\n- Dependencies (main): electron-store (persistent settings), fs-extra, nanoid, zod (for validating IPC args), readline (for line-by-line logs), node:events.\n- Optional: electron-log OR implement custom rotating logs later; for now, per-session file write streams are enough.\n- File structure additions:\n  - electron/main/config/store.ts\n  - electron/main/agents/processManager.ts\n  - electron/main/ipc/agents.ts\n  - electron/preload/index.ts (expose agents API)\n  - shared/types/agents.ts (TypeScript interfaces for IPC payloads)\n  - renderer/src/services/agents.ts\n  - renderer/src/hooks/useAgents.ts and useAgentLogs.ts\n  - renderer/src/components/AgentManager/{AgentList.tsx,AgentItem.tsx,AgentLogs.tsx,InterpreterSettings.tsx}\n  - config/agents.json\n  - scripts/run_local_agent.py (sample agent)\n\n3) Settings: Python interpreter path with validation\n- electron/main/config/store.ts: Use electron-store to persist settings under key app: { pythonPath: string }.\n- Implement resolvePythonPath(): precedence: stored path -> auto-detect candidates [\"python3\", \"python\", \"py\", \"py -3\"] using spawnSync to test -V.\n- Implement validatePythonPath(path): spawnSync(path, [\"-V\"]) and return either ok or descriptive error message (include stderr output).\n- Renderer UI: InterpreterSettings.tsx component to view/edit the Python interpreter path with buttons [Test], [Auto-detect], [Save]. Show clear errors when invalid.\n\n4) Main process: AgentProcessManager\n- electron/main/agents/processManager.ts exports a singleton AgentProcessManager with:\n  - Types: AgentId = string; Status = 'idle'|'starting'|'running'|'stopping'|'exited'|'error';\n  - ProcessInfo: { agentId, status, pid?, startedAt?, exitedAt?, exitCode?, signal?, proc?: ChildProcessWithoutNullStreams, logFilePath?: string, logStream?: fs.WriteStream, subscribers: Set<webContentsId>, sessionId: string }.\n  - Registry: Map<AgentId, ProcessInfo> and a set of locks to prevent duplicate starts.\n  - loadAgents(): read and cache agents.json, validate paths (script exists). Expose getAgents() returning {id,name,scriptPath,status,pid}.\n  - startAgent(agentId, extraArgs?):\n    - Guard: if status is 'starting'|'running' return AlreadyRunning error.\n    - Resolve and validate python path (from store). If invalid, throw error \"Python interpreter invalid\" with details.\n    - Build args: [scriptPath, ...defaultArgs, ...extraArgs]. Use spawn(pythonPath, args, { cwd: projectRoot, env: process.env, stdio: ['ignore','pipe','pipe'] }). Avoid shell to prevent injection.\n    - Update registry status to 'starting' then 'running' on 'spawn' event. Save pid.\n    - Logging: Create log directory: path.join(app.getPath('userData'), 'logs', 'agents', agentId). Create session file: ${Date.now()}-${pid}.log. Create fs.WriteStream with flags 'a'.\n    - Attach stdout/stderr with readline.createInterface to split lines; for each line:\n      - Append to log file with prefix: `[ts][stdout] line` or `[stderr]`.\n      - Emit IPC event to subscribers: 'agents:logs:data' with { agentId, ts, stream: 'stdout'|'stderr', line }.\n      - Keep in-memory ring buffer per agent of last N lines (e.g., 2000) for fast history.\n    - Handle errors: 'error' event -> set status 'error' and expose message; close streams safely; emit status update.\n    - Handle exit: 'close' -> set status 'exited', record code/signal, close log stream, notify subscribers.\n  - stopAgent(agentId, opts?):\n    - Guard: if not running -> return no-op or error.\n    - Set status 'stopping'. Try graceful termination:\n      - On POSIX: proc.kill('SIGINT'), wait up to 5s; if still alive, proc.kill('SIGTERM'), wait 3s; then force kill('SIGKILL').\n      - On Windows: try proc.kill(); if not exited, fallback to spawn('taskkill', ['/PID', pid, '/T', '/F']).\n    - Ensure registry updated on exit; ensure streams closed.\n  - subscribeLogs(agentId, webContentsId): add subscriber id to ProcessInfo.subscribers.\n  - unsubscribeLogs(agentId, webContentsId)\n  - getLogHistory(agentId, tail?: number, sinceTs?: number): return lines from in-memory ring buffer; optional: also read from latest session file if buffer empty.\n  - app lifecycle: on app.will-quit, stop all running agents gracefully; close all log streams.\n\n5) IPC and preload bridge (secure)\n- electron/preload/index.ts: expose window.api.agents with typed methods using contextBridge:\n  - list(): Promise<AgentSummary[]>  // id, name, status, pid\n  - start(agentId: string, extraArgs?: string[]): Promise<{ ok: true, pid: number } | { ok: false, error: string }>\n  - stop(agentId: string): Promise<{ ok: true } | { ok: false, error: string }>\n  - subscribeLogs(agentId: string, callback: (evt: LogEvent) => void): () => void  // returns unsubscribe\n  - getLogHistory(agentId: string, tail?: number): Promise<LogEvent[]>\n  - getSettings(): Promise<{ pythonPath?: string }>\n  - setPythonPath(path: string): Promise<{ ok: true } | { ok: false, error: string }>\n  - testPythonPath(path?: string): Promise<{ ok: true, version: string } | { ok: false, error: string }>\n- electron/main/ipc/agents.ts:\n  - Register ipcMain.handle('agents:list', ...) to return AgentSummary[].\n  - ipcMain.handle('agents:start', (evt, {agentId, extraArgs}))\n  - ipcMain.handle('agents:stop', ...)\n  - ipcMain.on('agents:logs:subscribe', (evt, {agentId})) -> store evt.sender.id as subscriber and immediately send history via evt.sender.send('agents:logs:history', ...)\n  - ipcMain.on('agents:logs:unsubscribe', ...)\n  - ipcMain.handle('agents:logs:getHistory', ...)\n  - Settings handlers: 'agents:settings:get', 'agents:settings:setPythonPath', 'agents:settings:testPythonPath'.\n- Security: Validate inputs with zod; whitelist channels in preload; no eval or shell.\n\n6) Renderer services and hooks\n- services/agents.ts: Thin wrapper around window.api.agents with TS types from shared/types/agents.\n- hooks/useAgents.ts: manage list, poll status every 2-3s or react to push notifications (optional add 'agents:status:update' events). Provide start/stop actions and loading/error states.\n- hooks/useAgentLogs.ts: given agentId, subscribe to logs on mount, expose logs[], methods: clearView(), fetchHistory(tail), autoScroll flag.\n\n7) UI components\n- AgentList.tsx: Displays agents from useAgents; for each agent show name, status pill (idle/running etc), PID if running, Start/Stop button. Disable start when running; show tooltip \"Already running\".\n- AgentItem.tsx: Single row; on Start -> call start(); on Stop -> call stop(). Show errors as toasts/snackbars.\n- AgentLogs.tsx: Text area or virtualized list to render log lines; color-code stdout (default) vs stderr (red). Controls: filter stderr/stdout, tail size, search, copy, auto-scroll toggle. On mount, fetch tail history (e.g., last 500 lines) and then stream.\n- InterpreterSettings.tsx: Input for Python path; buttons: Test, Auto-detect, Save. Show interpreter version if valid; show clear error if invalid.\n- Place these into a page: AgentManagerPage with 2-panel layout: list on left, logs on right.\n\n8) Sample agent for acceptance testing\n- scripts/run_local_agent.py:\n  - Prints a heartbeat line every second: \"[sample] working... {timestamp}\"; flush stdout.\n  - Writes occasional stderr lines for testing.\n  - Handles SIGINT/SIGTERM: print(\"Shutting down\"), sleep(0.5), exit 0.\n  - Cross-platform line buffering: use flush=True in print or sys.stdout.reconfigure(line_buffering=True).\n\n9) Error handling and UX\n- Broken interpreter path: startAgent should reject with error code 'INTERPRETER_NOT_FOUND' and a clear user-facing message: \"Python interpreter not found or invalid at '<path>'. Configure a valid path in Settings. Details: <stderr>\". In UI, show call-to-action linking to InterpreterSettings.\n- Multiple accidental starts: start button disabled when status running; backend also enforces idempotency and returns 'ALREADY_RUNNING' if race occurs; UI shows non-blocking toast.\n- Process crash: Detect 'exit' with non-zero code; update status to 'error' and display notice with exitCode/signal; keep logs available.\n\n10) Log persistence details\n- Directory: app.getPath('userData')/logs/agents/<agentId>/\n- File: <YYYYMMDD-HHMMSS>-<pid>.log. Metadata: first line writes session header with ISO timestamp, pid, version info.\n- Write each line with timestamp ISO and stream label. Example: \"2025-08-23T12:34:56.789Z [stdout] message\".\n- Keep an in-memory ring buffer (e.g., circular-array) per agent capped at N lines to serve history quickly.\n\n11) Cross-platform considerations\n- Use spawn without shell; pass arguments array.\n- On Windows stopping: if proc.kill() fails to terminate, fallback to taskkill as mentioned with /T /F.\n- Ensure paths normalized; use quotes only when needed (but since we avoid shell, not needed).\n\n12) Wiring and lifecycle\n- Initialize AgentProcessManager during app ready; load agents.json and initialize registry with 'idle' statuses.\n- On app quit (before-quit/will-quit): iterate running agents and attempt graceful stop; wait up to a few seconds with Promise.allSettled; ensure log streams flushed/closed.\n\n13) Testing and acceptance checklist\n- Manual tests:\n  - Set invalid python path; attempt start -> clear error shown; agents not started.\n  - Set valid python path; start 'sample' agent -> process spawns, status transitions to running, PID shown.\n  - Logs stream in real-time; both stdout and stderr visible and color-coded; history persists to file; restart app and fetch history.\n  - Stop agent -> receives graceful signal, exits with code 0; status updates to exited; Start enabled again.\n  - Double-click Start rapidly -> only one process launches; UI shows Already running.\n  - IPC verified: agents:list returns agents with statuses; agents:start/stop work; logs subscribe delivers lines; getHistory returns recent lines.\n- Programmatic smoke: add a minimal test script or dev command to call ipcMain handlers directly (optional).\n\n14) Documentation\n- Add README section 'Agent Process Manager' with setup instructions: configure Python path, start sample agent, where logs are stored, troubleshooting notes (Windows signals, antivirus), and IPC contract.\n\n15) Future enhancements (out of scope now, but plan-friendly)\n- Multiple instances support with instanceId; advanced log rotation; per-agent environment variables; attach to existing processes; richer discovery of agents.\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.12",
      "status": "-",
      "title": "Agent activity detection and completion notifications",
      "description": "Detect agent progress by monitoring process lifecycle and file changes in tasks/ (e.g., updated task.json or tests). When an agent finishes or triggers notable changes, show OS notifications and add to an in-app notifications center. Acceptance: File watcher identifies relevant changes; notification includes agent name and summary; user can mute/disable; tested with simulated runs; no duplicate spam.",
      "plan": "Implementation Plan: Agent activity detection and completion notifications (Feature 5.12)\n\n0) Assumptions / prerequisites\n- App structure: Electron main process + React renderer with preload (contextIsolation). Project has a known root directory; tasks live under <projectRoot>/tasks/.\n- Agents can be launched by the app (child_process) or run independently; we must detect both via file changes and via process lifecycle when launched by the app.\n- Tech stack: chokidar for file watching, Electron Notification API for OS notifications, Zustand (or Redux) for renderer store, IPC for messaging, vitest for unit tests.\n\n1) Define types and settings schema\n- Create shared types in packages/shared or src/common/types/\n  - NotificationType = 'agent-complete' | 'file-change' | 'tests-updated' | 'error'\n  - NotificationSource = 'process' | 'filewatcher'\n  - Notification = { id, type, source, timestamp, summary, agentId?, agentName?, taskId?, path?, read }\n  - ActivityEvent = { type: 'spawn'|'exit'|'stderr'|'stdout'|'error', agentId, agentName?, pid?, code?, message?, timestamp }\n- Settings schema (persisted in userData/notifications.settings.json):\n  notifications: {\n    enabled: true,\n    osNotifications: true,\n    fileChange: true,\n    agentComplete: true,\n    mutedAgents: string[],\n    doNotDisturb: { enabled: false, start: '22:00', end: '08:00' },\n    debounceMs: 2000,\n    watcherEnabled: true\n  }\n\n2) Main process: SettingsStore\n- Implement SettingsStore (src/main/settings/SettingsStore.ts)\n  - Load defaults; read/write JSON to app.getPath('userData')/notifications.settings.json\n  - validate on load; migrate if needed\n  - Expose get(), update(partial), onChange(cb)\n- Expose IPC handlers: notifications-settings:get, notifications-settings:update\n\n3) Main process: NotificationService\n- Implement NotificationService (src/main/notifications/NotificationService.ts)\n  - addNotification(event: Notification) => applies DND and settings filters, deduplicates, persists to in-memory list, emits to renderer via ipcMain\n  - Deduping/spam control: maintain LRU Map<string, number> recentKeys with TTL 60s; key = `${type}:${agentId||''}:${taskId||''}:${hash(summary)}`; if called within debounce window (settings.debounceMs), drop\n  - OS notifications: if settings.osNotifications && settings.enabled && not DND => new Notification({ title, body, icon }). On click: focus main window, send ipcMain.emit('notifications:open', { id, taskId, agentId })\n  - Provide clear(), markRead(id), muteAgent(agentId)\n  - Respect per-agent mute: if agentId in mutedAgents => no OS notif, still store in center unless global disabled\n\n4) Main process: FileChangeWatcher\n- Implement FileChangeWatcher (src/main/watchers/FileChangeWatcher.ts)\n  - Precondition: settings.watcherEnabled\n  - chokidar.watch(<projectRoot>/tasks, { ignoreInitial: true, depth: 5, awaitWriteFinish: { stabilityThreshold: 300, pollInterval: 100 }, ignored: ['**/node_modules/**', '**/.git/**'] })\n  - On events 'add'|'change'|'unlink': classify(filePath, event)\n    - If path ends with '/task.json':\n      - Read current JSON safely; compare with cached previous snapshot (Map<taskDir, prevTaskJson>)\n      - Detect status change: e.g., in_progress -> done; notes changed; title changed\n      - Build summary: \"Task {taskId} status: {old} \u2192 {new}\", or \"Task {taskId} notes updated\"\n      - Determine taskId from dir name or JSON; agentId/agentName from task.json.assignedAgent or previous cache\n    - If path includes '/tests/' or filename matches *.test.*|*.spec.*: summary: \"Tests updated for task {taskId}\" (find nearest task dir up the path)\n    - For other relevant files (e.g., result.md, output.json): create summary: \"Outputs updated for task {taskId}\"\n  - Emit NotificationService.addNotification with type 'file-change' or 'tests-updated' and source 'filewatcher'\n  - Keep snapshot cache updated (only for task.json); handle JSON read failures gracefully\n\n5) Main process: ProcessActivityTracker\n- Implement ProcessActivityTracker (src/main/agents/ProcessActivityTracker.ts)\n  - registerAgent({ agentId, agentName, childProcess, taskId? }) attaches listeners: 'spawn', 'exit', 'error', 'close'\n  - On 'spawn': track activeAgents Map<agentId, { pid, name, taskId }>, send ipcMain 'agent:status' updates\n  - On 'exit': remove from activeAgents; create Notification with type 'agent-complete', summary based on code/signal: \"{agentName} finished successfully\" or \"{agentName} exited with code {code}\"\n  - On 'error': create 'error' notification with message\n  - Provide manual API reportExit(agentId, result) for externally-run agents (optional)\n\n6) Main process: IPC wiring\n- Channels to renderer:\n  - 'notifications:new' (payload: Notification)\n  - 'notifications:seed' (on renderer init, send current list)\n  - 'notifications:open' (from OS click) => renderer routes to details\n  - 'agent:status' (payload: { agentId, name, pid?, status: 'running'|'stopped'|'error', taskId? })\n- Channels from renderer:\n  - 'notifications:markRead', 'notifications:clear', 'notifications:muteAgent', 'notifications:unmuteAgent'\n\n7) Renderer preload bridge\n- Expose safe APIs: window.api.notifications.onNew(cb), getAll(), markRead(id), clear(), muteAgent(id), settings.get(), settings.update()\n\n8) Renderer state store\n- Implement notifications store (Zustand) with state: items: Notification[], unreadCount, mutedAgents; actions sync with IPC\n- Implement agents store to reflect 'agent:status' for activity overview badges (optional, but helpful)\n\n9) UI: Notifications Center\n- Add a bell icon with badge to the app header\n- Clicking opens a drawer/panel listing notifications (newest first)\n  - Each item shows: icon by type, summary, agentName (if any), time ago, buttons: Mark read, Mute agent (if applicable), Open\n  - Controls: Mark all as read, Clear all\n- Ensure accessibility and virtualization if list grows\n\n10) UI: Settings\n- Settings > Notifications section\n  - Master toggle: Enable notifications\n  - OS notifications toggle\n  - Show file change notifications toggle\n  - Show agent completion notifications toggle\n  - Do Not Disturb toggle + time pickers (start/end)\n  - Per-agent mute management (list with remove)\n  - Debounce window (ms) numeric input\n\n11) Navigation on notification click\n- Renderer listens to 'notifications:open' and navigates to the appropriate route:\n  - If taskId exists: go to TaskDetails(taskId)\n  - Else if agentId exists: go to AgentDetails(agentId)\n  - Else go to Notifications center\n\n12) Spam/duplicate prevention\n- In NotificationService, implement LRU dedupe as above with TTL and debounce window\n- In FileChangeWatcher, coalesce bursts with awaitWriteFinish and an additional per-path throttle Map<path, lastTs>\n- Ensure process exit generates a single 'agent-complete' even if multiple events fire\n\n13) Persistence (optional for MVP)\n- Store notifications for the current session in memory; optionally persist last N (e.g., 200) to userData/notifications.log.json on exit and reload on start\n\n14) Testing: unit tests (vitest)\n- NotificationService.spec.ts: dedupe logic, DND time window, muted agent behavior, settings gates\n- FileChangeWatcher.spec.ts: classification of task.json status change, notes change, tests-updated; snapshot cache update; error handling\n- ProcessActivityTracker.spec.ts: exit event creates proper notification, status updates\n- Mock Electron Notification in tests to assert calls without showing OS notifications\n\n15) Testing: integration/simulation\n- Create test/simulateAgentRun.ts script:\n  - Prepares temp project with tasks/task-123/\n  - Writes task.json with { id: 'task-123', title, status: 'in_progress', assignedAgent: { id: 'agentA', name: 'Agent A' } }\n  - After 500ms, writes tests/sample.test.ts\n  - After 500ms, updates task.json status to 'done'\n  - Exits with code 0\n- Add an in-app dev command in Debug menu: \"Simulate Agent Run\" that runs the above and registers a fake agent with ProcessActivityTracker\n- Manual acceptance checklist uses this to verify notifications\n\n16) Documentation\n- docs/notifications.md: how detection works, what triggers notifications, settings, mute per agent, DND, deduping, limitations\n- docs/dev/testing-notifications.md: how to run unit tests and simulation script\n\n17) Acceptance criteria mapping\n- File watcher identifies relevant changes: implemented via FileChangeWatcher with classification and tests\n- Notification includes agent name and summary: notifications include agentName from task.json or process registry; summaries crafted per change/exit\n- User can mute/disable: settings toggles and per-agent mute implemented\n- Tested with simulated runs: simulation script and dev menu entry\n- No duplicate spam: dedupe and throttling implemented and unit-tested\n\n18) Implementation order\n1. Types and SettingsStore\n2. NotificationService with dedupe and OS notifications\n3. IPC channels and preload bridge\n4. FileChangeWatcher (with snapshots)\n5. ProcessActivityTracker and integration with agent launcher\n6. Renderer state + Notifications UI\n7. Settings UI\n8. Navigation on click\n9. Unit tests\n10. Simulation script + manual verification\n\n19) Risks and mitigations\n- Linux OS notifications variability: rely on Electron Notification; document requirement; fallback to in-app toast if OS notifications not available\n- High-frequency file writes: awaitWriteFinish + per-path throttle and service-level dedupe\n- Ambiguous task/agent mapping when agents run externally: fall back to task-derived names; if unavailable, show path and generic summary\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.13",
      "status": "-",
      "title": "Notifications center UI and preferences",
      "description": "Add a notifications panel listing recent events (agent started/stopped, edits saved, git changes). Provide settings to enable/disable OS notifications and categories. Acceptance: Notifications persist across reloads; can be marked as read; preferences stored in settings; OS notifications use Electron Notification with fallbacks.",
      "plan": "Notifications Center UI and Preferences \u2014 Implementation Plan\n\nGoal\n- Add a notifications panel that lists recent events (agent started/stopped, edits saved, git changes), with persistence across reloads, read/unread states, and preferences to enable/disable OS notifications and per-category toggles. Use Electron Notification for OS alerts with in-app fallback.\n\nTech choices\n- Persistence: electron-store (main process) for both notifications and notification preferences.\n- IPC: contextBridge + ipcMain/ipcRenderer channels for notifications and preferences.\n- Renderer state: Zustand (simple state store) to manage notifications list, unread count, and preferences.\n- UI: React components for bell icon + panel, list, filters, and preferences UI. Optional lightweight toast lib (or custom) for in-app fallback.\n\nData model\n1) Notification\n- id: string (uuid)\n- title: string\n- body: string\n- category: 'agent' | 'task' | 'git' | 'doc' | 'system'\n- level: 'info' | 'success' | 'warning' | 'error'\n- timestamp: number (ms)\n- read: boolean\n- meta?: { entityId?: string; action?: string; [k:string]: any }\n- source?: 'system' | 'user' | 'agent'\n\n2) Preferences (NotificationSettings)\n- osEnabled: boolean (default true)\n- categories: { agent: boolean; task: boolean; git: boolean; doc: boolean; system: boolean } (default all true)\n- inAppFallbackEnabled: boolean (default true)\n- retention: { maxItems: number (default 500); maxDays: number (default 30) }\n\nStorage keys in electron-store (main process)\n- storeName: 'notifications'\n  - notifications: Notification[]\n- storeName: 'notificationPreferences'\n  - preferences: NotificationSettings\n\nFile structure (proposed)\n- electron/main/notifications/notificationStore.ts\n- electron/main/notifications/preferencesStore.ts\n- electron/main/notifications/service.ts\n- electron/main/ipc/notifications.ts\n- electron/preload/notifications.ts\n- renderer/src/state/notifications.ts\n- renderer/src/components/Notifications/Bell.tsx\n- renderer/src/components/Notifications/Panel.tsx\n- renderer/src/components/Notifications/NotificationItem.tsx\n- renderer/src/components/Notifications/Preferences.tsx\n- renderer/src/components/Notifications/index.ts (barrel)\n- renderer/src/lib/toast.ts (optional if using react-hot-toast)\n- types/shared/notifications.ts (shared TS types via tsconfig path alias)\n\nStep-by-step\n1) Main process: add stores and service\n1.1) electron/main/notifications/notificationStore.ts\n- Implement NotificationStore using electron-store.\n  - Methods:\n    - getAll(): Notification[] (sorted desc by timestamp)\n    - add(n: Notification): Notification[] (push, prune by retention, persist)\n    - markRead(id: string): void\n    - markAllRead(): void\n    - clear(): void\n    - getUnreadCount(): number\n    - prune(retention: { maxItems; maxDays }): void\n\n1.2) electron/main/notifications/preferencesStore.ts\n- Implement PreferencesStore using electron-store with defaults.\n  - Methods: get(), set(patch), toggleCategory(category, enabled), setOsEnabled(bool), getRetention(), etc.\n\n1.3) electron/main/notifications/service.ts\n- Export setupNotificationService(mainWindow: BrowserWindow) with:\n  - function emitAppNotification(partial: Omit<Notification, 'id' | 'timestamp' | 'read'>)\n    - Build full Notification object (uuid, timestamp, read=false)\n    - Save to NotificationStore\n    - Read preferences; if osEnabled && preferences.categories[category] is true -> new Notification({ title, body, silent: true })\n      - On click: focus mainWindow, send 'notifications:clicked' with id to renderer\n      - Handle Windows: ensure app.setAppUserModelId set in app init (if not already)\n    - Always send to renderer via mainWindow.webContents.send('notifications:push', notification)\n    - If osEnabled is false or OS notifications not supported, renderer will show in-app toast when it receives push (controlled by inAppFallbackEnabled)\n  - Expose accessors for IPC handlers (list, mark, clear)\n- Export helper functions: notifyAgentStarted/Stopped, notifyEditSaved, notifyGitChange for use by other modules.\n\n1.4) electron/main/ipc/notifications.ts\n- Register ipcMain handlers:\n  - 'notifications:list' -> return NotificationStore.getAll()\n  - 'notifications:markRead' (id: string)\n  - 'notifications:markAllRead'\n  - 'notifications:clear'\n  - 'notifications:getPreferences' -> PreferencesStore.get()\n  - 'notifications:updatePreferences' (partial: Partial<NotificationSettings>) -> merge and persist, return updated\n- Validate inputs (category in enum, strings length) to harden IPC boundary.\n\n1.5) Integrate service\n- In main entry (electron/main/index.ts), import and call setupNotificationService(mainWindow)\n- Ensure app.setAppUserModelId('com.yourorg.localapp') on Windows before creating notifications.\n\n2) Preload bridge\n2.1) electron/preload/notifications.ts\n- contextBridge.exposeInMainWorld('notifications', {\n    list: () => ipcRenderer.invoke('notifications:list'),\n    markRead: (id) => ipcRenderer.invoke('notifications:markRead', id),\n    markAllRead: () => ipcRenderer.invoke('notifications:markAllRead'),\n    clear: () => ipcRenderer.invoke('notifications:clear'),\n    getPreferences: () => ipcRenderer.invoke('notifications:getPreferences'),\n    updatePreferences: (partial) => ipcRenderer.invoke('notifications:updatePreferences', partial),\n    onPush: (callback) => ipcRenderer.on('notifications:push', (_, n) => callback(n)),\n    onClicked: (callback) => ipcRenderer.on('notifications:clicked', (_, id) => callback(id))\n  })\n- Wire this preload in BrowserWindow creation if not already.\n\n3) Renderer state (Zustand)\n3.1) renderer/src/state/notifications.ts\n- Create useNotificationsStore with:\n  - notifications: Notification[]\n  - unreadCount: number\n  - preferences: NotificationSettings | null\n  - actions: init(), push(n), markRead(id), markAllRead(), clear(), setPreferences(p)\n- init():\n  - fetch list and preferences via window.notifications\n  - subscribe to onPush to push into state\n  - when pushing, optionally show toast if preferences.inAppFallbackEnabled && (!preferences.osEnabled || !preferences.categories[n.category])\n\n4) Renderer UI components\n4.1) Bell icon\n- renderer/src/components/Notifications/Bell.tsx\n  - Bell icon in top bar with badge for unreadCount\n  - Clicking toggles Panel visibility\n\n4.2) Panel\n- renderer/src/components/Notifications/Panel.tsx\n  - A right-side Drawer/Popover\n  - Header with: Filters by category (All, Agent, Task, Git, Docs, System)\n  - Actions: Mark all as read; Clear all; Link to Preferences\n  - List of NotificationItem components\n  - Infinite scroll or simple list; empty state message\n\n4.3) NotificationItem\n- renderer/src/components/Notifications/NotificationItem.tsx\n  - Displays icon by category, title, timestamp, body snippet\n  - Unread indicator; click toggles read or opens target\n  - Optional CTA button \"View\" based on meta (e.g., open agent detail, open file, open git diff)\n\n4.4) Preferences UI\n- renderer/src/components/Notifications/Preferences.tsx\n  - Toggles: Enable OS notifications; per-category toggles; retention maxItems and maxDays; in-app fallback enabled\n  - Save applies via updatePreferences and updates local state\n\n4.5) Toast fallback\n- renderer/src/lib/toast.ts or react-hot-toast\n  - Show small in-app notification when push arrives and OS notification is disabled or category disabled for OS\n\n5) Integration: emit notifications for events\n5.1) Agent lifecycle\n- Where agent start/stop events are emitted, call notifyAgentStarted/Stopped({ agentId, name }) in main process (or via another IPC to main service which then calls emitAppNotification). If these events come from renderer, send IPC to main 'notifications:add' or utilize existing event bus to call service.\n- Example payloads:\n  - title: \"Agent started\"; body: `${agentName} is running`; category: 'agent'; level: 'info'; meta: { agentId }\n  - title: \"Agent finished\"; body: `${agentName} completed` ; level: 'success'\n\n5.2) Edits saved\n- When a document/task edit is saved successfully, emit notification:\n  - title: \"Changes saved\"; body: `Saved ${docName}`; category: 'doc'; level: 'success'; meta: { path }\n\n5.3) Git changes\n- On repo watcher or post-commit hook: title: \"Git updated\"; body: `Committed ${shortHash}` or \"Unstaged changes detected\"; category: 'git'; level: 'info'|'warning'\n\n6) Read/unread and persistence\n- Mark single as read via item click (calls window.notifications.markRead)\n- Mark all read via header action -> window.notifications.markAllRead\n- Clear uses window.notifications.clear\n- State updates after IPC resolves; store persists immediately, so reload restarts with saved list\n\n7) OS notification behavior and fallbacks\n- Electron Notification is created in main process only if preferences.osEnabled && category enabled\n- Always send renderer push; renderer shows toast only if inAppFallbackEnabled && (OS disabled or no OS support)\n- Add minimal rate limiting in service (e.g., ignore duplicate same title/body within 1s) to avoid floods\n\n8) OS-specific details\n- Ensure Windows: app.setAppUserModelId is configured or OS notifications won\u2019t appear\n- macOS: Notifications work by default; add click focus behavior\n- Linux: Respect desktop environment availability; fallback to in-app toasts when not supported\n\n9) Security and validation\n- In ipcMain handlers, validate:\n  - IDs are strings\n  - Categories belong to known enum\n  - Title/body size limits (truncate > 512 chars body)\n- Sanitize strings before rendering (escape HTML) in NotificationItem\n\n10) Testing\n- Unit tests (if test infra present):\n  - notificationStore add/markRead/markAllRead/clear/prune\n  - preferencesStore get/set/toggleCategory\n  - service: category filter for OS notifications, emits renderer push\n- Manual QA checklist:\n  - New notifications appear in panel and survive reload\n  - Mark read updates badge, persists after reload\n  - Preferences toggles OS notifications; per-category OS on/off works; in-app fallback works\n  - Electron OS notifications appear with proper titles on macOS/Windows\n  - Clicking OS notification focuses app and highlights item\n\n11) Documentation\n- docs/notifications.md:\n  - Data model, IPC API, how to emit notifications from other modules\n  - Preferences schema, defaults, and examples\n\n12) Implementation notes\n- Types: Define shared types in types/shared/notifications.ts and use via path alias to avoid duplication\n- Retention pruning: on add and on app launch\n- Performance: Keep list capped by maxItems and virtualize list if very long (optional)\n- Accessibility: Aria roles for list and buttons; keyboard navigation; readable contrast for unread indicators\n\nAcceptance alignment\n- Persistence across reloads: electron-store in main; initial load and push ensures state is restored\n- Can be marked as read: item action and mark-all; stored in main\n- Preferences stored in settings: electron-store preferences; UI to toggle OS and categories\n- OS notifications use Electron Notification with fallbacks: main process dispatch, renderer toast fallback when disabled or unsupported\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.14",
      "status": "-",
      "title": "Chat interface UI (sessions, messages, basic send/receive)",
      "description": "Create a chat UI with session list, message view, composer with multiline input, and send action. Persist conversation locally. Pluggable model selector. Acceptance: New session, rename session, message history persists; keyboard shortcuts (Shift+Enter for newline, Enter to send configurable); empty/error states handled; uses llm:chat IPC stub.",
      "plan": "Chat Interface UI (sessions, messages, basic send/receive) - Implementation Plan\n\nGoal: Build a chat interface for the local Electron+React app with session management, persistent history, a pluggable model selector, and basic send/receive via an llm:chat IPC stub. Include keyboard shortcuts, empty/error states, and settings for Enter/Shift+Enter behavior.\n\n1) Define IPC Contracts and Preload Bridges\n   - In main/preload:\n     - Expose window.api.llm.chat(payload) -> Promise<ChatResponse> using IPC channel 'llm:chat'.\n       - payload: { sessionId?: string; messages: Array<{role: 'system'|'user'|'assistant'; content: string}>; model: string; options?: Record<string, any> }\n       - response: { id: string; role: 'assistant'; content: string; usage?: { prompt_tokens?: number; completion_tokens?: number; total_tokens?: number } }\n     - Expose window.api.llm.listModels() -> Promise<Array<{ id: string; label?: string; provider?: string }>> via 'llm:listModels'. Return at least a stub array if not configured.\n     - Expose window.api.settings.get(key, defaultValue?) and .set(key, value) via 'settings:get' and 'settings:set'. We will use key 'chat.enterToSend' (boolean, default: true) and possibly 'chat.defaultModel'.\n   - Ensure the preload provides type-safe wrappers and guards for undefined channels (graceful fallback with errors).\n\n2) Data Models and Types (renderer)\n   - Define types in src/types/chat.ts:\n     - ChatRole = 'system' | 'user' | 'assistant'\n     - ChatMessage = { id: string; sessionId: string; role: ChatRole; content: string; createdAt: number; error?: string | null }\n     - ChatSession = { id: string; name: string; modelId: string | null; createdAt: number; updatedAt: number }\n     - ChatModel = { id: string; label?: string; provider?: string }\n     - ChatSendOptions = { sessionId: string; input: string; modelId?: string }\n\n3) Persistence Layer\n   - Use IndexedDB via Dexie in renderer for local persistence (no Node context required):\n     - db.sessions: id (string primary key), name, modelId, createdAt, updatedAt\n     - db.messages: id (string primary key), sessionId (indexed), role, content, createdAt, error\n   - Create src/data/chatDb.ts using Dexie:\n     - export functions: loadSessions(), createSession(name, modelId?), updateSessionName(id, name), updateSessionModel(id, modelId), deleteSession(id)\n     - message ops: loadMessages(sessionId), appendMessage(msg), deleteMessagesBySession(sessionId)\n   - Ensure all writes update updatedAt on session.\n\n4) State Management\n   - Use Zustand for simplicity: src/state/chatStore.ts\n     - state: { sessions: ChatSession[]; selectedSessionId: string | null; messagesBySession: Record<sessionId, ChatMessage[]>; enterToSend: boolean; models: ChatModel[]; sending: boolean; sendError: string | null }\n     - actions:\n       - init(): load models via window.api.llm.listModels, load sessions and the latest session selection from localStorage (e.g., 'chat.lastSessionId'), load messages for selected session.\n       - createSession(name?: string, modelId?: string): creates, persists, selects session; default name: 'New Chat'.\n       - renameSession(id, name)\n       - deleteSession(id): deletes session and its messages; if deleting selected, auto-select most recent, else null.\n       - selectSession(id)\n       - setSessionModel(id, modelId)\n       - sendMessage(input: string): orchestrates sending (see step 7), updates 'sending' state, error handling.\n       - setEnterToSend(boolean) and persist to settings via window.api.settings.set.\n     - Keep messagesBySession hydrated lazily: load messages for selected session if not in cache.\n\n5) UI Layout and Components\n   - Page Shell: src/views/ChatPage.tsx\n     - Two-column layout (Sidebar 280px, Main flex). Use CSS modules or Tailwind (depending on project convention). Keep accessible and responsive.\n   - Left Sidebar: SessionList\n     - Component: src/components/chat/SessionList.tsx\n       - Renders a searchable list of sessions sorted by updatedAt desc.\n       - Actions:\n         - New Session button at top.\n         - Click to select session; selected highlighted.\n         - Context menu or inline three-dots: Rename, Delete.\n         - Inline rename: click or F2 to toggle an input; on blur/Enter commits; Esc cancels.\n       - Empty state: 'No chats yet. Create your first conversation.' with a button to create.\n   - Main Header: ChatHeader\n     - Component: src/components/chat/ChatHeader.tsx\n       - Editable Session Title (inline edit, same behavior as Sidebar)\n       - ModelSelector (pluggable) aligned right\n   - ModelSelector (pluggable)\n     - Component: src/components/chat/ModelSelector.tsx\n       - Fetches models from store (populated via IPC). Shows a dropdown with model labels.\n       - On change, updates session's modelId via store.\n       - Handles missing models state: shows 'No models configured' with tooltip and disabled state.\n     - Design pluggability: Model list comes from window.api.llm.listModels; future providers can populate this without UI changes.\n   - Message List: src/components/chat/MessageList.tsx\n     - Displays messages for selected session.\n     - Auto-scroll to bottom on new message append.\n     - Different styling for user vs assistant; render error-style bubble if message.error present.\n     - Empty state when no messages: 'Start a conversation' prompt.\n   - Composer: src/components/chat/Composer.tsx\n     - Multiline textarea with auto-resize; placeholder 'Type a message'.\n     - Keyboard shortcuts:\n       - Enter sends if enterToSend is true and not Shift.\n       - Shift+Enter inserts newline always.\n       - If enterToSend is false, Ctrl/Cmd+Enter sends.\n     - Send button with loading state when sending; disabled if input empty or sending.\n     - A small gear icon to toggle 'Press Enter to send' (updates store + settings).\n     - Error banner under composer if store.sendError is set.\n\n6) Session Lifecycle\n   - New Session: Clicking 'New Chat' creates a session with default name and default model (from settings 'chat.defaultModel' or first available model). Select it and focus composer.\n   - Rename Session: Inline edit in either Sidebar or Header; updates persisted session name.\n   - Delete Session: Confirmation dialog: 'Delete this chat and its messages? This cannot be undone.'; if confirmed, delete and update selection; if no sessions remain, show empty state.\n\n7) Sending / Receiving Messages (IPC integration)\n   - In chatStore.sendMessage(input):\n     - Guard: if no selected session, create one or show error.\n     - Build message objects:\n       - userMsg = { id: uuid(), sessionId, role: 'user', content: input, createdAt: now }\n       - assistantMsg placeholder: { id: uuid(), sessionId, role: 'assistant', content: '', createdAt: now }\n     - Persist and push userMsg to state+DB.\n     - Set sending=true; clear sendError.\n     - Resolve model to use: session.modelId or fallback default; if none, set error 'No model selected' and return.\n     - Call await window.api.llm.chat({ sessionId, model, messages: [...existing session messages (user+assistant only)], options: {} })\n       - Note: For performance, send only necessary recent messages if needed later; for now, send all.\n     - On success: update assistantMsg.content to response.content; persist assistantMsg; push to state.\n     - On failure: set assistantMsg.error = error.message; persist; set store.sendError with a short description; keep sending=false.\n     - Finally: sending=false; clear composer input; scroll to bottom.\n   - Handle re-send on failed assistant message via context menu 'Retry last assistant response', which re-invokes chat with the same context.\n\n8) Keyboard Shortcuts and Settings\n   - On Composer mount, read enterToSend from settings via window.api.settings.get('chat.enterToSend', true) and set in store.\n   - Behavior mapping:\n     - enterToSend=true: Enter sends; Shift+Enter newline.\n     - enterToSend=false: Enter newline; Ctrl/Cmd+Enter sends.\n   - Provide tooltip/help text near the gear icon explaining the current behavior.\n\n9) Empty and Error States\n   - No sessions: Sidebar shows 'No chats' with a primary action button. Main area shows onboarding message.\n   - No session selected: Show message 'Select a chat or create a new one'.\n   - No models available: ModelSelector shows disabled state; composer send disabled with inline notice 'No model configured'.\n   - IPC error (llm:chat rejected): show error toast/banner and mark assistant message with error styling and retry control.\n\n10) Persistence Guarantees\n   - Sessions and messages live in IndexedDB (Dexie). On each store mutation, write-through to Dexie.\n   - On app launch, load sessions; auto-select last used session id from localStorage ('chat.lastSessionId') if exists.\n   - Save selected session id on selection change.\n   - Ensure all message and session writes are awaited to prevent data loss on quit.\n\n11) Minimal Styling and Accessibility\n   - Use existing design system if present; otherwise, neutral styling:\n     - High-contrast bubbles, clear focus states, ARIA labels for buttons (Send, New Chat, Rename).\n     - Ensure screen reader text for role labels (User/Assistant).\n     - Maintain 44px tap targets.\n\n12) Tests and QA (lightweight)\n   - Unit tests for store actions (create/rename/delete session; sendMessage success and error paths) using Jest/RTL if available.\n   - Manual acceptance test checklist:\n     - Create a new session; rename session; persists after reload.\n     - Type multi-line message with Shift+Enter; Enter sends (default). Toggle setting and verify new behavior.\n     - Messages persist across reload; selecting sessions loads history.\n     - Model selector lists models; selecting updates session model; used by send.\n     - Send succeeds; assistant message appears. Simulate failure (mock IPC reject) and verify error rendering and retry.\n     - Empty states: no sessions, no selected session, no models.\n\n13) Extensibility Hooks (non-functional now, design in place)\n   - ModelSelector decoupled from provider; window.api.llm.listModels is the sole source for model list.\n   - sendMessage structured to later support streaming (onProgress callback) without UI changes.\n   - Sessions may later include system prompt and metadata; keep type extensible.\n\n14) Implementation Order\n   1. IPC preload stubs and types for llm:chat, llm:listModels, settings.\n   2. Dexie DB setup and data access functions.\n   3. Zustand store with init/load, session CRUD, settings integration.\n   4. Sidebar (SessionList) + create/rename/delete/select.\n   5. Header (title edit + ModelSelector).\n   6. MessageList (empty state, autoscroll).\n   7. Composer (input, shortcuts, send button, settings toggle).\n   8. Wire sendMessage to IPC and persistence; handle error states.\n   9. Polish: disabled states, toasts/banners, accessibility, persistence of selected session.\n   10. Light tests + manual acceptance run.\n\n15) Deliverables\n   - Components: ChatPage, SessionList, ChatHeader, ModelSelector, MessageList, Composer.\n   - State: chatStore with full session/message lifecycle and settings.\n   - Persistence: Dexie database for sessions/messages.\n   - IPC: usage of 'llm:chat' and 'llm:listModels' stubs; settings get/set.\n   - Configurable keyboard behavior; empty/error states.\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.15",
      "status": "-",
      "title": "LLM connector abstraction and providers (LiteLLM, OpenAI-compatible)",
      "description": "Design an abstraction for chat providers. Implement connectors for: (1) LiteLLM-compatible HTTP endpoint, (2) OpenAI-compatible custom base URL to support LM Studio / Ollama. Configurable API key, base URL, model name, timeouts. Acceptance: Provider interface documented; connectors unit-tested with mocked servers; UI to add/edit providers; failing requests produce actionable errors.",
      "plan": "Feature: LLM connector abstraction and providers (LiteLLM, OpenAI-compatible)\n\nGoal\n- Provide a clean provider interface for chat.\n- Implement two connectors:\n  1) LiteLLM-compatible HTTP endpoint\n  2) OpenAI-compatible with custom base URL (supports LM Studio, Ollama in OpenAI-compat mode)\n- Configurable API key, base URL, model name, timeouts.\n- UI to add/edit/test providers and select default.\n- Unit tests with mocked servers; actionable errors on failure.\n\nAssumptions\n- Electron + React app with main (Node) and renderer (React). We keep secrets (API keys) in main process and communicate via IPC.\n- HTTP requests from main process to avoid CORS and protect keys.\n- For Ollama, we rely on OpenAI-compatible endpoint (e.g., LM Studio / Ollama openai-compat servers exposing /v1/chat/completions).\n\nHigh-level Architecture\n- src/common: shared types and zod schemas.\n- src/main/llm: provider abstractions, connectors, registry, HTTP client, error mapper, service.\n- src/main/config: provider config store (encrypted storage for secrets when possible).\n- src/main/ipc: IPC channels for provider CRUD, test, and chat execute.\n- src/renderer/modules/providers: React UI for list/add/edit/test, validation, error display.\n- tests/main/llm: unit tests for connectors using mocked servers (nock or msw/node).\n\nDeliverables\n- Provider interface documented in code and docs.\n- LiteLLM and OpenAI-compatible connectors.\n- Config persistence with validation and masking of secrets in UI.\n- IPC endpoints for CRUD/test/execute.\n- UI for add/edit/test providers and set default provider.\n- Unit tests with mocked servers; actionable errors.\n\nStep-by-step Plan\n\n1) Define Types and Schemas (src/common)\n- Chat types:\n  - ChatMessage: { role: 'system' | 'user' | 'assistant' | 'tool', content: string }\n  - ChatOptions: { model: string; temperature?: number; maxTokens?: number; stop?: string[]; timeoutMs?: number; stream?: boolean }\n  - ChatResponse: { id: string; content: string; usage?: { promptTokens?: number; completionTokens?: number; totalTokens?: number }; raw?: unknown }\n- Provider identity/types:\n  - ProviderId: string\n  - ProviderKind: 'litellm' | 'openai_compat'\n- Config schemas (zod):\n  - Base provider config: { id: string; name: string; kind: ProviderKind; baseUrl: string; apiKey?: string; model: string; timeoutMs?: number; extraHeaders?: Record<string,string> }\n  - Validation ensures baseUrl is URL, model non-empty, timeout reasonable (1s-120s), headers safe keys.\n- AppError shape and error codes:\n  - AppError: { code: 'NETWORK'|'TIMEOUT'|'AUTH'|'RATE_LIMIT'|'NOT_FOUND'|'BAD_REQUEST'|'SERVER'|'UNSUPPORTED'|'UNKNOWN', httpStatus?: number, hint?: string, details?: unknown }\n\n2) Provider Interface (src/main/llm/IChatProvider.ts)\n- export interface IChatProvider {\n  - readonly id: string\n  - readonly kind: ProviderKind\n  - configure(cfg: ProviderConfig): void // validates\n  - testConnection(): Promise<{ ok: true } | { ok: false; error: AppError }>\n  - chat(messages: ChatMessage[], options?: ChatOptions): Promise<ChatResponse>\n  - supportsStreaming(): boolean // may return false initially\n}\n- Provide a helper type for ProviderConfig.\n- Document expectations: chat should map errors to AppError; all connectors must honor timeoutMs and abort requests.\n\n3) HTTP Client Helper (src/main/llm/http.ts)\n- buildFetch(baseUrl, path, method, headers, body, timeoutMs): Promise<Response>\n  - Uses node-fetch or undici; supports AbortController for timeout.\n  - Merges default headers + extraHeaders; inject Authorization: Bearer <apiKey> when apiKey present.\n  - Converts network/timeout errors into AppError.\n- parseJSON(response): safe JSON parse with AppError on invalid JSON.\n\n4) Error Mapping Utility (src/main/llm/errorMapper.ts)\n- fromHttpResponse(resp: Response, payload: any): AppError\n  - 401/403 -> AUTH with hint: 'Check API key and base URL.'\n  - 404 -> NOT_FOUND with hint: 'Verify model name and endpoint path.'\n  - 429 -> RATE_LIMIT with hint: 'Reduce request rate or increase model quota.'\n  - 400 -> BAD_REQUEST with hint: 'Verify request fields, model supports options.'\n  - 5xx -> SERVER with hint: 'Server error; retry later or check provider.'\n  - else -> UNKNOWN.\n- fromException(err: unknown): AppError\n  - ECONNREFUSED/ENOTFOUND -> NETWORK with hint to check server reachable.\n  - Timeout -> TIMEOUT with hint to increase timeout or ensure server responsiveness.\n\n5) Provider Registry (src/main/llm/registry.ts)\n- In-memory registry mapping providerId -> instance implementing IChatProvider.\n- loadProvidersFromStore() builds instances and configures them.\n- getDefaultProviderId()/setDefaultProviderId().\n- CRUD operations update store and registry.\n\n6) Config Persistence (src/main/config/providersStore.ts)\n- Use electron-store or lowdb. Prefer electron-store for simplicity.\n- Store schema: { providers: ProviderConfig[]; defaultProviderId?: string }\n- Secrets handling:\n  - Use keytar to store apiKey per providerId when available; Store only a placeholder or empty in electron-store; On load, hydrate config with apiKey from keytar.\n  - Fallback: Electron safeStorage encrypt; else plaintext with a warning flag.\n- Provide functions: list(), get(id), upsert(cfg), remove(id), setDefault(id), getSecret(id)/setSecret(id, apiKey).\n\n7) Implement LiteLLMConnector (src/main/llm/connectors/LiteLLMProvider.ts)\n- Endpoint: baseUrl + '/v1/chat/completions'\n- Request body follows OpenAI chat format: { model, messages: [{role, content}], temperature, max_tokens, stop, stream: false }\n- chat():\n  - Validate config and messages.\n  - Call HTTP helper with timeout.\n  - On non-2xx, map error via errorMapper.\n  - On 2xx, parse JSON and map to ChatResponse (content from choices[0].message.content, usage if available).\n- testConnection():\n  - Strategy A: Make a lightweight POST with a short prompt 'ping' and max_tokens: 1.\n  - Or Strategy B: GET baseUrl + '/v1/models' if LiteLLM supports; If 200, ok. Prefer Strategy B if available; fallback to A.\n- supportsStreaming(): false for now (can be extended later).\n\n8) Implement OpenAICompatibleProvider (src/main/llm/connectors/OpenAICompatProvider.ts)\n- Same request/response shape as LiteLLM (OpenAI-spec).\n- Endpoint: baseUrl + '/v1/chat/completions'\n- testConnection():\n  - Try GET baseUrl + '/v1/models' (LM Studio supports; Ollama openai-compat generally supports too). Fallback to tiny chat as above.\n\n9) Unit Tests with Mocked Servers (tests/main/llm)\n- Testing framework: vitest.\n- Mock HTTP: nock or msw/node. Use nock for simplicity.\n- Test cases common to both providers:\n  - chat success: returns expected content and usage.\n  - 401/403 -> AUTH error with hint.\n  - 404 -> NOT_FOUND with hint.\n  - 429 -> RATE_LIMIT with hint.\n  - 400 -> BAD_REQUEST.\n  - 500 -> SERVER.\n  - malformed JSON -> UNKNOWN with details.\n  - network error (ECONNREFUSED) -> NETWORK.\n  - timeout -> TIMEOUT when exceeding timeoutMs.\n- testConnection paths:\n  - models endpoint success.\n  - models endpoint missing -> fallback tiny chat.\n  - tiny chat failure -> returns error.\n- Config validation tests:\n  - Reject invalid baseUrl, missing model, unreasonable timeout.\n\n10) IPC Layer (src/main/ipc/llm.ts)\n- Channels and payload schemas (zod on both ends):\n  - llm.providers.list -> returns array of provider configs with apiKey status masked.\n  - llm.providers.get(id)\n  - llm.providers.upsert(cfg, secret?) -> validates; stores cfg and secret via keytar; loads into registry.\n  - llm.providers.remove(id)\n  - llm.providers.setDefault(id)\n  - llm.providers.test(id) -> calls provider.testConnection()\n  - llm.chat.execute({ providerId?, messages, options }) -> resolves with ChatResponse or AppError.\n- Ensure errors are serialized using AppError shape for renderer.\n\n11) Renderer UI (src/renderer/modules/providers)\n- ProvidersPage: list providers with name, kind, baseUrl, model, default badge.\n- Add/Edit Provider Modal/Form:\n  - Fields: name, kind (select), baseUrl, model, apiKey (password field, masked; show \"stored\" indicator), timeoutMs, extra headers JSON (optional advanced section).\n  - Client-side validation mirrors zod schema; server-side validation via IPC on save.\n  - Buttons: Save, Test Connection, Cancel.\n  - Test Connection triggers IPC test; display status (success with checkmark; error shows code, message, hint).\n- Set Default: action on list row to set default provider.\n- Error presentation:\n  - Use a reusable Alert component to display AppError code, human-readable message, and hint.\n\n12) Actionable Error Strategy\n- Standardize human-readable messages for each AppError.code plus context, e.g.:\n  - AUTH: \"Authentication failed. Check API key and permissions.\"\n  - NETWORK: \"Cannot reach server. Verify base URL and that the server is running.\"\n  - TIMEOUT: \"The request timed out. Try increasing timeout or ensuring the server responds promptly.\"\n  - RATE_LIMIT: \"Rate limit exceeded. Slow down requests or increase quota.\"\n  - NOT_FOUND: \"Resource not found. Check model name or endpoint path.\"\n  - BAD_REQUEST: \"Request was invalid. Review options like temperature, max tokens, and message formatting.\"\n  - SERVER: \"Provider server error. Try again later.\"\n- Include any response error.message in details dropdown for debugging.\n\n13) Documentation\n- docs/llm_providers.md\n  - Overview of Provider interface, method contracts, error mapping, and configuration.\n  - How to add a new provider connector (template/boilerplate).\n  - Examples for LiteLLM, LM Studio, Ollama (OpenAI-compat): sample baseUrl and typical models.\n  - Security notes about API key storage (keytar) and fallbacks.\n\n14) Developer Experience\n- Add scripts:\n  - test:unit: llm connectors tests.\n  - typecheck.\n- TypeDoc or JSDoc for IChatProvider and connectors.\n\n15) Manual QA Matrix\n- LiteLLM on localhost:\n  - Valid key and baseUrl -> chat works.\n  - Wrong key -> AUTH error.\n  - Wrong path/baseUrl -> NETWORK/NOT_FOUND.\n- LM Studio:\n  - baseUrl http://localhost:1234; model name available; chat works.\n  - Missing model -> NOT_FOUND or BAD_REQUEST with hint.\n- Ollama (openai-compat mode):\n  - baseUrl http://localhost:11434/v1; known model; chat works.\n  - Stop server -> NETWORK error in UI.\n- UI: add, edit, test, set default; masked apiKey display.\n\n16) Future-proofing (optional, behind flags)\n- Streaming support (Server-Sent Events) in providers and IPC if needed later.\n- List models endpoint to assist UI selection when available.\n\n17) Definition of Done\n- Provider interface defined and documented.\n- LiteLLM and OpenAI-compatible connectors implemented.\n- Unit tests passing with mocked servers covering success and common failure modes.\n- UI flows to add/edit/test providers and set default provider.\n- Actionable error messages surfaced in UI.\n- Minimal documentation committed.\n\nImplementation Notes\n- Use undici for HTTP in main process for performance.\n- Use zod for config validation and IPC payload validation.\n- Use keytar for secure secret storage; provide graceful fallback with warning if unavailable.\n- Ensure no API keys are ever sent to renderer or persisted in plaintext configs.\n- Keep connectors small and leverage shared HTTP + error mapping utilities to avoid duplication.\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.16",
      "status": "-",
      "title": "Read-only tool adapters for chat",
      "description": "Implement tools accessible from chat with strict read-only capabilities: read_file, list_dir (scoped to project root), docs_index, read_doc, tasks_index, get_task, git_status, list_agents, agent_log_tail. Enforce allowlists and path sandboxing. Acceptance: Tools cannot write to disk; attempts to escape sandbox blocked; usage audited/logged; tool registry exposes metadata; covered by security unit tests.",
      "plan": "Implementation Plan: Read-only tool adapters for chat (Feature 5.16)\n\n1) Define scope, constraints, and foundations\n   1.1. Tech stack: Node.js/TypeScript backend in Electron main process (or a local service), React for UI. Use zod for runtime schema validation and type inference. Use child_process.execFile for git (no shell) and fs/promises for file I/O.\n   1.2. Project root: Determine a single projectRoot directory at app startup (configurable via settings, defaults to the app workspace directory). All file-based tools must operate strictly within this root or an allowlisted subset of it.\n   1.3. Read-only enforcement: Registry will only expose tools flagged readOnly=true to the chat layer. Do not register any mutating tools here. Ensure all implementations avoid write operations.\n\n2) Core security utilities\n   2.1. Path sandboxing helper: create util pathSafe.ts with functions:\n       - resolveInsideRoot(root: string, input: string): string\n         \u2022 Uses path.resolve(root, input) and fs.realpath on the final path.\n         \u2022 Reject if resolved path does not start with root + path.sep.\n         \u2022 Reject NUL bytes, drive letter tricks, and normalize to POSIX-like expectations while supporting Windows.\n       - assertInsideRoot(root: string, target: string): void throws on violation.\n       - sanitizeRelPath(input: string): remove trailing slashes, collapse .., prohibit absolute and UNC.\n   2.2. Symlink handling: Always fs.realpath the target; reject if it resolves outside projectRoot.\n   2.3. Rate limiting middleware for tools (basic): per-session and per-tool token bucket, e.g., 10 calls/min default; overridable per tool metadata.\n   2.4. Size limits: impose maximum read sizes (e.g., read_file: 512 KB cap; agent_log_tail: 10 KB cap; list_dir: 500 entries cap) to prevent resource abuse.\n\n3) Tool Registry and metadata\n   3.1. Define Tool interface:\n       - name: string\n       - description: string\n       - readOnly: true\n       - paramsSchema: zod schema\n       - execute(ctx: { projectRoot: string; sessionId: string; userId?: string }, params: unknown): Promise<JSON-serializable>\n       - allowedRoots?: string[] (relative to projectRoot) for extra scoping (e.g., docs/*).\n       - rateLimit?: { callsPerMinute?: number }\n   3.2. Implement ToolRegistry:\n       - register(tool: Tool)\n       - list(): metadata only (no execute)\n       - get(name): returns tool instance\n       - Only expose readOnly tools to chat integration.\n   3.3. Tool metadata endpoint for UI: return list of tools with name, description, paramsSchema (JSON representation), readOnly flag, limits, and allowedRoots.\n\n4) Audit logging\n   4.1. Implement AuditLogger writing JSONL to logs/chat-tools.log and in-memory buffer for quick UI display.\n       - Fields: ts, sessionId, userId, tool, allowed (bool), paramsRedacted (apply simple redaction for paths), resultMeta { bytes?, items? }, error?\n   4.2. Hook audit logs in a middleware:\n       - Before execution: validate and check allowlists/sandbox; if fail, log denied and throw.\n       - After execution: log summary (sizes, counts), but never raw file contents.\n\n5) Implement tools (all readOnly=true)\n   Common: validate params via zod; enforce allowedRoots by pre-resolving base root = projectRoot or projectRoot/allowedRoot; use resolveInsideRoot; apply size limits; audit.\n   5.1. read_file\n       - Params: { path: string; encoding?: 'utf8'|'base64'='utf8'; maxBytes?: number }\n       - Resolve path within projectRoot; fs.stat; cap size to min(requested, 512KB default); read and return { content, bytes, truncated }.\n   5.2. list_dir\n       - Params: { path?: string; depth?: 1|2=1; includeFiles?: boolean=true; includeDirs?: boolean=true; maxEntries?: number=500 }\n       - Base is projectRoot if path missing. Use fs.readdir({ withFileTypes: true }); depth-limited recursion; return entries with { name, type, size?, mtime } for first level; enforce caps.\n   5.3. docs_index\n       - AllowedRoots: [\"docs\", \"README.md\", \"CONTRIBUTING.md\"]\n       - Walk projectRoot/docs and selected top-level README*.md; extract top-level headings (# ...); return tree of docs with relative paths, titles, size, mtime.\n   5.4. read_doc\n       - Params: { path: string }\n       - Only within docs and top-level *.md allowlist; reuse read_file with stricter allowedRoots; return content and front-matter (if present) parsed read-only.\n   5.5. tasks_index\n       - Assumption: tasks stored via TaskStore (existing or to be created) reading from a JSON/db in project data dir. Implement a read-only adapter: TaskStore.listPublic() returning id, title, status, assignee, updatedAt, tags (no sensitive notes by default).\n       - Params: { status?: string[]; limit?: number=200; q?: string }\n       - Server-side filter and return lightweight list.\n   5.6. get_task\n       - Params: { id: string; includeNotes?: boolean=false }\n       - Read from TaskStore; if includeNotes is true, still read-only; optionally redact private fields via configuration.\n   5.7. git_status\n       - Params: { porcelain?: boolean=true; branch?: boolean=true }\n       - Use execFile('git', ['status','--porcelain=v2','--branch']) with cwd=projectRoot; no shell; timeout 5s; return stdout parsed into structured fields (branch, ahead/behind, changes[]), plus raw for display.\n   5.8. list_agents\n       - Params: none\n       - Read from AgentManager registry: return [{ id, name, status: 'idle'|'running'|'error', currentTask?, pid?, startedAt?, lastHeartbeatAt? }]. Ensure only metadata, no control actions.\n   5.9. agent_log_tail\n       - Params: { agentId: string; lines?: number=200; maxBytes?: number=10240 }\n       - Source from in-memory ring buffer maintained by AgentManager; fallback to a per-agent log file under projectRoot/.logs/agents/<id>.log (ensure allowedRoots to .logs/agents only); return last lines up to limits.\n\n6) Chat integration (read-only)\n   6.1. In the chat tool-calling layer, fetch ToolRegistry.list() and expose only readOnly tools. Bind invocation to the execute method with session context.\n   6.2. Validate all incoming tool calls against the registry (no dynamic tool names). Deny any tool not in allowlist or with params failing schema; audit as denied.\n   6.3. Add UI affordance: In the chat panel, show an \"Available tools\" dropdown with metadata and parameter hints; show audit log sidebar for recent tool calls in-session.\n\n7) Configuration\n   7.1. Add settings keys: projectRoot (string), toolRateLimits (per tool), docsRoots (override), taskStoreConfig (path/driver), logDir (default projectRoot/.logs), maxReadBytes defaults.\n   7.2. Ensure settings changes require restart for projectRoot and logDir to avoid TOCTOU issues.\n\n8) Testing: security and functionality\n   8.1. Unit tests (Jest):\n       - Path sandbox: attempts to use '../', absolute paths, UNC, null bytes \u2192 rejected.\n       - Symlink outside root: create tmp structure with symlink to /etc or outside temp dir \u2192 rejected by resolveInsideRoot.\n       - read_file truncation: large file truncated at cap with truncated=true.\n       - list_dir caps: excessive entries trimmed; depth respected.\n       - docs_index restricts to docs + top-level allowlist only.\n       - git_status uses execFile without shell; malicious args not possible; timeout enforced.\n       - ToolRegistry exposes readOnly only; non-existent tool invocation rejected.\n       - Audit logging: allowed and denied calls recorded; no content leaked in logs.\n       - Rate limiting: exceed limit \u2192 429-like error; audit recorded.\n   8.2. Integration tests:\n       - Chat tool invocation flow: call each tool with valid params; verify outputs and audit entries.\n       - Attempt escape via path traversal in chat \u2192 denied and audited.\n\n9) Documentation\n   9.1. docs/dev/chat-tools.md: architecture, registry API, metadata schema (JSON), security model, limits, examples.\n   9.2. docs/user/chat-tools-usage.md: how the chat uses tools, visible metadata, privacy notes.\n\n10) Delivery\n   10.1. Wire up CI to run security/unit tests on PR.\n   10.2. Add a feature flag or version tag: tools.readOnly.v1.\n   10.3. Open a follow-up ticket for write-capable tools with separate explicit opt-in and stricter security review.\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.17",
      "status": "-",
      "title": "Chat tool permissions and admin gating",
      "description": "Add UI and backend enforcement for enabling/disabling tools per session. Provide a clear indicator in the chat UI of which tools are enabled. Acceptance: Disabled tools are not invocable; permissions persist; attempting to call a disabled tool returns a controlled error; tests verify enforcement at IPC and provider levels.",
      "plan": "Feature 5.17: Chat tool permissions and admin gating\n\nGoal\n- Add UI and backend enforcement for enabling/disabling tools per chat session.\n- Provide a clear indicator in the chat UI of which tools are enabled.\n- Disabled tools are not invocable; permissions persist across app restarts.\n- Attempting to call a disabled tool returns a controlled error.\n- Tests verify enforcement at both IPC and provider levels.\n\nAssumptions and Repo Layout\n- Electron + React app with:\n  - main/ (Electron main process, IPC, persistence)\n  - renderer/ (React/TS UI)\n  - common/ (shared types, constants)\n  - providers/ (LLM providers and tool execution layer)\n  - tools/ (tool registry and implementations)\n- Chat sessions already exist with IDs; LLM tool calling is centralized via a tool registry and provider wrappers.\n\n1) Data Model and Types\n1.1 Create shared types in common/types/tools.ts:\n- export type ToolId = string\n- export type ToolCapability = 'read' | 'write'\n- export interface ToolDescriptor {\n    id: ToolId\n    name: string\n    description: string\n    capability: ToolCapability\n    scope: 'chat' | 'agent' | 'both'\n    defaultEnabledInChat?: boolean // default true only for read-only tools\n  }\n- export interface SessionToolPermissions {\n    sessionId: string\n    allowedToolIds: ToolId[]\n    updatedAt: string\n  }\n- export interface ToolPermissionErrorPayload {\n    code: 'TOOL_DISABLED'\n    message: string\n    toolId: ToolId\n  }\n\n1.2 Define admin gating types in common/types/admin.ts:\n- export interface AdminSettings { enabled: boolean; pinHash?: string }\n- export interface AdminState { active: boolean; activatedAt?: string }\n\n2) Tool Registry Updates\n2.1 In tools/registry.ts, ensure each tool has a ToolDescriptor including capability and scope.\n- Mark read-only tools with capability: 'read' (e.g., git.status, fs.readFile, search.index).\n- Write tools flagged as 'write' (e.g., fs.writeFile, git.commit).\n- Set defaultEnabledInChat true only for read-only tools.\n\n2.2 Export helper functions:\n- listAllTools(): ToolDescriptor[]\n- listChatTools(): ToolDescriptor[] // scope chat/both\n- listReadOnlyChatTools(): ToolDescriptor[] // capability read\n\n3) Persistence Layer\n3.1 Add a new file main/persistence/permissionsStore.ts using electron-store or simple JSON in appData:\n- Methods:\n  - getSessionPermissions(sessionId): SessionToolPermissions | null\n  - setSessionPermissions(perm: SessionToolPermissions): void\n  - migrateIfNeeded(): void\n- On migrateIfNeeded, for sessions lacking permissions, set allowedToolIds to listReadOnlyChatTools().map(t => t.id).\n\n3.2 Admin settings persistence main/persistence/adminStore.ts:\n- getAdminSettings(): AdminSettings\n- setAdminSettings(settings: AdminSettings): void\n- getAdminState(): AdminState (in-memory)\n- setAdminState(state: AdminState): void\n\n4) Permission Manager (Backend Enforcement)\n4.1 Create main/security/permissionManager.ts:\n- class PermissionManager {\n    constructor(permissionsStore, adminStore, toolRegistry)\n    getAllowedTools(sessionId): ToolDescriptor[]\n    isToolAllowed(sessionId, toolId): boolean\n    requireAdmin(): void // throws if AdminState.active=false and AdminSettings.enabled=true\n    updateSessionPermissions(sessionId, allowedToolIds: ToolId[]): void // validates toolIds belong to listChatTools; if AdminSettings.enabled, requireAdmin\n    ensureDefaults(sessionId): void // set defaults if missing\n  }\n- Validate that only tools with scope chat/both can be enabled for chat sessions.\n- Extra guard: if a tool capability is 'write', allow it only if explicitly enabled via UI (no default).\n\n4.2 Define a specific error class in common/errors.ts:\n- export class ToolPermissionError extends Error { code='TOOL_DISABLED'; toolId: ToolId; }\n\n5) IPC API\n5.1 Define IPC channels in common/ipc.ts:\n- 'chat.getPermissions' -> (sessionId) => SessionToolPermissions\n- 'chat.updatePermissions' -> (sessionId, allowedToolIds) => SessionToolPermissions (admin gated)\n- 'tools.list' -> ({scope?: 'chat'|'agent'|'both'}) => ToolDescriptor[]\n- 'chat.invokeTool' -> ({sessionId, toolId, args}) => ToolResult | ToolPermissionErrorPayload\n- 'admin.enableMode' -> ({pin}) => {active: boolean}\n- 'admin.disableMode' -> () => {active: boolean}\n- 'admin.status' -> () => AdminState\n- 'admin.updateSettings' -> ({enabled, pin}) => AdminSettings (admin gated or if no PIN set yet)\n\n5.2 Implement handlers in main/ipc/chatTools.ts:\n- chat.getPermissions: permissionManager.ensureDefaults(sessionId); return permissionsStore.getSessionPermissions(sessionId)\n- chat.updatePermissions: permissionManager.requireAdmin(); validate IDs; save; return updated\n- tools.list: filter by scope\n- chat.invokeTool:\n  - if !permissionManager.isToolAllowed(sessionId, toolId) -> return { code: 'TOOL_DISABLED', message: 'Tool is disabled for this session', toolId }\n  - else forward to tool execution pipeline\n\n5.3 Implement admin handlers in main/ipc/admin.ts:\n- admin.enableMode: verify pin by comparing hash (use bcrypt/scrypt); set AdminState.active=true; return state\n- admin.disableMode: set active=false\n- admin.status: return AdminState\n- admin.updateSettings: if settings.pinHash not set, allow setting; else requireAdmin; store enabled flag and new pinHash if provided\n\n6) Provider-Level Enforcement\n6.1 When constructing tool/function list for the LLM provider (providers/*):\n- Add a function buildAllowedToolDefs(sessionId): returns only tools allowed by PermissionManager.\n- Ensure provider.request() for a chat session passes only these tool definitions to the model.\n\n6.2 In the tool execution layer (tools/executor.ts):\n- Before executing any tool invocation, call permissionManager.isToolAllowed(sessionId, toolId). If false, throw ToolPermissionError so backend catches and returns controlled error payload via IPC.\n\n7) UI: Permissions Indicator and Admin Gating\n7.1 Add a ChatHeaderTools component in renderer/components/chat/ChatHeaderTools.tsx:\n- Button \"Tools\" showing a badge with count of enabled tools (e.g., 5).\n- Clicking opens a side drawer or modal listing chat-scope tools grouped by capability:\n  - Enabled tools: toggle on\n  - Disabled tools: toggle off\n  - Non-interactive when not in Admin Mode and AdminSettings.enabled (show lock icon tooltip \"Admin mode required\")\n- Controls:\n  - Search/filter tools\n  - Reset to defaults\n  - Apply/save (disabled unless changes + admin if required)\n\n7.2 Admin Mode UI in renderer/components/admin/AdminMode.tsx:\n- Status indicator in app header (shield icon): Active/Inactive\n- Button to Enable Admin Mode -> opens PIN prompt modal\n- Button to Disable Admin Mode\n- Preferences page to enable/disable admin gating and set/change PIN (if gating enabled). If PIN not yet set, allow set without admin mode; otherwise require admin mode.\n\n7.3 Chat Input area indicator:\n- Under the text input, display a pill row: \"Tools enabled:\" followed by chips for enabled tool names (truncated + tooltip). When zero enabled, show warning chip \"No tools enabled\".\n\n7.4 Error surfacing:\n- If chat.invokeTool returns TOOL_DISABLED, append a system message bubble: \"Tool <name> is disabled for this session. Ask an admin to enable it.\" with a shortcut button opening the Tools drawer.\n\n7.5 State management:\n- Redux/Zustand slice: permissionsSlice with state per session { allowedToolIds, loading, error }\n- Effects to load on chat mount: fetch tools.list(scope='chat') and chat.getPermissions(sessionId)\n- Actions to update: chat.updatePermissions -> refresh state and toast success\n- Admin slice: adminState and adminSettings with IPC bindings\n\n8) Security and Validation\n- Renderer never trusted: IPC handlers enforce permissions and admin gating\n- Validate allowedToolIds against registry; drop unknown IDs\n- If AdminSettings.enabled=false, allow toggles without Admin Mode (backward compatible dev mode)\n- Admin mode times out after 15 minutes of inactivity: implement in AdminState using timestamp + periodic check; auto-disable and notify UI\n\n9) Migrations\n- On app startup, permissionsStore.migrateIfNeeded() creates allowedToolIds for each existing chat session with defaults (read-only chat tools)\n- Maintain backup of previous sessions file: sessions.json.bak\n\n10) Error Codes and Mapping\n- Standardize error payload for disabled tools: { code:'TOOL_DISABLED', message, toolId }\n- Map ToolPermissionError to this payload in IPC and provider error paths\n- Ensure renderer gracefully handles this in chat stream or single-shot calls\n\n11) Tests\n11.1 Unit tests (jest) for PermissionManager:\n- Defaults applied for new sessions\n- isToolAllowed true/false logic across read/write tools\n- updateSessionPermissions rejects non-chat tools or unknown IDs\n- requireAdmin throws when admin gating enabled and not active\n\n11.2 IPC integration tests (using spectron/electron-mocha or electron-playwright):\n- chat.invokeTool on disabled tool returns TOOL_DISABLED\n- chat.updatePermissions blocked without admin when gating enabled; succeeds when admin active\n- tools.list returns proper scope filtering\n\n11.3 Provider tests:\n- buildAllowedToolDefs excludes disabled tools\n- Tool executor throws ToolPermissionError when a tool invocation arrives for a disabled tool (simulate function_call from model)\n\n11.4 UI tests (Playwright):\n- Tools drawer shows enabled/disabled states and count badge updates when toggled\n- With Admin gating on and admin inactive, toggles are disabled and lock icon shown\n- Enabling Admin Mode allows toggling and persists after reload\n- Attempt to use disabled tool shows system message and disabled state persists after app restart\n\n12) Documentation\n- Update README/User Guide: Managing chat tool permissions, Admin Mode, defaults, and error messages\n- Admin Guide: How to set/change PIN, enable gating, session defaults, and timeout behavior\n- Security note: renderer not trusted; all checks in main process\n\n13) Rollout and Acceptance Checklist\n- Feature flag: Admin gating enabled by default = true; PIN required; initial PIN must be set on first attempt to enable Admin Mode\n- Acceptance criteria mapping:\n  - Disabled tools not invocable -> Verified by IPC and provider tests and manual QA\n  - Permissions persist -> Restart app and verify allowedToolIds saved and reloaded\n  - Attempt to call disabled tool returns controlled error -> TOOL_DISABLED payload shown in UI\n  - Tests at IPC and provider levels -> Implemented as above\n\n14) Implementation Order\n1. Types and registry updates\n2. Persistence stores\n3. PermissionManager and error class\n4. IPC handlers (chat + admin)\n5. Provider enforcement (tool list filtering and executor checks)\n6. UI components and state slices\n7. Migrations and defaults\n8. Tests (unit -> integration -> UI)\n9. Documentation\n\n15) Notes\n- Keep the tool IDs stable and human-readable (e.g., 'git.status', 'fs.readFile')\n- For hashing PINs, use bcrypt with salt; store only hash\n- Ensure no tool invocation path bypasses PermissionManager (audit calls)\n- Consider telemetry/logging for permission denials (local-only)\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.18",
      "status": "-",
      "title": "Context retrieval for chat (RAG-lite)",
      "description": "Implement simple keyword-based search over project docs and tasks. Allow user to attach retrieved snippets into context before sending. Optionally auto-attach top-k snippets with a toggle. Acceptance: Search returns ranked results quickly; selected snippets previewed; tokens limited by model configuration; unit tests confirm deterministic retrieval on fixed corpora.",
      "plan": "Feature: Context retrieval for chat (RAG-lite)\n\nGoal\n- Implement fast, deterministic keyword-based search over project docs and tasks.\n- Let users preview and select snippets to attach to chat context.\n- Optional auto-attach top-k snippets with token-budget enforcement.\n- Provide unit tests ensuring deterministic retrieval ordering on a fixed corpus.\n\nHigh-level architecture\n- Main process (Electron): File scanning, indexing, search service (read-only), exposed via IPC.\n- Common package: Tokenizer, BM25 scoring, types, token counting.\n- Renderer (React): UI for search, selection, preview, token budget display, auto-attach toggle; integration with chat send pipeline.\n\n1) Data sources and scope\n1.1 Define corpus roots from current project settings: projectRoot/docs/**/*.md, projectRoot/tasks/**/*.(md|json|yaml), and future adapters (extensible).\n1.2 Exclude large/binary/unwanted paths: node_modules, .git, .env*, build artifacts, images, >2MB files by default.\n1.3 Add a simple adapter interface: CorpusAdapter { id, name, globPatterns, parse(file) -> {doc: Document | chunkedDocs[]} } to support docs and tasks uniformly.\n\n2) Common library (packages/common)\n2.1 Types (src/common/rag/types.ts)\n- RawDocument: { id, source: 'docs'|'tasks'|'other', path, title, content, meta? }\n- Chunk: { id, docId, chunkIndex, text, tokensApprox, title, path, source, meta }\n- SearchResult: { chunkId, docId, score, highlights: { start, end }[], preview: string, title, path, source }\n- RagConfig: { chunkSizeChars: number, chunkOverlapChars: number, stopwords: string[], bm25: { k1: number, b: number }, maxFileSizeBytes: number }\n2.2 Deterministic tokenizer (src/common/rag/tokenizer.ts)\n- Lowercase, Unicode NFKD normalize, strip diacritics, remove punctuation, split on non-letter/digit, stopword removal.\n- Expose tokenize(text): string[] and matchOffsets(text, terms) -> [{start,end,term}].\n- Keep deterministic ordering for ties by stable sort rules.\n2.3 BM25 scorer (src/common/rag/bm25.ts)\n- Build index from chunks: DF per term, avg doc length, per-chunk term frequencies.\n- Implement BM25 with k1=1.2, b=0.75 defaults; deterministic score + tie-break rule: higher score, then higher sum of IDF, then path lexicographically, then chunkIndex asc.\n2.4 Token counting (src/common/rag/tokens.ts)\n- Provide two methods: approxCharsToTokens(chars/4) and optional tiktoken via dynamic import if available (documented opt-in). Default to approx for zero-dependency.\n\n3) Main process: index and search (packages/main)\n3.1 File discovery and watching (src/main/rag/fileWatcher.ts)\n- Use chokidar to watch configured glob patterns for adapters.\n- On add/change/unlink: schedule incremental reindex for affected file (debounced).\n3.2 Adapters (src/main/rag/adapters)\n- docsAdapter.ts: read markdown, extract title (first H1 or filename), split into chunks by heading or fixed window (config.chunkSizeChars with overlap).\n- tasksAdapter.ts: parse md/json/yaml; extract task fields (id, title, description, notes) and emit chunks from description/notes.\n3.3 Index builder (src/main/rag/indexer.ts)\n- Build/maintain in-memory index: { chunks[], lexicon, df, avgLen }.\n- Persist snapshot to disk (appData/rag/index.json) with corpus hash to accelerate startup.\n- Deterministic ordering guaranteed by sorting and stable data structures.\n3.4 Search service (src/main/rag/search.ts)\n- search(query: string, k: number): tokenize query, compute BM25 scores, select top-k, generate previews (first N chars around highlight), and highlight offsets.\n- Enforce max results and timeouts; results returned in under ~100ms for medium corpora via precomputed structures.\n3.5 IPC API (src/main/rag/ipc.ts)\n- rag:buildIndex(): force rebuild; rag:getStatus(): { docs, chunks, lastBuildAt, ready }.\n- rag:search({ query, k }): return SearchResult[].\n- rag:getConfig()/rag:setConfig(partial): allow tuning chunk size, stopwords, k1, b.\n- Rate-limit search requests and ensure read-only operations.\n\n4) Renderer: state and hooks (packages/renderer)\n4.1 Global state (Zustand or Redux) (src/renderer/store/ragSlice.ts)\n- query, results, selectedChunkIds, autoAttachEnabled, topK, tokenBudget, modelMaxTokens, attachmentTokensUsed.\n- Actions: setQuery, search, toggleSelect(chunkId), clearSelection, setAutoAttach, setTopK, setTokenBudget, setModelMaxTokens.\n4.2 Hook (src/renderer/hooks/useRag.ts)\n- Debounced search tied to query changes (250ms debounce).\n- Calculates per-snippet tokens via tokens.approx; computes total selection tokens; prevents exceeding budget.\n\n5) Renderer: UI components\n5.1 Chat context panel (src/renderer/components/chat/ChatContextPanel.tsx)\n- Search input, auto-attach toggle, top-k selector, results list.\n- Each result shows title, source badge (Docs/Tasks), path, score bar (subtle), highlighted terms, and a 3-5 line preview.\n- Checkbox to select snippets; footer shows Selected N, Tokens total/limit; Attach Selected button.\n5.2 Selected attachments bar (src/renderer/components/chat/ContextAttachmentsBar.tsx)\n- Lists selected snippets as chips with token count and remove button; open-in-viewer action.\n5.3 Settings modal (src/renderer/components/settings/RagSettings.tsx)\n- Configure: chunk size/overlap, k1/b, default topK, token budget strategy, model max tokens, stopwords list.\n\n6) Chat send integration\n6.1 Message pipeline middleware (src/renderer/chat/sendMiddleware/ragContext.ts)\n- On send: if auto-attach enabled and no manual selection, perform a search using current composer text as query; pick topK within remaining token budget (modelMaxTokens - safety margin - current prompt tokens - system tokens - existing attachments).\n- Merge manual selections with auto-attach (deduplicate).\n- Construct a context block message preceding user message (e.g., role: \"system\" or a structured \"context\" metadata) with a header and the selected snippets with sources.\n- Enforce token budget: drop tail snippets if budget exceeded; show a toast when truncation occurs.\n\n7) Determinism and performance guarantees\n7.1 Deterministic sort: implement explicit tiebreak strategy and stable sorting; pin config defaults; pin stopwords list.\n7.2 Cache index snapshot and warm it on startup; show small status in UI (Indexing..., Ready).\n7.3 Debounced search in UI and IPC result streaming to keep interactions snappy.\n\n8) Unit tests (Vitest)\n8.1 Tokenizer tests (tests/rag/tokenizer.spec.ts)\n- Normalization, stopwords removal, punctuation handling, non-ASCII diacritics.\n8.2 BM25 tests (tests/rag/bm25.spec.ts)\n- Known corpus with 5-10 chunks; verify exact ordered results for fixed queries; tie-break rules verified.\n8.3 Indexer/search integration (tests/rag/search.spec.ts)\n- Build small in-memory index; run queries; verify preview generation and highlight offsets; ensure same order across runs.\n8.4 Token budget tests (tests/rag/tokens.spec.ts)\n- Approximate token counts and enforcement logic.\n\n9) Developer experience\n9.1 Dev commands\n- yarn rag:rebuild to trigger IPC buildIndex; yarn test:rag to run unit tests.\n9.2 Logging\n- Scoped logs: RAG:Indexer, RAG:Search, RAG:UI; disable in production.\n\n10) Documentation\n10.1 README-RAG.md\n- Overview, design choices, determinism guarantees, configuration, performance tips, privacy (local-only), and how to extend adapters.\n10.2 Third-party considerations\n- Default implementation is dependency-light. Optionally allow swapping to lunr/minisearch via an adapter in future; document trade-offs.\n\n11) Acceptance criteria mapping\n- Fast ranked results: Debounced UI + BM25 index with precomputed stats; verified via manual test and logs.\n- Selected snippets previewed: UI components show preview and highlights; attachments bar confirms selection.\n- Tokens limited by model configuration: Settings define modelMaxTokens; middleware enforces budget, shows live totals.\n- Deterministic retrieval: Unit tests validate order on fixed corpus; deterministic tokenizer + explicit tie-breakers.\n\n12) Implementation order\n1) Common lib (tokenizer, bm25, tokens, types).\n2) Main indexer + adapters + search + IPC.\n3) Renderer store + hook + basic UI with manual selection and attachment.\n4) Send middleware with token budget and auto-attach toggle.\n5) Unit tests.\n6) Docs and polish (highlights, file watcher, settings UI).\n\n13) Validation checklist\n- [ ] Index builds on startup; status \"Ready\" visible.\n- [ ] Query returns ranked results within ~100ms on typical corpora.\n- [ ] Selecting results updates token totals; cannot exceed budget.\n- [ ] Auto-attach top-k adds context when sending with toggle on.\n- [ ] Unit tests pass and confirm deterministic ordering.\n- [ ] No write operations exposed; read-only search only.",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.19",
      "status": "-",
      "title": "Child projects overview (submodules browser)",
      "description": "List submodules under projects/ with name, URL, current commit, and dirty status. Provide quick links to open in file explorer or terminal. Acceptance: Handles absent submodules gracefully; data sourced via git plumbing; UI updates when submodule pointers change; read-only operations only.",
      "plan": "Child projects overview (submodules browser) \u2014 Implementation Plan\n\nGoal\nList submodules under projects/ with name, URL, current commit, and dirty status. Provide quick links to open in file explorer or terminal. Read-only operations only. Handle absence of submodules gracefully. UI updates when submodule pointers change.\n\nAssumptions\n- The app knows the workspace root path of the repository (via settings or initial app configuration). Call it repoRoot.\n- The submodules are expected under repoRoot/projects/.\n- All git operations must be read-only and use git plumbing where possible.\n\nHigh-level Design\n- Main (Electron) provides a GitSubmodulesService that parses .gitmodules and uses plumbing commands to compute submodule info.\n- Preload exposes a safe API to the renderer: listSubmodules() and onSubmodulesUpdated(cb).\n- Renderer shows a table of submodules with actions (open explorer, open terminal, copy path/URL).\n- A background timer (or FS watcher + debounced polling) in the main process will periodically refresh submodule data and push updates when changes are detected.\n\nData Model\nType SubmoduleInfo {\n  name: string               // submodule name from .gitmodules (fallback to path basename)\n  path: string               // e.g., projects/foo\n  url?: string               // from .gitmodules; undefined if not present\n  pointerCommit?: string     // 40-char SHA from index (gitlink) for this path\n  headCommit?: string        // submodule worktree HEAD if initialized (rev-parse), else undefined\n  initialized: boolean\n  dirty: boolean             // true if worktreeDirty || untracked || pointerMismatch\n  status: {\n    pointerMismatch: boolean // headCommit != pointerCommit (when initialized)\n    worktreeDirty: boolean   // changes relative to HEAD in submodule\n    untracked: boolean       // untracked files in submodule\n    notInitialized: boolean\n  }\n}\n\nPlumbing Sources\n- List submodule definitions (name, path, url):\n  - git config -f .gitmodules --get-regexp ^submodule\\..*\\.path\n  - git config -f .gitmodules --get-regexp ^submodule\\..*\\.url\n- List current submodule pointers (index):\n  - git ls-files -s -- projects (parse entries with mode 160000)\n  - Fallback: if projects/ missing or no entries, treat as empty list\n- HEAD pointer for comparison (optional; not strictly needed to display but useful for richer status):\n  - git ls-tree -z HEAD projects (parse 160000 entries)\n- For each submodule path subPath:\n  - Detect initialized: fs.existsSync(join(repoRoot, subPath, '.git'))\n  - headCommit: git -C subPath rev-parse HEAD (if initialized)\n  - worktreeDirty: git -C subPath diff-index --quiet HEAD -- -> exitCode === 1 => dirty; 0 => clean\n  - untracked: git -C subPath ls-files --others --exclude-standard -> any output => untracked\n\nStep-by-step\n1) Main service: filesystem and process utilities\n   - Create main/services/git/submodules.ts with:\n     - execGit(args: string[], opts?): Promise<{stdout, stderr, code}>\n     - safeGit(root, args, opts?) that sets cwd to repoRoot.\n     - helper to exec in submodule: execGitInSub(path, args).\n     - parseGitmodules(repoRoot): returns Map<path, { name, url }>\n       - Use: git config -f .gitmodules --get-regexp ^submodule\\..*\\.path and ^submodule\\..*\\.url\n       - Build mapping between path -> name (from the section key) and url\n       - Handle no .gitmodules file gracefully (return empty map)\n     - listGitlinksFromIndex(repoRoot): returns Map<path, sha>\n       - Use: git ls-files -s -- projects\n       - Parse lines like: \"160000 <sha> 0\\tprojects/foo\"\n     - listGitlinksFromHead(repoRoot): optional for diagnostics; use git ls-tree -z HEAD projects and parse 160000\n     - getSubmoduleWorktreeState(repoRoot, subPath):\n       - initialized: existsSync(join(repoRoot, subPath, '.git'))\n       - if not initialized: return { initialized: false }\n       - headCommit: git -C subPath rev-parse HEAD\n       - worktreeDirty: run git -C subPath diff-index --quiet HEAD --; code 1 => true; 0 => false\n       - untracked: run git -C subPath ls-files --others --exclude-standard; length > 0 => true\n       - Return state\n     - buildSubmoduleList(repoRoot): Promise<SubmoduleInfo[]>:\n       - gm = parseGitmodules\n       - indexLinks = listGitlinksFromIndex\n       - candidatePaths = union of gm.paths and indexLinks.paths that start with 'projects/'\n       - For each path p in candidatePaths:\n         - meta = gm.get(p) or { name: basename(p), url: undefined }\n         - pointerCommit = indexLinks.get(p) (may be undefined if only in .gitmodules)\n         - state = getSubmoduleWorktreeState(repoRoot, p)\n         - headCommit = state.headCommit\n         - pointerMismatch = state.initialized && pointerCommit && headCommit && pointerCommit !== headCommit\n         - dirty = Boolean(pointerMismatch || state.worktreeDirty || state.untracked)\n         - Assemble SubmoduleInfo\n       - Sort list by path\n       - Return\n     - compareSubmoduleLists(a, b): boolean (deep comparison for change detection)\n\n2) Main service: IPC API and polling\n   - In main/ipc/submodules.ts:\n     - ipcMain.handle('git:listSubmodules', async () => buildSubmoduleList(repoRoot))\n     - Start a poller in main process: setInterval every 5000 ms (configurable), compute new list and if changed from last snapshot (using compare), send to all windows: webContents.send('git:submodulesUpdated', list)\n     - Also watch for immediate triggers with chokidar on:\n       - repoRoot/.gitmodules\n       - repoRoot/projects/**/.git/HEAD (and/or repoRoot/.git/modules/**/HEAD)\n       - repoRoot/.git/index\n       - On change, debounce (e.g., 300ms) and trigger a refresh\n     - Ensure cleanup on app quit\n   - Ensure all operations are read-only; avoid any commands that mutate state\n\n3) Main service: utility actions for UI\n   - openInExplorer(path): use shell.openPath(absPath) or shell.showItemInFolder depending on platform reliability\n   - openInTerminal(dir): implement platform-specific behavior:\n     - macOS: spawn('open', ['-a', 'Terminal', dir])\n     - Windows: spawn('cmd', ['/c', 'start', 'cmd.exe', '/K', `cd /d \"${dir}\"`])\n       - If Windows Terminal is preferred and available: spawn('wt.exe', ['-d', dir])\n     - Linux: try sequentially until success:\n       - x-terminal-emulator -e bash -lc \"cd '<dir>'; exec bash\"\n       - gnome-terminal -- bash -lc \"cd '<dir>'; exec bash\"\n       - konsole --workdir \"<dir>\"\n       - xfce4-terminal --working-directory=\"<dir>\"\n       - If none found, return an error so UI can show fallback (copy path)\n   - Wire IPC handlers:\n     - ipcMain.handle('system:openInExplorer', (_, relPath) => openInExplorer(join(repoRoot, relPath)))\n     - ipcMain.handle('system:openInTerminal', (_, relPath) => openInTerminal(join(repoRoot, relPath)))\n\n4) Preload bridge\n   - In preload/index.ts, expose via contextBridge:\n     - git.listSubmodules(): ipcRenderer.invoke('git:listSubmodules')\n     - git.onSubmodulesUpdated(cb): add listener to 'git:submodulesUpdated'\n     - system.openInExplorer(path): invoke('system:openInExplorer', path)\n     - system.openInTerminal(path): invoke('system:openInTerminal', path)\n\n5) Renderer UI\n   - Create a page/view: views/ChildProjects/SubmodulesView.tsx\n     - On mount: fetch initial list via git.listSubmodules()\n     - Subscribe to git.onSubmodulesUpdated to update state live\n     - Handle empty state: \"No child projects found under projects/\" with subtle guidance\n   - Table columns:\n     - Name (fallback to basename if missing); clickable to copy path\n     - Path (projects/foo); copy button\n     - URL (if present); hyperlink icon opens in default browser if http(s)\n     - Pointer commit (short 7 chars) with copy; tooltip shows full SHA\n     - HEAD commit (short; only if initialized); tooltip full SHA; if uninitialized show \"\u2014\"\n     - Status chip: values: Clean, Uninitialized, Dirty, Pointer mismatch; with tooltip showing:\n       - initialized, pointerMismatch, worktreeDirty, untracked booleans\n     - Actions:\n       - Open in Explorer\n       - Open in Terminal\n       - Copy URL (if present)\n   - Visual cues:\n     - If not initialized: show a warning icon and tooltip \"Submodule not initialized\"\n     - If pointerMismatch: highlight pointer/HEAD cells with subtle color\n   - Ensure read-only: no buttons to update/init submodules\n\n6) Graceful handling and errors\n   - If repoRoot is not a git repo or git not available:\n     - listSubmodules returns [] and an additional warning string; renderer shows banner: \"Git not available or not a repository\"\n   - If .gitmodules missing and no gitlinks: show empty state\n   - If parsing errors occur, log in main (debug) and return partial results where possible\n\n7) Performance and debouncing\n   - Poll every 5s; also trigger on chokidar events; debounce refresh by 300ms to coalesce bursts\n   - Limit submodule per-path checks to discovered paths; run worktree checks in parallel with Promise.all but cap concurrency (e.g., p-limit 5) to avoid overwhelming system\n\n8) Types and structure\n   - Shared types (SubmoduleInfo) placed in a common shared module imported by both main and renderer (or duplicate TypeScript declaration in both with care)\n\n9) Testing and validation\n   - Unit tests (node environment) for:\n     - parseGitmodules mapping (with sample .gitmodules content via temp files)\n     - listGitlinksFromIndex parser using mocked git output\n     - getSubmoduleWorktreeState logic with mocked exec results\n   - Manual QA scenarios:\n     - Repo with no projects/ directory\n     - Repo with projects/ but no .gitmodules\n     - Repo with properly initialized submodules (clean)\n     - Submodule with untracked files\n     - Submodule with modified files\n     - Submodule not initialized (missing .git)\n     - Submodule HEAD at different commit than superproject pointer (pointerMismatch)\n     - Switching branches to update submodule pointers; confirm UI updates automatically within ~5s or immediately on FS event\n     - Open in Explorer/Terminal actions on macOS, Windows, Linux (verify fallbacks)\n\n10) Documentation\n   - Add a README section \"Child Projects (Submodules)\" explaining:\n     - What is shown\n     - Data sources and read-only behavior\n     - How to troubleshoot if nothing appears\n     - Notes on platform-specific terminal opening behavior\n\nCommand references (plumbing-centric)\n- git config -f .gitmodules --get-regexp '^submodule\\..*\\.path'\n- git config -f .gitmodules --get-regexp '^submodule\\..*\\.url'\n- git ls-files -s -- projects\n- git ls-tree -z HEAD projects (optional)\n- git -C projects/<name> rev-parse HEAD\n- git -C projects/<name> diff-index --quiet HEAD --\n- git -C projects/<name> ls-files --others --exclude-standard\n\nAcceptance alignment\n- Handles absent submodules gracefully: empty list + informative UI\n- Data sourced via git plumbing: commands listed above; no porcelain reliance\n- UI updates when submodule pointers change: poll + chokidar-triggered refresh and IPC push\n- Read-only operations only: only rev-parse, ls-files, ls-tree, diff-index, and ls-files (others) used; no mutations\n- Quick links to open in file explorer or terminal provided via Electron shell/spawn",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.20",
      "status": "-",
      "title": "Cross-platform packaging configuration",
      "description": "Configure electron-builder to produce distributables for macOS (dmg), Windows (nsis), and Linux (AppImage). Include app icons and code signing placeholders. Acceptance: CI-local builds produce artifacts; metadata correct (name, version, copyright); app auto-updates disabled initially.",
      "plan": "Implementation Plan: Cross-platform packaging with electron-builder\n\n1) Preconditions: confirm build outputs\n- Decide your main and renderer output locations (examples below):\n  - Main (Electron): dist-electron/main.js (or similar)\n  - Renderer (React build): dist/ (or build/ from CRA)\n- You will reference these in the electron-builder config under `files`.\n\n2) Install packaging tooling\n- Add electron-builder as a dev dependency:\n  - npm: npm i -D electron-builder\n  - yarn: yarn add -D electron-builder\n\n3) Prepare icons\n- Create a base icon at assets/icon.png (recommend 1024x1024, square, no transparency issues).\n- Create resources/icons folder structure:\n  - resources/icons/icon.icns (macOS)\n  - resources/icons/icon.ico (Windows)\n  - resources/icons/png/ (Linux) with 512x512, 256x256, 128x128, 64x64, 48x48, 32x32, 24x24, 16x16\n- If you prefer auto-generation, add a dev script (choose one approach you like):\n  - Option A (electron-icon-builder):\n    - npm i -D electron-icon-builder\n    - Add script: \"icons:generate\": \"electron-icon-builder --input=assets/icon.png --output=resources/icons\"\n  - Option B (icon-gen):\n    - npm i -D icon-gen\n    - Add script: \"icons:generate\": \"icon-gen -i assets/icon.png -o resources/icons -m -w -l\"\n- Run: npm run icons:generate (or place your prepared icons manually).\n\n4) Add electron-builder config (disable auto-updates; include signing placeholders)\n- Create electron-builder.yml at repo root with this starter config. Adjust `files` to match your build outputs and update metadata fields to your org.\n\n--- electron-builder.yml ---\nappId: com.yourorg.localapp\nproductName: Factory Local App\ndirectories:\n  output: dist\n  buildResources: resources\nfiles:\n  # Adjust these patterns to include your built main and renderer bundles\n  - \"dist/**\"           # renderer output (e.g., React build)\n  - \"dist-electron/**\"  # main process output/bundle\n  - \"!**/*.map\"\nasar: true\npublish: \"never\"  # ensures auto-updates disabled by default\nextraMetadata:\n  # These override/augment package.json fields at build-time\n  # You can remove or change as needed\n  author: \"Your Org\"\n  # Update explicitly in package.json[version] for releases\n\nmac:\n  category: public.app-category.developer-tools\n  target:\n    - target: dmg\n      arch:\n        - x64\n        - arm64\n  icon: resources/icons/icon.icns\n  identity: null  # code signing disabled by default\n\ndmg:\n  artifactName: \"${productName}-${version}-mac-${arch}.${ext}\"\n\nwin:\n  target:\n    - target: nsis\n      arch:\n        - x64\n  icon: resources/icons/icon.ico\n  signAndEditExecutable: false\n  verifyUpdateCodeSignature: false\n\nnsis:\n  oneClick: true\n  perMachine: false\n  allowElevation: true\n  artifactName: \"${productName}-${version}-win-${arch}.exe\"\n\nlinux:\n  category: Development\n  target:\n    - AppImage\n  icon: resources/icons/png\n  maintainer: \"Your Name <you@example.com>\"\n  synopsis: \"Local project manager\"\n  description: \"Electron+React app to manage local agents, tasks, and project assets\"\n  artifactName: \"${productName}-${version}-linux-${arch}.${ext}\"\n--- end ---\n\n5) Package scripts in package.json\n- Add (or update) the following scripts. Keep the prepack step aligned with your project\u2019s build commands (ensure your main+renderer are built before packaging):\n\n\"scripts\": {\n  \"build\": \"<your existing full build that outputs dist and dist-electron>\",\n  \"prepack\": \"npm run build\",  \n  \"pack\": \"electron-builder --dir -c.mac.identity=null -c.win.sign=false\",\n  \"dist\": \"electron-builder -mwl\",\n  \"dist:mac\": \"electron-builder --mac -c.mac.identity=null\",\n  \"dist:win\": \"electron-builder --win --x64 -c.win.sign=false\",\n  \"dist:linux\": \"electron-builder --linux AppImage\",\n  \"clean:dist\": \"rimraf dist\"\n}\n\nNotes:\n- `prepack` triggers before `pack` and `dist`, ensuring the build artifacts exist.\n- The explicit `-c.*` flags keep signing disabled when running these commands locally/CI.\n\n6) Ensure metadata correctness\n- In package.json, set:\n  - name: a lowercase, hyphenated package name (e.g., \"factory-local-app\")\n  - version: a valid semver (e.g., \"0.1.0\")\n- In electron-builder.yml, set:\n  - productName: the human-readable app name\n  - appId: reverse-DNS unique ID (keep stable across releases)\n- Optional: Update copyright.\n\n7) Disable auto-updates in application code (if present)\n- If you already import/use electron-updater, gate it behind an env flag and default to off:\n\nconst enableAutoUpdate = process.env.AUTO_UPDATE === 'true';\nif (enableAutoUpdate) {\n  // init electron-updater here\n}\n\n- With the config\u2019s publish: \"never\", no update provider is configured by default.\n\n8) CI: cross-platform builds producing artifacts\n- Create .github/workflows/build.yml:\n\n--- .github/workflows/build.yml ---\nname: build\non:\n  push:\n    branches: [ main ]\n  pull_request:\n\njobs:\n  mac:\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n      - run: npm ci\n      - run: npm run dist:mac\n        env:\n          CSC_IDENTITY_AUTO_DISCOVERY: false\n      - uses: actions/upload-artifact@v4\n        with:\n          name: mac-dist\n          path: dist/**\n\n  windows:\n    runs-on: windows-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n      - run: npm ci\n      - run: npm run dist:win\n        env:\n          CSC_IDENTITY_AUTO_DISCOVERY: false\n      - uses: actions/upload-artifact@v4\n        with:\n          name: windows-dist\n          path: dist/**\n\n  linux:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n      - run: npm ci\n      - run: npm run dist:linux\n      - uses: actions/upload-artifact@v4\n        with:\n          name: linux-dist\n          path: dist/**\n--- end ---\n\n9) Code signing placeholders and documentation\n- Keep signing disabled by default (mac.identity: null; win.sign=false) so CI/local builds work without certs.\n- Add docs/packaging.md explaining how to enable signing later:\n  - macOS notarized signing: set env CSC_LINK (base64 .p12 or .cert), CSC_KEY_PASSWORD, APPLE_ID, APPLE_APP_SPECIFIC_PASSWORD (or use API key via APPLE_API_ISSUER/APPLE_API_KEY/APPLE_API_KEY_ID), remove mac.identity:null in config or set CSC_IDENTITY_AUTO_DISCOVERY=true.\n  - Windows signing: set WIN_CSC_LINK and WIN_CSC_KEY_PASSWORD (or CSC_* equivalents) and remove the win.sign=false override in scripts.\n- Clearly state that without these env vars, builds remain unsigned and will still produce distributables.\n\n10) Local verification (per OS)\n- macOS: npm run dist:mac -> verify dist/*.dmg exists; open DMG and install. Check bundle metadata: Finder > App > Get Info for name/version.\n- Windows: npm run dist:win -> verify dist/*.exe exists; run installer; check installed app About or executable Properties > Details for name/version.\n- Linux: npm run dist:linux -> verify dist/*.AppImage exists; chmod +x and run; check app about dialog.\n\n11) Acceptance checklist\n- CI and local `npm run dist:*` produce artifacts in dist/ for macOS (dmg), Windows (nsis exe), Linux (AppImage).\n- Metadata (name, version, copyright) appear correctly in installers/apps.\n- Auto-updates are disabled (publish: \"never\"; no updater initialized by default).\n- Code signing is documented but off by default; enabling requires providing secrets and adjusting config.\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.21",
      "status": "-",
      "title": "CI pipeline for build and release",
      "description": "Add GitHub Actions workflows to lint, type-check, build, and produce release artifacts on tags. Cache dependencies for speed. Optionally draft release with artifacts attached. Acceptance: CI green on main; tag push triggers build for all OS targets; artifacts downloadable; secrets managed securely (no plaintext keys).",
      "plan": "CI pipeline for build and release (Electron + React app)\n\nGoal\n- Add CI that:\n  - Lints, type-checks, and runs tests on push/PR to main.\n  - On tag push, builds production artifacts for macOS, Windows, Linux, uploads them as workflow artifacts, and drafts a GitHub Release with assets attached.\n  - Uses dependency and electron caches for speed.\n  - Uses only GITHUB_TOKEN (no plaintext keys), with optional code-signing/notarization env vars if configured.\n\nAssumptions\n- Repo is the Local Electron+React app (separate repo).\n- Build tool: electron-builder (standard for cross-OS packaging). If not yet chosen, this plan includes adding the minimal configuration needed.\n- Package manager is auto-detected by lockfile: pnpm-lock.yaml -> pnpm; yarn.lock -> yarn; package-lock.json -> npm.\n- Node 20 is the baseline (LTS).\n\nPlan\n1) Ensure package.json scripts and electron-builder config exist\n   - Add these scripts (adjust for your PM: npm/yarn/pnpm):\n     - \"lint\": \"eslint .\",\n     - \"typecheck\": \"tsc -p . --noEmit\" (or appropriate tsconfig path),\n     - \"test\": \"vitest run --coverage\" (or your chosen test runner),\n     - \"build:web\": \"vite build\" (or react-scripts build),\n     - \"build:main\": \"tsc -p tsconfig.main.json --noEmit false\" (if you split main/renderer),\n     - \"build:ci\": \"npm run build:web && npm run build:main\",\n     - \"dist\": \"electron-builder -c electron-builder.yml\"\n   - Add electron-builder config (choose either package.json `build` field or `electron-builder.yml`). Example electron-builder.yml:\n     ---\n     appId: com.yourorg.localapp\n     productName: LocalApp\n     directories:\n       output: dist\n     files:\n       - \"packages/**/dist/**\"\n       - \"dist/**\"\n       - \"build/**\"\n       - \"package.json\"\n     mac:\n       target: [\"dmg\", \"zip\"]\n       category: public.app-category.productivity\n     win:\n       target: [\"nsis\"]\n     linux:\n       target: [\"AppImage\", \"deb\"]\n       category: Utility\n     publish: \"never\"\n   - Ensure the build output of renderer and main ends up where electron-builder expects (adjust files list accordingly).\n\n2) Add dependency caches and electron caches strategy\n   - Use actions/setup-node with `cache` auto-detection for npm/yarn/pnpm.\n   - Cache electron/electron-builder using actions/cache with paths:\n     - ~/.cache/electron\n     - ~/.cache/electron-builder\n   - Set env vars to avoid signing prompts in CI: `CSC_IDENTITY_AUTO=false` and `CI=true`.\n\n3) Create CI workflow for push/PR: .github/workflows/ci.yml\n   - Trigger: on push to any branch, pull_request targeting main.\n   - Jobs: lint-typecheck-test-build\n     - runs-on: ubuntu-latest\n     - Steps (pseudocode YAML; adapt PM based on lockfile):\n       - actions/checkout@v4\n       - actions/setup-node@v4 with node-version: 20 and cache: auto\n       - If pnpm: pnpm/action-setup@v4 with version: 9 and run_install: true; else run install for npm/yarn\n       - actions/cache@v4 for electron caches\n       - Run lint: `npm run lint`\n       - Run typecheck: `npm run typecheck`\n       - Run test: `npm run test`\n       - Run build check: `npm run build:ci`\n   - Set `concurrency: ci-${{ github.ref }}-push` with `cancel-in-progress: true` to keep queue lean.\n\n   Example ci.yml:\n   name: CI\n   on:\n     push:\n       branches: [\"*\"]\n     pull_request:\n       branches: [\"main\"]\n   concurrency:\n     group: ci-${{ github.ref }}\n     cancel-in-progress: true\n   jobs:\n     build:\n       runs-on: ubuntu-latest\n       steps:\n         - uses: actions/checkout@v4\n         - uses: actions/setup-node@v4\n           with:\n             node-version: 20\n             cache: \"auto\"\n         - if: hashFiles('pnpm-lock.yaml') != ''\n           uses: pnpm/action-setup@v4\n           with:\n             version: 9\n             run_install: true\n         - if: hashFiles('yarn.lock') != ''\n           run: yarn install --frozen-lockfile\n         - if: hashFiles('package-lock.json') != ''\n           run: npm ci\n         - name: Cache Electron\n           uses: actions/cache@v4\n           with:\n             path: |\n               ~/.cache/electron\n               ~/.cache/electron-builder\n             key: ${{ runner.os }}-electron-${{ hashFiles('**/package-lock.json', '**/yarn.lock', '**/pnpm-lock.yaml') }}\n         - run: npm run lint --if-present\n         - run: npm run typecheck --if-present\n         - run: npm run test --if-present\n         - run: npm run build:ci --if-present\n\n4) Create Release workflow for tags: .github/workflows/release.yml\n   - Trigger: on push tags matching v* (e.g., v1.2.3).\n   - permissions: contents: write (required to create release and upload assets with GITHUB_TOKEN).\n   - Strategy: matrix over os: [macos-latest, windows-latest, ubuntu-latest].\n   - Each matrix job:\n     - Checkout, setup Node 20 with cache, install deps (pnpm/yarn/npm as above), cache electron.\n     - Set env: CSC_IDENTITY_AUTO=false, CI=true.\n     - Build artifacts via electron-builder for the OS:\n       - macOS: `npx electron-builder --mac dmg zip`\n       - Windows: `npx electron-builder --win nsis`\n       - Linux: `npx electron-builder --linux AppImage deb`\n     - Upload built files from dist/ as artifacts with a unique name per OS.\n   - Final aggregator job (ubuntu): needs all matrix jobs; downloads artifacts; creates or updates a draft GitHub Release and attaches all artifacts.\n   - No secrets required; uses `GITHUB_TOKEN` automatically granted.\n\n   Example release.yml:\n   name: Release\n   on:\n     push:\n       tags:\n         - \"v*\"\n   permissions:\n     contents: write\n   jobs:\n     build:\n       name: Build (${{ matrix.os }})\n       strategy:\n         matrix:\n           os: [ubuntu-latest, macos-latest, windows-latest]\n       runs-on: ${{ matrix.os }}\n       steps:\n         - uses: actions/checkout@v4\n         - uses: actions/setup-node@v4\n           with:\n             node-version: 20\n             cache: \"auto\"\n         - if: hashFiles('pnpm-lock.yaml') != ''\n           uses: pnpm/action-setup@v4\n           with:\n             version: 9\n             run_install: true\n         - if: hashFiles('yarn.lock') != ''\n           run: yarn install --frozen-lockfile\n         - if: hashFiles('package-lock.json') != ''\n           run: npm ci\n         - name: Cache Electron\n           uses: actions/cache@v4\n           with:\n             path: |\n               ~/.cache/electron\n               ~/.cache/electron-builder\n             key: ${{ runner.os }}-electron-${{ hashFiles('**/package-lock.json', '**/yarn.lock', '**/pnpm-lock.yaml') }}\n         - name: Build artifacts\n           env:\n             CSC_IDENTITY_AUTO: false\n             CI: true\n           run: |\n             if [[ \"${{ runner.os }}\" == \"macOS\" ]]; then npx electron-builder --mac dmg zip; fi\n             if [[ \"${{ runner.os }}\" == \"Windows\" ]]; then npx electron-builder --win nsis; fi\n             if [[ \"${{ runner.os }}\" == \"Linux\" ]]; then npx electron-builder --linux AppImage deb; fi\n         - name: Upload artifacts\n           uses: actions/upload-artifact@v4\n           with:\n             name: dist-${{ runner.os }}\n             path: dist/**\n     publish:\n       name: Publish GitHub Release\n       runs-on: ubuntu-latest\n       needs: build\n       steps:\n         - uses: actions/download-artifact@v4\n           with:\n             path: ./artifacts\n         - name: Create/Update Release and Upload Assets\n           uses: softprops/action-gh-release@v2\n           with:\n             draft: true\n             files: ./artifacts/**\n           env:\n             GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n5) Optional code-signing and notarization (secure handling)\n   - Do not store any signing keys in the repo.\n   - If/when you want signed notarized builds:\n     - Add repo secrets (not plaintext):\n       - For macOS: APPLE_ID, APPLE_APP_SPECIFIC_PASSWORD, CSC_IDENTITY_NAME or use API key for notarization.\n       - For Windows: CSC_LINK (base64 of .pfx in a secure secret), CSC_KEY_PASSWORD.\n     - Update release.yml to conditionally set env vars if secrets exist (e.g., only sign when `secrets.CSC_LINK` is set). Keep default unsigned otherwise.\n\n6) Documentation\n   - Add docs/ci.md explaining:\n     - What workflows exist and when they run.\n     - How to trigger a release: `git tag vX.Y.Z && git push origin vX.Y.Z`.\n     - Where to find artifacts (Actions run artifacts and Releases page).\n     - How caching works.\n     - How to configure signing via repo secrets.\n\n7) Housekeeping\n   - Ensure dist/ is gitignored.\n   - Ensure ESLint/TS config is present to make lint/typecheck meaningful.\n   - Set badges in README for CI status (optional): `![CI](https://github.com/<org>/<repo>/actions/workflows/ci.yml/badge.svg)`.\n\n8) Verification steps (acceptance)\n   - Push a branch/PR: CI should run lint/typecheck/test/build and pass (green on main upon merge).\n   - Create a tag v0.1.0 and push: three matrix jobs should produce OS-specific artifacts; publish job should create a draft release with all artifacts attached.\n   - Open the Actions tab to download artifacts from the run.\n   - Open the Releases page to confirm artifacts attached to the new draft release.\n   - Confirm no secrets in plaintext in the repo; only GITHUB_TOKEN is used by default.\n\nNotes/Contingencies\n- If repo uses Yarn/Pnpm, the workflows auto-detect by lockfile. If monorepo, adjust install commands and working-directory or add a root-level script to orchestrate build.\n- If Electron app requires native dependencies (node-gyp), windows-latest and macos-latest images include build tools; if needed, add `actions/setup-python@v5` with python-version 3.x and install build-essential on Linux.\n- If your build requires a display, avoid running the app in CI; packaging with electron-builder does not require xvfb.\n",
      "context": [],
      "acceptance": []
    },
    {
      "id": "5.22",
      "status": "-",
      "title": "Developer documentation and runbook",
      "description": "Complete docs: ARCHITECTURE.md (process boundaries, IPC contract), DEVELOPMENT.md (setup, scripts), SECURITY.md (IPC, sandbox, tool restrictions), PROVIDERS.md (LLM connectors), AGENTS.md (how agent processes are managed), and a quickstart. Acceptance: Docs pass link check; examples tested; contributors can set up locally following docs without assistance.",
      "plan": "Developer Documentation and Runbook Plan (Feature 5.22)\n\nGoal\nProduce complete developer documentation for the Local Electron+React app so contributors can understand architecture, set up and run the project, reason about security, add LLM providers, and manage agent processes. Ensure docs pass link checks and examples are tested so a contributor can set up locally without assistance.\n\nDeliverables\n- /docs/ARCHITECTURE.md: Process boundaries, components, IPC contract, data flows\n- /docs/DEVELOPMENT.md: Environment setup, scripts, build, test, troubleshooting\n- /docs/SECURITY.md: Threat model, IPC hardening, sandboxing, tool restrictions\n- /docs/PROVIDERS.md: LLM connectors (LiteLLM, OpenAI, LM Studio, Ollama), config\n- /docs/AGENTS.md: Agent process management, lifecycle, adding new agents\n- /docs/QUICKSTART.md: 10-minute path to running the app and seeing value\n- Docs tooling: link checks, markdown lint; CI job to verify\n- Example snippets referenced by docs that can be executed/verified locally\n\nAssumptions\n- Repo uses Electron (main, preload), React renderer, TypeScript\n- Agents run as local Node child processes with a tool registry\n- LLM access is abstracted behind provider connectors (current: LiteLLM) with ability to add others (LM Studio, Ollama, OpenAI)\n\nImplementation Steps\n\n1) Prepare docs workspace\n1.1 Create /docs directory at repo root with the following files:\n- /docs/ARCHITECTURE.md\n- /docs/DEVELOPMENT.md\n- /docs/SECURITY.md\n- /docs/PROVIDERS.md\n- /docs/AGENTS.md\n- /docs/QUICKSTART.md\n- /docs/README.md (index linking the above)\n- /docs/snippets/ (folder for code snippets referenced by docs)\n1.2 Add /docs/_assets/ for future diagrams/screenshots (placeholder images).\n1.3 Add a docs index section to top-level README pointing to /docs.\n\n2) Add docs quality tooling\n2.1 Add devDependencies:\n- markdownlint-cli2 (style)\n- remark, remark-cli, remark-validate-links (broken link checking)\n- optional: cspell (spelling), but not required for acceptance\n2.2 Add configuration files:\n- .markdownlint.jsonc with common rules and overrides for code blocks\n- .remarkrc.mjs with validate-links plugin and local reference handling\n2.3 Add npm scripts in package.json:\n- \"docs:lint\": \"markdownlint-cli2 \\\"**/*.md\\\" --ignore node_modules --ignore dist\"\n- \"docs:links\": \"remark . --quiet --frail\"\n- \"docs:check\": \"npm run docs:lint && npm run docs:links\"\n2.4 Add GitHub Actions workflow .github/workflows/docs.yml to run docs:check on push/PR.\n\n3) Author ARCHITECTURE.md\n3.1 Purpose & scope\n- What the app is: local Electron+React project management console for the factory\n- Non-goals: cloud services, remote management (future work)\n3.2 High-level architecture diagram (Mermaid, included inline)\n- Processes: Electron main, preload, renderer (React), Agent Manager (child processes), Git worker, LLM provider clients\n3.3 Process boundaries\n- Main process responsibilities: app lifecycle, IPC routing, file system, spawn agents, notifications\n- Preload: contextBridge, safe API surface to renderer, channel whitelist\n- Renderer (React): UI only, no Node APIs, uses typed IPC calls via preload\n- Agent processes: spawned Node processes, isolated working dirs, logs, lifecycle\n3.4 IPC contract (versioned)\n- Channel naming convention: app/<domain>/<action> with version suffix (e.g., v1)\n- Message envelope: { id, type, payload, ts }, response: { id, ok, data?, error? }\n- List required channels with TypeScript interfaces (inlined and also as /docs/snippets/ipc.ts)\n  Examples:\n  - app/v1/agents.list -> returns AgentSummary[]\n  - app/v1/agents.start { agentId, config? } -> AgentStatus\n  - app/v1/agents.stop { agentId }\n  - app/v1/git.status { repoPath } -> GitStatus\n  - app/v1/tasks.list, tasks.update\n  - app/v1/docs.list, docs.get\n  - app/v1/chat.send { provider, model, message, tools: readonly[] } -> stream/token events\n3.5 Data storage and state\n- Project workspace directories, config files, caches (LLM), logs\n- Git integration (read repo status; write only on explicit actions)\n3.6 LLM provider abstraction\n- Provider interface, capability detection, streaming mode, rate limiting\n3.7 Notifications & background jobs\n- OS notifications, tray integration, background checks\n3.8 Extensibility\n- Plug-in points: providers, agents, tools; IPC versioning strategy\n\n4) Author AGENTS.md\n4.1 Agent model\n- Agent definition (id, name, purpose, tools allowed, working dir)\n- Tool registry (capabilities, read-only vs write), permission model\n4.2 Lifecycle management\n- Spawn via child_process, env injection, config hydration\n- Heartbeat/health checks; graceful shutdown and timeouts\n- Crash detection and auto-restart policy\n4.3 I/O and logs\n- stdout/stderr capture; log file rotation; log streaming via IPC\n4.4 Agent status in UI\n- States: idle, running, blocked, finished; progress events\n4.5 Adding a new agent\n- Folder structure/template\n- Required manifest (YAML/JSON) with metadata and tool permissions\n- How to register agent with the app\n4.6 Security constraints for agents\n- Least privilege FS access (scoped paths)\n- Network access policy (default off / restricted)\n- Tool allowlist; read-only tools for chat-driven sessions\n4.7 Example\n- Provide /docs/snippets/agent.manifest.example.yaml\n\n5) Author PROVIDERS.md\n5.1 Provider interface\n- Methods: listModels, generate, stream, embeddings (optional)\n- Config shape (apiBase, apiKey, model, headers)\n5.2 Built-in connectors\n- LiteLLM: usage and configuration\n- OpenAI: direct API usage\n- LM Studio: local server configuration (port, models); test curl commands\n- Ollama: local endpoint examples, model pull/run\n5.3 Configuration\n- .env and app settings; per-provider fields and precedence\n- Rate limits, retries, timeouts\n5.4 Switching providers\n- UI setting vs env var; fallbacks\n5.5 Testing providers\n- /docs/snippets/provider.smoketest.http (http file with sample requests)\n- Quick Node script snippet to validate connectivity\n\n6) Author SECURITY.md\n6.1 Threat model\n- Local app; untrusted repositories; LLM prompt injection; malicious agents\n6.2 Electron hardening\n- contextIsolation: true, sandbox: true, disable remote module\n- nodeIntegration: false in renderer; trusted preload only\n- Content-Security-Policy; disable eval; no insecure http loads\n6.3 IPC security\n- Strict channel allowlist; Zod schema validation on both ends\n- Never pass raw user input to privileged operations without validation\n- Error handling without leaking sensitive paths\n6.4 Tool restrictions\n- Read-only tool set for chat; permission prompts for escalations\n- Path whitelisting for FS operations; no shell exec from renderer\n6.5 Secrets management\n- .env.local (gitignored); OS keychain integration roadmap\n6.6 Dependency hygiene\n- npm audit, lockfile policy, signed binaries for release\n6.7 Git interactions\n- Only explicit writes; dry-run previews; safe merges\n6.8 Updates and signing (roadmap)\n\n7) Author DEVELOPMENT.md\n7.1 Prerequisites\n- Node.js LTS version, npm/pnpm, OS build deps for Electron\n- Git; optional: LM Studio/Ollama install links\n7.2 Cloning and installing\n- git clone, npm i (or pnpm i) commands\n7.3 Running the app\n- npm run dev: start main+renderer with hot reload\n- npm run typecheck, test, lint\n7.4 Building\n- npm run build; npm run package (if using electron-builder/forge)\n7.5 Environment variables\n- .env examples for providers (OPENAI_API_KEY, LMSTUDIO_BASE_URL, OLLAMA_BASE_URL)\n7.6 Debugging\n- DevTools; logging locations; enabling verbose logs via env\n7.7 Scripts overview\n- docs:*, test:*, agents:*\n7.8 Troubleshooting\n- Common errors and fixes (Electron build tools on Windows, provider connection failures)\n\n8) Author QUICKSTART.md\n8.1 Goal-based path in ~10 minutes\n- Install prerequisites\n- Clone repo and install dependencies\n- Start LM Studio or Ollama (optional path if no cloud key)\n- Create .env from example (pick a provider)\n- npm run dev to launch\n- Connect to a local project path in the app\n- Start a sample agent; watch status\n- Open Chat; select provider; send a message (read-only tools)\n- View Markdown docs rendered in the app\n- Optional: check git status view\n8.2 Screenshots placeholders ((add later)) and callouts\n8.3 Next steps and links to other docs\n\n9) Create executable examples/snippets\n9.1 /docs/snippets/ipc.ts\n- TypeScript interfaces for IPC messages and validation example (Zod). Ensure code compiles with ts-node.\n9.2 /docs/snippets/provider.smoketest.http\n- HTTP requests for LM Studio and Ollama; include curl variants\n9.3 /docs/snippets/agent.manifest.example.yaml\n- Minimal agent manifest with read-only tools\n9.4 Add npm scripts to validate examples:\n- \"docs:examples:ts\": \"ts-node --compiler-options '{\\\"module\\\":\\\"commonjs\\\"}' docs/snippets/ipc.ts --check\"\n- \"docs:examples\": \"npm run docs:examples:ts\"\n\n10) Link and content validation\n10.1 Ensure all intra-doc links are relative and correct\n10.2 Run npm run docs:check locally; fix any broken links\n10.3 Validate example commands:\n- Execute provider curls against running LM Studio/Ollama and note expected outputs in docs\n- Confirm ts snippet typechecks/executes\n10.4 Have a teammate or clean VM dry-run QUICKSTART and note friction points; update docs accordingly\n\n11) Wire acceptance checks\n11.1 Verify docs:check passes locally and in CI\n11.2 Verify examples runnable (ts compiles; curl commands return 200 with instructions if server not running)\n11.3 Confirm a new contributor can set up and run the app using QUICKSTART + DEVELOPMENT.md without assistance\n\n12) Maintenance & contribution guidance\n12.1 Add Docs section to CONTRIBUTING.md\n- How to add/modify docs; writing style checklist\n- How to add new provider/agent and update docs accordingly\n12.2 Add a PR checklist item: \"docs updated and docs:check passes\"\n\nContent Notes and Standards\n- Use Mermaid for diagrams in ARCHITECTURE.md\n- Include explicit versioning for the IPC contract and change log notes when channels change\n- Mark experimental features with stability tags\n- Keep provider credentials optional with local-first setups (LM Studio/Ollama)\n- All code blocks specify language for syntax highlighting\n\nOut-of-Scope (Future)\n- Full static doc site (Docusaurus) \u2013 optional future enhancement\n- Automated screenshot generation\n\nCompletion Criteria Mapping\n- Docs pass link check: Achieved via remark-validate-links in npm script + CI\n- Examples tested: Typescript snippet compiles; provider curls return; documented expectations\n- Contributors can set up locally: QUICKSTART + DEVELOPMENT.md tested on fresh environment and refined\n",
      "context": [],
      "acceptance": []
    }
  ]
}